<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Gianluca Quercini">

  
  
  
    
  
  <meta name="description" content="MLlib lab.">

  
  <link rel="alternate" hreflang="en-us" href="/courses/plp/tutorials/mllib/">

  


  
  
  
  <meta name="theme-color" content="rgb(0, 136, 204)">
  

  
  
  
  <script src="/js/mathjax-config.js"></script>
  


  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu68b06f59cdf252d86e7129a31e131766_426695_32x32_fill_lanczos_center_3.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu68b06f59cdf252d86e7129a31e131766_426695_192x192_fill_lanczos_center_3.png">

  <link rel="canonical" href="/courses/plp/tutorials/mllib/">

  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Gianluca Quercini">
  <meta property="og:url" content="/courses/plp/tutorials/mllib/">
  <meta property="og:title" content="Spark MLlib | Gianluca Quercini">
  <meta property="og:description" content="MLlib lab."><meta property="og:image" content="img/map[gravatar:%!s(bool=true) shape:circle]">
  <meta property="twitter:image" content="img/map[gravatar:%!s(bool=true) shape:circle]"><meta property="og:locale" content="en-us">
  
    
    
  

  



  


  


  





  <title>Spark MLlib | Gianluca Quercini</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Gianluca Quercini</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Gianluca Quercini</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#experience"><span>Experience</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#teaching"><span>Teaching</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      

      

      

    </ul>

  </div>
</nav>


  

  

<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      


<script src="/js/toggle-menu.js"></script>







  
    
  




<form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-3" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <span><i class="fas fa-bars"></i></span>
  </button>

  
</form>

<nav class="collapse docs-links" id="docs-nav">
  

  
  
  
  
  <div class="docs-toc-item">

    <a onclick=open_menu_on_click(this) id="tutorials" class="docs-toc-link" href="/courses/plp/tutorials/map-reduce/">Tutorials and labs</a>
    
    <div id="tutorials-ddowncontent" class="tutorials-ddowncontent ddowncontent">
    <ul class="nav docs-sidenav">
      
      
      <li class="tutorials">
        <a href="/courses/plp/tutorials/map-reduce/">MapReduce</a>
      </li>
      
      
      <li class="tutorials">
        <a href="/courses/plp/tutorials/structured-streaming-lab/">Spark structured streaming</a>
      </li>
      
      <script>open_menu_on_load("tutorials".concat("-ddowncontent"))</script>
      <li class="active tutorials">
        <a href="/courses/plp/tutorials/mllib/">Spark MLlib</a>
      </li>
      
    </ul>
    </div>
    
    

  </div>
  
  
</nav>

    </div>

    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article">

        <div class="docs-article-container">
          <div class="heading">Platforms and languages</div>
          <h1>Spark MLlib</h1>
          <hr>
          <div class="logo">
            <p><img src="/img/cs-logo.png" width="20%" style="display: block; margin: auto;" /></p>
            </div>

          <div class="article-style">
            


<p><link rel="stylesheet" href="/styles/course.css">
<link rel="stylesheet" href="/styles/cloud-computing.css"></p>
<!-- ############ IMPORTANT: CHANGE THESE VALUES BEFORE ANY LAB ############ -->
<!-- The link to the Edunao page where the students submit their work -->
<!-- The submission deadline -->
<!-- The group to which users in the cluster belong-->
<!-- User accounts are numbered from the lower to the upper limit-->
<!-- ############ END OF MODIFICATIONS ############ -->
<p>In this tutorial, you’ll learn how to use the Spark MLlib library to train, test and evaluate machine learning models.
We’ll be using a dataset of AirBnb accommodation in the San Francisco area.
The dataset is available in HDFS at the following path:</p>
<div align="center">
<pre><code>hdfs://sar17:9000/cpu_quercini/ml/sf-airbnb-clean.parquet</code></pre>
</div>
<div class="infobox warning">
<p><strong>Dataset source</strong></p>
<p>The dataset has been obtained <a href="https://github.com/databricks/LearningSparkV2" target="_blank">from this GitHub repository</a>.</p>
</div>
<p>The goal of the exercise is to predict the price per night of an apartment given all the features
in the dataset.</p>
<div class="infobox warning">
<p><strong>Changing Python interpreter of the executors</strong></p>
<p>The default Python interpreter used by the executors in the cluster does not have the package <code>numpy</code> installed.
In order to use one that has <code>numpy</code>, you need to run the following command in the terminal:</p>
<div align="center">
<pre><code>export PYSPARK_PYTHON=/usr/bin/python3</code></pre>
</div>
</div>
<div id="obtaining-a-training-and-test-set" class="section level1">
<h1><span class="header-section-number">1</span> Obtaining a training and test set</h1>
<p>In order to build and evaluate a machine learning model, we need to split our dataset into
a <strong>training</strong> and <strong>test set</strong>.</p>
<div class="infobox exercisebox">
<p><strong>Activity</strong></p>
<ol style="list-style-type: decimal">
<li>Copy the file <code>train_test.py</code> to your home folder in the cluster by typing the following command:</li>
</ol>
<div align="center">
<pre><code>cp /usr/users/cpu-prof/cpu_quercini/mllib/train_test.py .</code></pre>
</div>
<ol start="2" style="list-style-type: decimal">
<li><strong>Complete Line 9</strong>, by specifying your directory in HDFS, which is as follows (<strong>replace X with your account number</strong>).</li>
</ol>
<div align="center">
<pre><code>hdfs://sar17:9000/plpspark22/plpspark22_X</code></pre>
</div>
</div>
<div class="infobox exercisebox">
<p><strong>Exercise</strong></p>

<div class="exercise">
<p><span id="exr:unnamed-chunk-1" class="exercise"><strong>Exercise 1.1  </strong></span></p>
<ol style="list-style-type: decimal">
<li><p><strong>Complete Line 23.</strong> Write the code to read the input file, which is stored in HDFS as a Parquet file, into the DataFrame <code>airbnb_df</code>.</p></li>
<li><p><strong>From Line 26</strong>, add the instructions necessary to print the schema of <code>airbnb_df</code> and the first 5 rows. Which option should you use
to nicely see the values in the columns?</p></li>
<li>Execute the code with <code>spark-submit</code> and verify that the data is correctly loaded.</li>
</ol>
</div>
</div>
<p>We now split <code>airbnb_df</code> into two separate DataFrames, <code>train_df</code> and <code>test_df</code>, containing the training and
test instances respectively.</p>
<div class="infobox exercisebox">
<p><strong>Exercise</strong></p>

<div class="exercise">
<p><span id="exr:unnamed-chunk-2" class="exercise"><strong>Exercise 1.2  </strong></span></p>
<ol style="list-style-type: decimal">
<li><p><strong>Uncomment Line 32.</strong> Write the code to split the dataset into a training and test set. 80% of the instances
must be taken as training instances, while the remaining 20% will be used a test instances.
<a href="https://spark.apache.org/docs/3.1.1/api/python/reference/pyspark.sql.html" target="_blank">Looking at the DataFrame API documentation</a>, which
function are you going to use?</p></li>
<li><p><strong>From Line 36</strong>, write the code to print the number of instances in the training and test set.</p></li>
<li>Execute the code with <code>spark-submit</code>. You should have 5780 training instances and 1366 test instances.</li>
</ol>
</div>
</div>
<p>It is time to save the training and test sets to a HDFS file.
This way, we can load them whenever we need them to build a machine learning model
for this problem.</p>
<div class="infobox exercisebox">
<p><strong>Exercise</strong></p>

<div class="exercise">
<p><span id="exr:unnamed-chunk-3" class="exercise"><strong>Exercise 1.3  </strong></span></p>
<p><strong>From Line 47</strong>. Write the code to write the training and test sets to two Parquet files in HDFS.
The paths to the two files are already available in variables <code>training_set_file</code> and <code>test_set_file</code>
defined at Lines 40 and 43 respectively.</p>
</div>
</div>
</div>
<div id="preparing-the-features" class="section level1">
<h1><span class="header-section-number">2</span> Preparing the features</h1>
<p>In both training and test sets, the features correspond to DataFrame columns.
Most of the machine learning algorithms in Spark need to have all features in one single vector.
We need to use a <strong>transformer</strong>.</p>
<div class="infobox warning">
<p><strong>Good to know</strong></p>
<p><strong>Transformers</strong> take in a DataFrame and return a new DataFrame that has the same columns as the
input DataFrame and additional columns that are specified as an argument to the transformer.</p>
</div>
</div>
<p>Copy the file <code>train_test_model</code> to your home folder in the cluster by typing the following command:</p>
<div align="center">
<p>cp /usr/users/cpu-prof/cpu_quercini/mllib/train_test_model.py .</p>
</div>
<div class="infobox exercisebox">
<p><strong>Exercise</strong></p>

<div class="exercise">
<p><span id="exr:unnamed-chunk-4" class="exercise"><strong>Exercise 2.1  </strong></span></p>
<ul>
<li><p>Implement the function <code>read_training_set</code> at Line 22.
The file reads into a Spark DataFrame the training set Parquet file that you generated in the previous section.</p></li>
<li><p>Implement the function <code>read_test_function</code> at Line 39. The file reads into a Spark DataFrame the test set Parquet file that you generated in the previous section.</p></li>
<li><p>Modify the variables at Line 105 and 106 so that they point to the two HDFS Parquet files that contain the training and test sets.</p></li>
<li><p>Uncomment Lines 109 and 110, so as to print the number of training and test instances.</p></li>
<li><p>Execute the file <code>train_test_model</code> with <code>spark-submit</code>. Check that the number of training and test instances correspond to what you
got in the first section.</p></li>
</ul>
</div>
</div>
<p>It is now time to learn how to use a transformer to put all the necessary features into a vector.
For the time being, we’ll only be using the feature <code>bedrooms</code> to predict the price.</p>
<div class="infobox exercisebox">
<p><strong>Exercise</strong></p>

<div class="exercise">
<p><span id="exr:unnamed-chunk-5" class="exercise"><strong>Exercise 2.2  </strong></span></p>
<ul>
<li><p>Implement the function <code>get_vector</code> at Line 55. The comments in the file describe what the function is supposed to do.
You’ll need to use a <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.VectorAssembler.html#pyspark.ml.feature.VectorAssembler" target="_blank">VectorAssembler object</a> to implement the function.</p></li>
<li><p>Uncomment Lines 117 and 118 to call the function <code>get_vector</code> and display the result.</p></li>
<li><p>Execute the file <code>train_test_model</code> with <code>spark-submit</code>. Observe the content of the the DataFrame <code>train_vect</code>. It should have a column named
<code>features</code> containing a list with one value (the value of feature <code>bedrooms</code>).</p></li>
</ul>
</div>
</div>
<p>It is now time to train a linear regression model on the given training set and the selected features.</p>
<div class="infobox exercisebox">
<p><strong>Exercise</strong></p>

<div class="exercise">
<p><span id="exr:unnamed-chunk-6" class="exercise"><strong>Exercise 2.3  </strong></span></p>
<ul>
<li><p>Implement the function <code>train_linear_regression_model</code> at Line 79. The comments in the file describe what the function is supposed to do.
<a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html" target="_blank">Looking at the documentation</a>, try to identify the object that you need to use
to create a linear regressor and the function that you need to invoke to train the linear regressor.</p></li>
<li><p>Uncomment Lines 121, 124, 125, 126 to call the function <code>train_linear_regression_model</code> and display the coefficients learned by the linear regression model.</p></li>
<li>Execute the file <code>train_test_model</code> with <code>spark-submit</code>.</li>
</ul>
</div>
</div>
<p>We can now use the trained model to make some predictions.
The model returned by the function that you implemented in the previous exercise
is an object of type <code>LinearRegressionModel</code>.
<a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegressionModel.html#pyspark.ml.regression.LinearRegressionModel" target="_true">Looking at the documentation</a>, we learn that there is a function <code>predict</code> that allows us to
make a prediction given a single instance.
If we want to make a prediction on the whole test set, we should use the function <code>transform</code>.
The function takes in a DataFrame with the test set and returns the same DataFrame with an additional column <code>prediction</code> that contains the predicted value.</p>
<div class="infobox exercisebox">
<p><strong>Exercise</strong></p>

<div class="exercise">
<p><span id="exr:unnamed-chunk-7" class="exercise"><strong>Exercise 2.4  </strong></span></p>
<ul>
<li><p>Look at Lines 130 and 131. Which DataFrame do we need to pass the function <code>transform</code>? Is <code>test_df</code> a good choice? Why?</p></li>
<li><p>Complete line 130 and uncomment lines 130, 131, 132.</p></li>
<li>Execute the file <code>train_test_model</code> with <code>spark-submit</code> and observe the result. Is the predicted value the one that you expect given that you
know the formula of the regression line?</li>
</ul>
</div>
</div>
</div>
<div id="pipelines" class="section level1">
<h1><span class="header-section-number">3</span> Pipelines</h1>
<p>In the previous section we learned that a training and test set need to go through the same transformation steps in
order to be fed to a machine learning model.
When we have few transformations, it is easy to remember the ones that we applied to a training set, so as to apply them to the
test set too.
However, when we need to apply a series of transformations, the order of which is important, it is easy to make mistakes (applying different sets of transformations
to the training and test instances, which leads to meaningless predictions).</p>
<p>A good practice is to use the <strong>Pipeline API</strong>.
A <strong>pipeline</strong> is composed of <strong>stages</strong>. Each stage may be a <strong>transformer</strong> or an <strong>estimator</strong>.
A <strong>transformer</strong> is an object on which we call the function <code>transform</code> to obtain a new DataFrame from an input DataFrame.
An <strong>estimator</strong> is an object on which we call the function <code>fit</code> to learn a model on a given DataFrame. The learned model is itself
a transformer.</p>
<p>When the function <code>fit</code> is called on a Pipeline, the training set goes through all the transformers and the estimators in the order in which they are declared in the pipeline;
at last, the estimator specified in the last stage is trained on the training set.
The model returned by applying the function <code>fit</code> on the pipeline is itself a transformer.
If we invoke the function <code>transform</code> on that model on the test set, we obtain a DataFrame that contains a column named <code>predictions</code>.
Implicitly, all the transformations in the pipeline will be applied to the test set too, before making the predictions.</p>
<p>Copy the file <code>pipeline_example.py</code> to your home folder in the cluster by typing the following command:</p>
<div align="center">
<pre><code>cp /usr/users/cpu-prof/cpu_quercini/mllib/pipeline_example.py .</code></pre>
</div>
<div class="infobox exercisebox">
<p><strong>Exercise</strong></p>

<div class="exercise">
<p><span id="exr:unnamed-chunk-8" class="exercise"><strong>Exercise 3.1  </strong></span>
<a href="https://spark.apache.org/docs/latest/ml-pipeline.html" target="_blank">Look at the documentation</a> and
write a code from Line 34 to create a pipeline that does the same operations as in file <code>train_test_model.py</code>
to train and test a linear regression model on the given training and test sets.</p>
<ul>
<li>Don’t forget to specify the paths to the training and test set files on HDFS at Lines 27 and 28.</li>
</ul>
</div>
</div>
<div id="from-categorical-to-numerical-features" class="section level2">
<h2><span class="header-section-number">3.1</span> From categorical to numerical features</h2>
<p>Many machine learning models do not handle categorical values: they need all features to be numerical.
Linear regression is such an example.</p>
<div class="infobox activitybox">
<p><strong>Activity</strong></p>
<ul>
<li>Copy the file <code>onehot_playground.py</code> to your home directory in the cluster by typing the following command:</li>
</ul>
<div align="center">
<pre><code>cp /usr/users/cpu-prof/cpu_quercini/mllib/onehot_playground.py .</code></pre>
</div>
<ul>
<li>Change lines 27 and 28 and write the paths to the files with the training and test sets.</li>
</ul>
</div>
<p>First, let’s find out which features are categorical in our dataset.</p>
<div class="infobox exercisebox">
<p><strong>Exercise</strong></p>

<div class="exercise">
<p><span id="exr:unnamed-chunk-9" class="exercise"><strong>Exercise 3.2  </strong></span>
Complete the function <code>get_categorical_columns</code>.</p>
<ul>
<li><p>In order to get an idea as to how to get the categorical columns, execute the code
with <code>spark_submit</code>. This execute the instruction at Line 86.</p></li>
<li><p>Once you’re done with the implementation, execute the file with <code>spark-submit</code> and observe the output.</p></li>
</ul>
</div>
</div>
<p>One example of categorical feature in our dataset is <code>property_type</code>, which takes values such as <em>Apartment</em>, <em>House</em>, <em>Condominium</em>…
Each value of a categorical feature is also referred to as a category.</p>
<p>One way to turn this feature into a numerical one would be to assign a number to each category (e.g., <em>Apartment</em> corresponds to 0, <em>House</em> to 1….).
However, this implicitly introduces an order among the categories: the category <em>House</em> would be worth twice as much as the category <em>Apartment</em>;
this would inevitably bias the trained model.</p>
<p>A commonly used method is <strong>one-hot encoding</strong>. Let’s find out how it works.
Let’s focus only on the feature <code>property_type</code>.</p>
<div class="infobox activitybox">
<p><strong>Activity</strong></p>
<ul>
<li><p>Uncomment Lines 40, 41 and 42. These lines instantiate an estimator that is called <code>StringIndexer</code>.
This estimator associates numeric indexes to the values of <code>property_type</code>. The indexes will be stored in another column
named <code>property_type_index</code>.</p></li>
<li><p>Uncomment Line 46. The <code>StringIndexer</code> is applied to the training set to learn how to associate indexes to the values of
<code>property_type</code>. The result of the instruction is a new transformer.</p></li>
<li><p>Uncomment Line 49. The transformer learned on Line 46 is used to transform the training set into a new DataFrame.
This DataFrame contains an additional column called <code>property_type_index</code>.</p></li>
</ul>
</div>
<div class="infobox exercisebox">
<p><strong>Exercise</strong></p>

<div class="exercise">
<p><span id="exr:unnamed-chunk-10" class="exercise"><strong>Exercise 3.3  </strong></span>
Complete the function <code>count_property_types</code>.
Follow the instructions in the file.</p>
<ul>
<li><p>Once the function is complete, uncomment Line 53 to call the function.</p></li>
<li><p>Execute the file with <code>spark-submit</code> and observe the output. Can you guess how the indexes are assigned to the categories
of the feature <code>property_type</code>?</p></li>
</ul>
</div>
</div>
<p>It is time to find out how one-hot encoding works.</p>
<div class="infobox activitybox">
<p><strong>Activity</strong></p>
<ul>
<li><p>Uncomment Lines 57, 58, 61, 64, 67. These lines instantiate an estimator that is called <code>OneHotEncoder</code>.
This estimator uses the indexes in <code>property_type_index</code> and creates a new column <code>property_type_ohe</code>.</p></li>
<li><p>The estimator is trained on the training set and a new transformer is obtained (line 61).</p></li>
<li><p>The transformer is used on the training set to transform it into a new DataFrame, where a new column <code>property_type_ohe</code> exists.</p></li>
<li><p>Line 67 prints selected columns of this transformed training set.</p></li>
</ul>
</div>
<div class="infobox exercisebox">
<p><strong>Exercise</strong></p>

<div class="exercise">
<p><span id="exr:unnamed-chunk-11" class="exercise"><strong>Exercise 3.4  </strong></span></p>
<ul>
<li><p>Execute the file with <code>spark-submit</code>.</p></li>
<li>Can you understand how one-hot encoding works?</li>
</ul>
</div>
</div>
<p>Now, you have all the ingredients to create a full pipeline to train and test a
linear regression model by using all features.</p>
<div class="infobox exercisebox">
<p><strong>Exercise</strong></p>

<div class="exercise">
<p><span id="exr:unnamed-chunk-12" class="exercise"><strong>Exercise 3.5  </strong></span>
Create a new file <code>full_pipeline.py</code> where:</p>
<ul>
<li><p>You select the categorical features.</p></li>
<li><p>Set up a <code>StringIndexer</code> and a <code>OneHotEncoder</code> to apply one-hot encoding to all categorical features.</p></li>
<li><p>Obtain the numeric features.</p></li>
<li><p>Set up a <code>VectorAssembler</code> to put into a single vector the one-hot encoded features and the numerical ones.</p></li>
<li><p>Set up a linear regression model that takes in all features and the variable to predict (<code>price</code>).</p></li>
<li><p>Mix all these ingredients in a <code>Pipeline</code>.</p></li>
<li>Use the <code>Pipeline</code> to train and test the model.</li>
</ul>
</div>
</div>
</div>
</div>
<div id="evaluating-a-model" class="section level1">
<h1><span class="header-section-number">4</span> Evaluating a model</h1>
<p>In the previous sections we visually looked at the predictions to get an vague idea of how our
estimator performs.
In order to quantify the quality of our estimator, we need some evaluation measures.</p>
<div class="infobox exercisebox">
<p><strong>Exercise</strong></p>

<div class="exercise">
<p><span id="exr:unnamed-chunk-13" class="exercise"><strong>Exercise 4.1  </strong></span>
<a href="https://spark.apache.org/docs/latest/ml-tuning.html#train-validation-split" target="_blank">Look at the documentation</a>
and play with the code to do model selection based on a grid search of parameters.</p>
</div>
</div>
</div>

          </div>

          



          
        </div>

        
      </article>

      

    </main>
  </div>
</div>


      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.1/anchor.min.js" integrity="sha256-pB/deHc9CGfFpJRjC43imB29Rse8tak+5eXqntO94ck=" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
    
    
    
    <script src="/js/academic.min.8741d44cdc5fc49466a5835d1bbea364.js"></script>

    






  
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
