<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Gianluca Quercini">

  
  
  
    
  
  <meta name="description" content="Tutorial Structured Streaming.">

  
  <link rel="alternate" hreflang="en-us" href="/courses/big-data-marseille/tutorials/spark-streaming/">

  


  
  
  
  <meta name="theme-color" content="rgb(0, 136, 204)">
  

  
  
  
  <script src="/js/mathjax-config.js"></script>
  


  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu68b06f59cdf252d86e7129a31e131766_426695_32x32_fill_lanczos_center_3.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu68b06f59cdf252d86e7129a31e131766_426695_192x192_fill_lanczos_center_3.png">

  <link rel="canonical" href="/courses/big-data-marseille/tutorials/spark-streaming/">

  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Gianluca Quercini">
  <meta property="og:url" content="/courses/big-data-marseille/tutorials/spark-streaming/">
  <meta property="og:title" content="Apache Spark — Structured Streaming | Gianluca Quercini">
  <meta property="og:description" content="Tutorial Structured Streaming."><meta property="og:image" content="img/map[gravatar:%!s(bool=true) shape:circle]">
  <meta property="twitter:image" content="img/map[gravatar:%!s(bool=true) shape:circle]"><meta property="og:locale" content="en-us">
  
    
    
  

  



  


  


  





  <title>Apache Spark — Structured Streaming | Gianluca Quercini</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Gianluca Quercini</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Gianluca Quercini</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#experience"><span>Experience</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#teaching"><span>Teaching</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      

      

      

    </ul>

  </div>
</nav>


  

  

<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      


<script src="/js/toggle-menu.js"></script>







  
    
  




<form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-3" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <span><i class="fas fa-bars"></i></span>
  </button>

  
</form>

<nav class="collapse docs-links" id="docs-nav">
  

  
  
  
  
  <div class="docs-toc-item">

    <a onclick=open_menu_on_click(this) id="overview" class="docs-toc-link" href="/courses/big-data-marseille/overview/">Overview</a>
    
    <div id="overview-ddowncontent" class="overview-ddowncontent ddowncontent">
    <ul class="nav docs-sidenav">
      
      
      <li class="overview">
        <a href="/courses/big-data-marseille/overview/">Big data</a>
      </li>
      
      
      <li class="overview">
        <a href="/courses/big-data-marseille/overview/installation-mongodb/">Installing MongoDB</a>
      </li>
      
      
      <li class="overview">
        <a href="/courses/big-data-marseille/overview/cluster-connection/">Connecting to the cluster</a>
      </li>
      
    </ul>
    </div>
    
    

  </div>
  
  <div class="docs-toc-item">

    <a onclick=open_menu_on_click(this) id="lectures" class="docs-toc-link" href="/courses/big-data-marseille/lectures/lectures/">Lectures</a>
    
    <div id="lectures-ddowncontent" class="lectures-ddowncontent ddowncontent">
    <ul class="nav docs-sidenav">
      
      
      <li class="lectures">
        <a href="/courses/big-data-marseille/lectures/lectures/">Overview</a>
      </li>
      
    </ul>
    </div>
    
    

  </div>
  
  <div class="docs-toc-item">

    <a onclick=open_menu_on_click(this) id="tutorials" class="docs-toc-link" href="/courses/big-data-marseille/tutorials/cc-tutorials/">Tutorials and labs</a>
    
    <div id="tutorials-ddowncontent" class="tutorials-ddowncontent ddowncontent">
    <ul class="nav docs-sidenav">
      
      
      <li class="tutorials">
        <a href="/courses/big-data-marseille/tutorials/cc-tutorials/">Overview</a>
      </li>
      
      
      <li class="tutorials">
        <a href="/courses/big-data-marseille/tutorials/map-reduce/">MapReduce</a>
      </li>
      
      
      <li class="tutorials">
        <a href="/courses/big-data-marseille/tutorials/spark-assignment/">Spark RDD</a>
      </li>
      
      <script>open_menu_on_load("tutorials".concat("-ddowncontent"))</script>
      <li class="active tutorials">
        <a href="/courses/big-data-marseille/tutorials/spark-streaming/">Structured Streaming</a>
      </li>
      
    </ul>
    </div>
    
    

  </div>
  
  <div class="docs-toc-item">

    <a onclick=open_menu_on_click(this) id="references" class="docs-toc-link" href="/courses/big-data-marseille/references/cc-references/">References</a>
    
    <div id="references-ddowncontent" class="references-ddowncontent ddowncontent">
    <ul class="nav docs-sidenav">
      
      
      <li class="references">
        <a href="/courses/big-data-marseille/references/cc-references/">Bibliography</a>
      </li>
      
    </ul>
    </div>
    
    

  </div>
  
  
</nav>

    </div>

    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article">

        <div class="docs-article-container">
          <div class="heading">Big data  — Tutorial 4</div>
          <h1>Apache Spark — Structured Streaming</h1>
          <hr>
          <div class="logo">
            <p><img src="/img/cs-logo.png" width="20%" style="display: block; margin: auto;" /></p>
            </div>

          <div class="article-style">
            


<p><link rel="stylesheet" href="/styles/course.css">
<link rel="stylesheet" href="/styles/cloud-computing.css"></p>
<!-- ############ IMPORTANT: CHANGE THESE VALUES BEFORE ANY LAB ############ -->
<!-- The link to the Edunao page where the students submit their work -->
<!-- The submission deadline -->
<!-- ############ END OF MODIFICATIONS ############ -->
<div id="introduction" class="section level1 unnumbered">
<h1>Introduction</h1>
<p>The goal of this lab assignment is to learn how to analyze streams of data with the Spark Structured Streaming API.
<a href="/courses/plp/overview/cluster-connection" target="_blank">Refer to this documentation</a> to learn how to connect and
interact with the cluster.</p>
<div class="infobox warning">
<p><strong>Documentation</strong></p>
<p>In order to answer the questions and do the exercises, you might want to refer to the following
documentation:</p>
<ul>
<li><p>The <a href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html" target="_blank">Structured Streaming programing guide</a>.</p></li>
<li><p>The <a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html" target="_blank">Spark SQL API reference</a>.</p></li>
</ul>
</div>
<!-- ############ IMPORTANT: CHANGE THESE VALUES BEFORE ANY LAB ############ -->
<!-- The group to which users in the cluster belong-->
<!-- User accounts are numbered from the lower to the upper limit-->
<!-- ############ END OF MODIFICATIONS ############ -->
</div>
<div id="warming-up" class="section level1">
<h1><span class="header-section-number">1</span> Warming up</h1>
<p>Consider the following program.</p>
<pre><code>from pyspark.sql import SparkSession
from pyspark.sql.types import *
import pyspark.sql.functions as F

port_number = COMPLETE HERE
checkpoint_location = COMPLETE HERE

spark = (SparkSession.builder.appName(&quot;Structured Streaming - exo1&quot;).getOrCreate())

lines = (spark\
        .readStream.format(&quot;socket&quot;)\
        .option(&quot;host&quot;, &quot;localhost&quot;)\
        .option(&quot;port&quot;, port_number)\
        .load())

streamingQuery = lines.writeStream\
                .option(&quot;checkpointLocation&quot;, checkpoint_location)\
                .format(&quot;console&quot;).start()

streamingQuery.awaitTermination()</code></pre>
<div class="infobox exercisebox">
<p><strong>Exercise</strong></p>

<div class="exercise">
<p><span id="exr:unnamed-chunk-1" class="exercise"><strong>Exercise 1.1  </strong></span></p>
<ol style="list-style-type: decimal">
<li><p>Where does this program get its input from?</p></li>
<li><p>What object type does the variable <code>lines</code> contain?</p></li>
<li><p>Where does this program write its output?</p></li>
<li><p>What is the output of this program?</p></li>
<li><p>What is the option <code>checkpointLocation</code> intended for?</p></li>
<li><p>What does the instruction <code>streamingQuery.awaitTermination()</code>?</p></li>
</ol>
</div>
</div>
<details>
<p><summary>Solution</summary></p>
<div class="infobox exosolution">
<ol style="list-style-type: decimal">
<li><p>The input is a socket, where a program generates some data.</p></li>
<li><p>lines is a <strong>dataframe</strong>.</p></li>
<li><p>To the console.</p></li>
<li><p>Just copies the input to the output.</p></li>
<li><p>It is where the Spark program writes the progress of the streaming query.</p></li>
<li><p>The instructions means that the program will block on this instruction. The program won’t stop until there is
data to process.</p></li>
</ol>
</div>
</details>
<p>You can now verify your answers to the previous questions by <strong>executing the program</strong>.</p>
<div class="infobox activitybox">
<p><strong>Activity</strong></p>
<ol style="list-style-type: decimal">
<li><p>Connect to the cluster, if you haven’t done so yet. <a href="/courses/plp/overview/cluster-connection" target="_blank">Refer to this documentation</a>.</p></li>
<li><p>After running the command <code>srun ...</code>, you should be connected to a machine on the cluster Kyle.
Note the name of this machine (you should see it at the terminal prompt).</p></li>
<li><p>Create a checkpoint directory for the first exercise (e.g., <code>checkpoint_exo1</code>) under your home directory
<code>hdfs://sar01:9000/cpuecm1/cpuecm1_X</code> <strong>in HDFS</strong>.</p></li>
<li>Copy and paste the code into a Python file (e.g., <code>exo1.py</code>) that you’ll save into your home directory <strong>in the local filesystem</strong>
of the cluster machine.
<ul>
<li>Change the value of the variable <code>checkpoint_location</code> so that it points to the directory that you created at point 3.</li>
<li>Change the value of the variable <code>port_number</code> to any value in the range [49152, 65535].</li>
</ul></li>
<li><p>Open a new terminal window, connect to <code>phome.metz.supelec.fr</code> and then to the same machine that you noted at point 2.</p></li>
<li><p>In the new terminal, start a <strong>netcat server</strong> listening on the port number that you selected at point 4. Use the following command:</p></li>
</ol>
<pre class="bash"><code>nc -lk port_number</code></pre>
<ol start="7" style="list-style-type: decimal">
<li>Run the Python code with the command <code>spark-submit</code>. Wait until Spark does not display any more messages on screen.
<ul>
<li>In case the program stops for an error, read the box “What to do in case of errors” below.</li>
</ul></li>
<li>In the netcat terminal, write few lines of text. Look at the terminal where the Spark program is running and observe the output.</li>
</ol>
</div>
<div class="infobox warning">
<p><strong>What to do in case of errors</strong></p>
<p>If any error arises, <strong>before</strong> running the <code>spark-submit</code> again it would be better to remove
all files from the checkpoint directory.</p>
</div>
<div class="infobox warning">
<p><strong>Stop the program</strong></p>
<ul>
<li><p>When you’re done with your experiments, you can stop the Spark program by simply
typing CTRL-C in the terminal where Spark is running.</p></li>
<li><p>Don’t stop the netcat server, you’ll need it in the next exercise.</p></li>
<li><p><strong>Remove all files</strong> from the checkpoint location.</p></li>
</ul>
</div>
</div>
<div id="triggering-policy" class="section level1">
<h1><span class="header-section-number">2</span> Triggering policy</h1>
<p>In a Structured Streaming program we can choose a <strong>triggering policy</strong>.</p>
<div class="infobox exercisebox">
<p><strong>Exercise</strong></p>

<div class="exercise">
<p><span id="exr:unnamed-chunk-3" class="exercise"><strong>Exercise 2.1  </strong></span></p>
<ol style="list-style-type: decimal">
<li><p>What is a triggering policy?</p></li>
<li><p>What is the triggering policy in the previous program?</p></li>
<li><p>Modify the code of the previous program in order to set the
<code>Fixed interval micro-batch</code> triggering policy.</p></li>
<li><p>Run the program. How is the behaviour of this program different from before?</p></li>
</ol>
</div>
</div>
<details>
<p><summary>Solution</summary></p>
<div class="infobox exosolution">
<ol style="list-style-type: decimal">
<li><p>It is a policy that dictates the timing of streaming data processing.</p></li>
<li><p>No triggering policy is specified, so the default is chosen.
In practice, as soon as the previous micro-batch finishes processing, the next one is read in.</p></li>
<li><p>Here is the code. We need to specify a `<code>trigger</code>.</p></li>
</ol>
<pre><code>streamingQuery = lines.writeStream
            .trigger(processingTime = &quot;15 seconds&quot;)
            .format(&quot;console&quot;).start()</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>The new data is checked at the specified interval.
It is possible that within the specified interval (15 seconds), we write
many lines, so the program will get multiple lines in a micro-batch (unlike before, when
the processing is triggered as soon as there is data available).</li>
</ol>
</div>
</details>
</div>
<div id="checkpoint-location-and-output-mode" class="section level1">
<h1><span class="header-section-number">3</span> Checkpoint location and output mode</h1>
<p>We’re now going to see the impact of the checkpoint location and the output modes on a streaming query.</p>
<div class="infobox exercisebox">
<p><strong>Exercise</strong></p>

<div class="exercise">
<p><span id="exr:unnamed-chunk-4" class="exercise"><strong>Exercise 3.1  </strong></span></p>
<ol style="list-style-type: decimal">
<li><p>What is an output mode and what are the available options?</p></li>
<li>What is the output mode of the previous program?</li>
</ol>
</div>
</div>
<details>
<p><summary>Solution</summary></p>
<div class="infobox exosolution">
<ol style="list-style-type: decimal">
<li><p>The output mode tells Spark how the output is presented.
There are several options: append (only the new rows added to the Result Table since the last trigger are visible in the output),
complete (the whole Result Table is visible after each trigger) and update (only the rows that were updated since the last trigger are visible in the
output).</p></li>
<li>In the previous program we didn’t specify any output mode, so the default mode (append) is selected.</li>
</ol>
</div>
</details>
<p>We’re now going to write a new streaming query.</p>
<div class="infobox exercisebox">
<p><strong>Exercise</strong></p>

<div class="exercise">
<p><span id="exr:unnamed-chunk-5" class="exercise"><strong>Exercise 3.2  </strong></span></p>
<ol style="list-style-type: decimal">
<li><p>Create a new checkpoint location in HDFS.
You may also keep the same directory as before; in this case, make sure you <strong>remove all files</strong> from that
directory.</p></li>
<li><p>Write a new program that reads a streaming text from a TCP socket and
counts the number of occurrences of each word.</p></li>
<li><p>Which output mode are you going to choose and why?</p></li>
<li><p>Run the program. Write few lines on the netcat server and observe the output.</p></li>
<li><p>Stop the program and run it again with no modifications. Write few lines in the netcat terminal and observe the output.
What can you say about the word counts?</p></li>
<li><p>Stop the program and remove the files in the checkpoint location. Run the program again and write few lines
on the netcat terminal. What can you say about the word counts?</p></li>
<li><p>Play with the different output modes and observe how the output changes.</p></li>
</ol>
</div>
</div>
<details>
<p><summary>Solution</summary></p>
<div class="infobox exosolution">
<p>The new program is as follows:</p>
<pre class="{python}"><code>lines = (spark\
        .readStream.format(&quot;socket&quot;)\
        .option(&quot;host&quot;, &quot;localhost&quot;)\
        .option(&quot;port&quot;, port_number)\
        .load())

lines = lines.select(F.explode(F.split(lines.value, &quot; &quot;))\
                     .alias(&quot;word&quot;))\
                     .groupBy(&quot;word&quot;).count()


streamingQuery = lines.writeStream\
            .trigger(processingTime = &quot;15 seconds&quot;)\
            .option(&quot;checkpointLocation&quot;, checkpoint_location)\
            .outputMode(&quot;update&quot;)\
            .format(&quot;console&quot;)\
            .start()

streamingQuery.awaitTermination()</code></pre>
<p>The append mode doesn’t work, because aggregating function might modify previous lines of the ResultTable.
So, the only options left are update and complete. We choose update to just have the values that changed since the last trigger.</p>
</div>
</details>
</div>
<div id="window-operations-on-event-time" class="section level1">
<h1><span class="header-section-number">4</span> Window operations on event time</h1>
<div class="infobox warning">
<p><strong>Netcat and checkpoint</strong></p>
<ol style="list-style-type: decimal">
<li><p>You can stop the netcat server now.</p></li>
<li><p>Remember to create a new checkpoint location for this exercise.
Alternatively, you can also use the same directory as in the previous exercises, but
you should remove all its files.</p></li>
</ol>
</div>
<p>We’re now going to find out how to perform aggregations over a sliding event-time window.</p>
<p>A given data source generates some words for a certain time interval.
Each word is accompanied with a timestamp that indicates the exact moment when the word is
generated. This timestamp is the <strong>event time</strong>.</p>
<p>After generating a word, the data source saves the word and its timestamp into
a CSV file in a directory on HDFS.
For convenience, we’ll refer to this directory as the <strong>source directory</strong>.</p>
<div class="infobox activitybox">
<p><strong>Activity</strong></p>
<p>Create the source directory under your home directory
<code>hdfs://sar01:9000/cpuecm1/cpuecm1_X</code> <strong>in HDFS</strong>.</p>
</div>
<p>At any given moment, the source will contain zero to many CSV files,
where each file only contains exactly one line in the format
<code>word,timestamp</code> (no whitespace before nor after the comma).</p>
<div class="infobox exercisebox">
<p><strong>Exercise</strong></p>

<div class="exercise">
<p><span id="exr:unnamed-chunk-6" class="exercise"><strong>Exercise 4.1  </strong></span></p>
<p>Write a Spark program that:</p>
<ol style="list-style-type: decimal">
<li><p>Reads the stream of data from the source directory.</p></li>
<li><p>Counts the number of occurrences of each word within 10 minute windows that slide every 5 minutes.</p></li>
<li>Print the output counts to the console. Use triggers of 5 seconds.</li>
</ol>
</div>
</div>
<details>
<p><summary>Solution</summary></p>
<div class="infobox exosolution">
<p>The new program is as follows:</p>
<pre class="{python}"><code>
source_directory = hdfs://....

words = (spark
        .readStream.format(&quot;csv&quot;)
        .schema(&quot;word STRING, timestamp TIMESTAMP&quot;)
        .load(source_directory))


windowedCount = words.groupBy(F.window(words.timestamp, 
                &quot;10 seconds&quot;, &quot;5 seconds&quot;, startTime=0), words.word).count()

windowedQuery = windowedCount.withColumn(&quot;trigger_timestamp&quot;, F.expr(&quot;get_current_timestamp()&quot;)).writeStream\
            .trigger(processingTime=&quot;5 seconds&quot;)\
            .outputMode(&quot;update&quot;)\
            .format(&quot;console&quot;)\
            .option(&quot;truncate&quot;, False)\
            .start()

streamingQuery.awaitTermination()</code></pre>
</div>
</details>
<p>We now test the new Spark program.</p>
<div class="infobox warning">
<p><strong>Data source and timeline visualization</strong></p>
<p>We provide two Python programs for this exercise: a data generator and
a tool for visualizing words in a timeline. Instructions to get and run
these two programs are given in the activity below.</p>
<p>The <strong>data generator</strong> is our data source.
It generates two words every second for a certain
amount of time.
Each word is saved in a separate CSV file in source directory.
It also saves the list of all generated
words to a summary CSV file.</p>
<p>The <strong>visualization tool</strong> takes as its input the summary CSV file
written by the data generator and visualizes the words
on a timeline.</p>
</div>
<div class="infobox activitybox">
<p><strong>Activity</strong></p>
<ol style="list-style-type: decimal">
<li>Copy to your home directory
in the local filesystem
the data generator that you find at the following path</li>
</ol>
<pre class="bash"><code>/usr/users/cpu-prof/cpu_quercini/structured-streaming/tempws_gen.py</code></pre>
<ol start="2" style="list-style-type: decimal">
<li><p>Start your Spark program. When running the first time, you might get some errors. Correct your code accordingly.</p></li>
<li><p>In another terminal, run the Python script <code>tempws_gen.py</code>. Use the
following command to learn how to run this program:</p></li>
</ol>
<pre class="bash"><code>python3 tempws_gen.py --help</code></pre>
<p>For this exercise, do not introduce any delay
(keep the default values of the parameters <code>--delay</code>, <code>--mindelay</code>, <code>--maxdelay</code>).</p>
<ol start="4" style="list-style-type: decimal">
<li><p>After launching the data generator, you should
see some output in the terminal where you launched the Spark program.
<strong>Wait for the script <code>tempws_gen.py</code> to terminate the data generation</strong>.
The output might be a bit overwhelming. Scroll up to identify the results
on each micro-batch.</p></li>
<li><p>If you need to rerun the Spark program and the data generator, make sure you delete all the files in the
checkpoint location and the source directory.</p></li>
</ol>
</div>
<p>We now want to analyze the output of the program.</p>
<ul>
<li><p>The script <code>tempws_gen.py</code> has generated
a file <code>gen_words.csv</code> in your home directory.
This file contains the list of all words generated with the relative timestamps.
<strong>Download the file to your computer</strong>.</p></li>
<li><p>Download the visualization tool that you find at the following path:</p></li>
</ul>
<pre class="bash"><code>/usr/users/cpu-prof/cpu_quercini/structured-streaming/timeline_visualization.py</code></pre>
<p>to your computer.</p>
<div class="infobox warning">
<p><strong>Visualization tool</strong></p>
<p>Use the following command to learn how to run the visualization tool:</p>
<pre class="bash"><code>python timeline_visualization.py --help</code></pre>
<p>The visualization tool displays a vertical blue bar at each trigger.
To this purpose, you’ll need to pass the tool the timestamps associated to the first
and last trigger and the interval (in seconds) between two consecutive triggers.</p>
<p>You can get the timestamps associated to the first and last trigger by analyzing the output of Spark.
More specifically, for each micro-batch, Spark outputs the progress details of the streaming query; you’ll need
to look at the timestamp associated to the first and last micro-batch.</p>
</div>
<div class="infobox exercisebox">
<p><strong>Exercise</strong></p>

<div class="exercise">
<p><span id="exr:unnamed-chunk-11" class="exercise"><strong>Exercise 4.2  </strong></span></p>
<ol style="list-style-type: decimal">
<li><p>Analyze the output of your Spark program and the timeline of the generated words.</p></li>
<li>Describe how the counts are updated by the Spark program.</li>
</ol>
</div>
</div>
<details>
<p><summary>Solution</summary></p>
<div class="infobox exosolution">
<p>Unlike the previous exercise, here the number of occurrences of each word is counted based on a
time window of 10 seconds that slides every 5 seconds.
Each word is associated with an <strong>event time</strong> that is used to compute the number of occurrences.
The time window starts from the first trigger, say at 12:00.
If a word arrives at 12:07, the count associated to this word are updated in two
time windows, 12:00 - 12:10 and 12:05 - 12:15.</p>
</div>
</details>
</div>

          </div>

          



          
        </div>

        
      </article>

      

    </main>
  </div>
</div>


      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.1/anchor.min.js" integrity="sha256-pB/deHc9CGfFpJRjC43imB29Rse8tak+5eXqntO94ck=" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
    
    
    
    <script src="/js/academic.min.8741d44cdc5fc49466a5835d1bbea364.js"></script>

    






  
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
