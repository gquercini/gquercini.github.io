<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Courses | Gianluca Quercini</title>
    <link>/courses/</link>
      <atom:link href="/courses/index.xml" rel="self" type="application/rss+xml" />
    <description>Courses</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language>
    <image>
      <url>img/map[gravatar:%!s(bool=true) shape:circle]</url>
      <title>Courses</title>
      <link>/courses/</link>
    </image>
    
    <item>
      <title>Tutorials</title>
      <link>/courses/cloud-computing/tutorials/cc-tutorials/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/cloud-computing/tutorials/cc-tutorials/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;div id=&#34;tutorial-1&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tutorial 1&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Getting started with Docker&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Supervisors&lt;/strong&gt;: Francesca Bugiotti, Gianluca Quercini, Arpad Rimmel, Idir Ait Sadoune, Marc-Antoine Weisser&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Thursday 22 April, 8:30 AM - 11:45 AM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Room&lt;/strong&gt;: Remotely on Microsoft Teams&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;: &lt;a href=&#34;/courses/cloud-computing/tutorials/tutorial-docker&#34;&gt;Click here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tutorial-2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tutorial 2&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Introduction to Kubernetes&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Supervisors&lt;/strong&gt;: Francesca Bugiotti, Gianluca Quercini, Arpad Rimmel, Idir Ait Sadoune, Marc-Antoine Weisser&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Thursday 6 May, 8:30 AM - 11:45 AM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Room&lt;/strong&gt;: Remotely on Microsoft Teams&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;: &lt;a href=&#34;/courses/cloud-computing/tutorials/tutorial-kube&#34;&gt;Click here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tutorial-3&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tutorial 3&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Introduction to Kubernetes&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Supervisors&lt;/strong&gt;: Francesca Bugiotti, Gianluca Quercini, Arpad Rimmel, Idir Ait Sadoune, Marc-Antoine Weisser&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Friday 21 May, 1:45 AM - 5 PM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Room&lt;/strong&gt;: Remotely on Microsoft Teams&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;: Available soon&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Tutorials</title>
      <link>/courses/databases/tutorials/cc-tutorials/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/databases/tutorials/cc-tutorials/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;div id=&#34;tutorial-1&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tutorial 1&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Data modeling&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Tuesday 15 September 2020, 10:30 AM - 12 PM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;: &lt;a href=&#34;/courses/databases/tutorials/data-modeling&#34;&gt;Click here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tutorial-2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tutorial 2&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Normalization&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Tuesday 29 September 2020, 10:30 AM - 12 PM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;: &lt;a href=&#34;/courses/databases/tutorials/normalization&#34;&gt;Click here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tutorial-3&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tutorial 3&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: SQL queries&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Tuesday 6 October 2020, 10:30 AM - 12 PM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;: &lt;a href=&#34;/courses/databases/tutorials/sql&#34;&gt;Click here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tutorial-4&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tutorial 4&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: SQLite in action&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Tuesday 13 October 2020, 10:30 AM - 12 PM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;: &lt;a href=&#34;/courses/databases/tutorials/sqlite&#34;&gt;Click here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tutorial-5&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tutorial 5&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Document-based databases: MongoDB.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Tuesday 3 November 2020, 10 AM - 12 AM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;: &lt;a href=&#34;/courses/databases/tutorials/mongodb&#34;&gt;Click here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tutorial-6&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tutorial 6&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Graph databases: Neo4j.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Tuesday 10 November 2020, 10 AM - 12 AM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;: available soon.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Tutorials and lab assignments</title>
      <link>/courses/big-data-marseille/tutorials/cc-tutorials/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/big-data-marseille/tutorials/cc-tutorials/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;div id=&#34;tutorial-1&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tutorial 1&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: MapReduce programming&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Monday 3 May 2021&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;: &lt;a href=&#34;/courses/big-data-marseille/tutorials/map-reduce&#34; target=&#34;_blank&#34;&gt;Click here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tutorial-2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tutorial 2&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Introduction to Spark programming&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Wednesday 5 May 2021&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;: &lt;a href=&#34;https://colab.research.google.com/drive/18NN1O6tu3FJdpAmv8AAOBw2ON689_pwZ?usp=sharing&#34; target=&#34;_blank&#34;&gt;Click here&lt;/a&gt;&lt;/p&gt;
&lt;!-- **Link**: [Click here](https://colab.research.google.com/drive/1qBLJrQZGum4A5m4RrofLq-KRXYug4HQM?usp=sharing)

**Link to the data**: [Click here](/courses/plp/tutorials/data.tgz)

**Link to the data**: [Click here](/courses/plp/tutorials/moviesEmbedded.json)--&gt;
&lt;/div&gt;
&lt;div id=&#34;tutorial-3&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tutorial 3&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Introduction to DataFrames and SparkSQL&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Monday 10 May 2021&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lab-assignment-1&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lab assignment 1&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Apache Spark programming&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Wednesday 12 May 2021&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tutorial-4&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tutorial 4&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Apache Structured Streaming&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Wednesday 12 May 2021&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lab-assignment-2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lab assignment 2&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: MongoDB&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Wednesday 19 May 2021&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;:&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Tutorials and lab assignments</title>
      <link>/courses/plp/tutorials/cc-tutorials/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/plp/tutorials/cc-tutorials/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;div id=&#34;tutorial-1&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tutorial 1&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: MapReduce programming&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Monday 4 January 2021, 3.30 PM - 5 PM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;: &lt;a href=&#34;/courses/plp/tutorials/map-reduce&#34; target=&#34;_blank&#34;&gt;Click here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tutorial-2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tutorial 2&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: MapReduce programming in Python&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Wednesday 6 January 2021, 10:15 AM - 11:45 AM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;: &lt;a href=&#34;https://colab.research.google.com/drive/1W8kyQmEpxiwoP66WG6ZQtNRfQwQQVqSI?usp=sharing&#34; target=&#34;_blank&#34;&gt;Click here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tutorial-3&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tutorial 3&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Introduction to Spark programming&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Thursday 7 January 2021, 10:15 AM - 11:45 AM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;: &lt;a href=&#34;https://colab.research.google.com/drive/1hQ6h_tNPNnzoAN-s7WI_K9tzoZjgIxzS?usp=sharing&#34; target=&#34;_blank&#34;&gt;Click here&lt;/a&gt;&lt;/p&gt;
&lt;!-- **Link**: [Click here](https://colab.research.google.com/drive/1qBLJrQZGum4A5m4RrofLq-KRXYug4HQM?usp=sharing)

**Link to the data**: [Click here](/courses/plp/tutorials/data.tgz)

**Link to the data**: [Click here](/courses/plp/tutorials/moviesEmbedded.json)--&gt;
&lt;/div&gt;
&lt;div id=&#34;tutorial-4&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tutorial 4&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Spark programming using a Spark cluster.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Thursday 7 January 2021, 1:45 PM - 5 PM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;: &lt;a href=&#34;/courses/plp/tutorials/spark-programming-dce&#34; target=&#34;_blank&#34;&gt;Click here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lab-assignment-1&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lab assignment 1&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Advanced Spark programming&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Monday 11 January 2021, 10:15 AM - 11.45 AM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;: &lt;a href=&#34;/courses/plp/tutorials/spark-lab-assignment&#34; target=&#34;_blank&#34;&gt;Click here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lab-assignment-2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lab assignment 2&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: MongoDB&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Thursday 21 January 2021, 10:15 AM - 11.45 AM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;: &lt;a href=&#34;/courses/plp/tutorials/mongodb-tutorial&#34; target=&#34;_blank&#34;&gt;Click here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tutorial-5&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tutorial 5&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Neo4j&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Thursday 28 January 2021, 10:15 AM - 11:45 AM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;: &lt;a href=&#34;/courses/plp/tutorials/neo4j-tutorial&#34; target=&#34;_blank&#34;&gt;Click here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Lab assignments</title>
      <link>/courses/cloud-computing/labs/cc-labs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/cloud-computing/labs/cc-labs/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Both lab assignments will be graded.&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;lab-assignment-1&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lab assignment 1&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Multi-service applications in the Cloud&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Supervisors&lt;/strong&gt;: Francesca Bugiotti Gianluca Quercini, Arpad Rimmel, Idir Ait Sadoune, Marc-Antoine Weisser&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Friday 7 May, 1:45 PM - 5 PM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Room&lt;/strong&gt;: On Microsoft Teams&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;: &lt;a href=&#34;/courses/cloud-computing/labs/kube-lab&#34;&gt;Click here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lab-assignment-2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lab assignment 2&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: MapReduce - Apache Spark&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Supervisors&lt;/strong&gt;: Francesca Bugiotti Gianluca Quercini, Arpad Rimmel, Idir Ait Sadoune, Marc-Antoine Weisser&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Friday 28 May, 1:45 PM - 5 PM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Room&lt;/strong&gt;: Remotely on Microsoft Teams&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Link&lt;/strong&gt;: available soon&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Lectures</title>
      <link>/courses/cloud-computing/lectures/lectures/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/cloud-computing/lectures/lectures/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;div id=&#34;lecture-1&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 1&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Introduction to Cloud Computing&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lecturer&lt;/strong&gt;: Gianluca Quercini&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Wednesday 14 April, 8:30 AM - 11:45 AM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Room&lt;/strong&gt;: Remotely on Microsoft Teams&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: Available on &lt;a href=&#34;https://centralesupelec.edunao.com/mod/resource/view.php?id=50327&#34; target=&#34;_blank&#34;&gt;Edunao&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 2&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Virtualization and Containerization&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lecturer&lt;/strong&gt;: Gianluca Quercini (CentraleSupélec)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Friday 16 April, 1:45 PM - 5 PM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Room&lt;/strong&gt;: Remotely on Microsoft Teams&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: Available on &lt;a href=&#34;https://centralesupelec.edunao.com/mod/resource/view.php?id=50468&#34; target=&#34;_blank&#34;&gt;Edunao&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-3&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 3&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Multi-service applications and orchestration&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lecturer&lt;/strong&gt;: Gianluca Quercini (CentraleSupélec)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Friday 23 April, 1:45 PM - 5:00 PM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Room&lt;/strong&gt;: Remotely on Microsoft Teams&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: Available on &lt;a href=&#34;https://centralesupelec.edunao.com/mod/resource/view.php?id=50689&#34; target=&#34;_blank&#34;&gt;Edunao&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-4&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 4&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Apache Spark&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lecturer&lt;/strong&gt;: Francesca Bugiotti (CentraleSupélec)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Friday 14 May, 1:45 PM - 5:00 PM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Room&lt;/strong&gt;: Remotely on Microsoft Teams&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: Available soon&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-5&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 5&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Apache Spark&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lecturer&lt;/strong&gt;: Francesca Bugiotti (CentraleSupélec)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Tuesday 18 May, 8:30 AM - 11:45 AM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Room&lt;/strong&gt;: Remotely on Microsoft Teams&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: Available soon&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-6&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 6&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Arrow - Spark + Argo&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lecturer&lt;/strong&gt;: Francesca Bugiotti (CentraleSupélec)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Wednesday 26 May, 8:30 AM - 11:45 AM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Room&lt;/strong&gt;: Remotely on Microsoft Teams&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: Available soon&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>References</title>
      <link>/courses/cloud-computing/references/cc-references/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/cloud-computing/references/cc-references/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;div id=&#34;class-material&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Class material&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Lecture slides, available &lt;a href=&#34;/courses/cloud-computing/lectures&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;An &lt;a href=&#34;/courses/cloud-computing/references/docker-primer&#34;&gt;introduction to Docker&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A &lt;a href=&#34;/courses/cloud-computing/references/docker-cheat-sheet&#34;&gt;Docker cheat sheet&lt;/a&gt;, with a summary of
the most important Docker commands.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;An &lt;a href=&#34;/courses/cloud-computing/references/linux-introduction&#34;&gt;introduction to Linux&lt;/a&gt;, useful to
understand how Docker works and how to interact with Docker.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;books&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Books&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Schenker, Gabriel. Learn Docker - &lt;em&gt;Fundamentals of Docker 18.x.&lt;/em&gt; Packt Publishing,. Print.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Surianarayanan, C., &amp;amp; Chelliah, P. R. (2019). &lt;em&gt;Essentials of Cloud Computing: A Holistic Perspective.&lt;/em&gt; Springer Nature.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Description</title>
      <link>/courses/databases/exam/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/databases/exam/project/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;The goal of this project is
to assess your knowledge of the main
notions presented in classroom.&lt;/p&gt;
&lt;p&gt;The project must be implemented by students &lt;strong&gt;working in groups&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Creating the groups&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://centralesupelec.edunao.com/mod/choicegroup/view.php?id=37046&#34; target=&#34;_blank&#34;&gt;Click here&lt;/a&gt;
to create your group.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This project consists in designing a relational database
for the given application context,
importing the data of a given dataset into a SQLite database and querying the data in SQL.&lt;/p&gt;
&lt;p&gt;The deadline to submit the work is &lt;strong&gt;Friday December 11th&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Submit your project&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Create a .zip archive with the required files and
&lt;a href=&#34;https://centralesupelec.edunao.com/mod/assign/view.php?id=37047&#34; target=&#34;_blank&#34;&gt;click here&lt;/a&gt;
to submit it.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Here is what you have to submit:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;A &lt;strong&gt;report in PDF&lt;/strong&gt; containing the answers to
all the questions and exercises, &lt;strong&gt;except the SQL queries&lt;/strong&gt; (max 10 pages).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A file .db containing the SQLite database with &lt;strong&gt;all the data&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A file .sql with &lt;strong&gt;all the SQL queries&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;application-context&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Application context&lt;/h1&gt;
&lt;p&gt;We intend to manage the data of a travel reservation system
with clients all over the world.
Upon registration, customers are automatically given a numeric identifier
and they are asked to indicate their first and family names, their gender,
date of birth, a phone number, an email address and their country of residence.&lt;/p&gt;
&lt;p&gt;Any customer can book a trip that includes
the reservation of &lt;strong&gt;one or more flights&lt;/strong&gt; and, possibly, &lt;strong&gt;one or more hotels&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Alice wants to fly from Paris,
France to New York City (NYC), USA
and she intends to stay in NYC for 10 days.
Her trip includes two flights: an outbound flight
from Paris to NYC and an inbound flight from NYC to Paris; and an hotel in NYC.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;A flight is operated by an airline company,
of which the system keeps its name (e.g., British Airways),
the country where the airline is incorporated and, when available,
its IATA code (e.g., BA, a two-letter code identifying the airline),
its ICAO code (e.g., BAW, a three-letter code identifying the airline)
and alternate name or alias (e.g., British).&lt;/p&gt;
&lt;p&gt;A flight connects two airports,
each having a name (e.g., London Heathrow Airport), and,
possibly, a IATA (e.g., LHR) and ICAO code (e.g., EGLL);
an airport serves a specific location (e.g., London, UK) and its precise position
is given by its geographic coordinates (latitude and longitude).&lt;/p&gt;
&lt;p&gt;A flight connecting two airports at specific departure and arrival times
is identified by a flight number.
Two flights operated by two different airline companies cannot have the same flight number,
but the same flight number can denote two flights operated
by the same airline company on different days.&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Emirates flight EK074 leaves Paris,
France at 10 AM and arrives at Dubai, UAE at 7:40 PM (regardless of the departure day).&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;For each flight booked by a customer,
the system keeps the seat number,
the travel class (e.g., economy or business),
the price and the date of the flight.
Usually, airlines include details on the type of aircraft
they plan to use on their flight schedules;
these details include the name of the aircraft (e.g., Boeing 787-8) and,
when available, the IATA code (e.g., 788, a unique three-letter identifier for the aircraft)
and the ICAO code (e.g., B788, a unique four-letter identifier for the aircraft).&lt;/p&gt;
&lt;p&gt;The system maintains a list of hotels,
with their names, addresses and an average review score,
which is a real number denoting the average grade assigned to
the hotel by its customers.
Customers can write a review for an hotel;
in which case the system stores the text of the review,
the date and its author.
When a customer books an hotel, the system keeps the price paid,
the check-in and check-out dates and whether the breakfast is included.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-dataset&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The dataset&lt;/h1&gt;
&lt;p&gt;You can download the dataset by clicking &lt;a href=&#34;/courses/databases/dataset.zip&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.
The dataset consists of 7 CSV files:
&lt;em&gt;aircrafts.csv&lt;/em&gt;, &lt;em&gt;airlines.csv&lt;/em&gt;, &lt;em&gt;airports.csv&lt;/em&gt;,
&lt;em&gt;hotels.csv&lt;/em&gt;, &lt;em&gt;customers.csv&lt;/em&gt;,
&lt;em&gt;hotel_bookings.csv&lt;/em&gt;, &lt;em&gt;flight_bookings.csv&lt;/em&gt;.
The separator character in each file is the tab character (‘’).&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Notice&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Take some time to look at the content
of the files to understand the structure that your tables will have.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;creation-of-a-relational-database&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Creation of a relational database&lt;/h1&gt;
&lt;p&gt;You’ll now proceed to the definition of a relational database for our travel reservation system.
First, you need to define the &lt;strong&gt;conceptual schema&lt;/strong&gt;
and then you’ll define the tables that compose the database.&lt;/p&gt;
&lt;div id=&#34;the-conceptual-schema&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The conceptual schema&lt;/h2&gt;
&lt;p&gt;Before defining the logical schema of the database, &lt;strong&gt;answer the following questions&lt;/strong&gt;:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;p&gt;Can you use the name of the hotel as a primary key? Justify your answer.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Can you use the flight number as a primary key to identify a flight?
Justify your answer and, in case of a negative answer, propose a solution.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Knowing that it is unlikely that two reviews have the same textual content,
would you use it as a primary key? Justify your answer.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Knowing that the IATA code uniquely identifies an airport,
would you choose it as a primary key for the entity Airport? Justify your answer.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-1&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1  &lt;/strong&gt;&lt;/span&gt;
Propose an Entity-Relationship diagram describing the conceptual
model of a relational database for the given application context.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Specify all the attributes for each entity and relation.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For each entity, underline the attributes composing the primary key.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;For each relation, clearly indicate the minimum and maximum cardinality.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;normalization&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Normalization&lt;/h2&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-2&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2  &lt;/strong&gt;&lt;/span&gt;
Translate the logical schema into a collection of tables. For each table:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Indicate its name and the names of the columns (but not their types).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Underline the columns that are part of the primary key.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Indicate the entity in the ER diagram to which the table corresponds.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To make sure you choose the right data types for the columns,
you can also check the values in the dataset.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Which &lt;strong&gt;normal form&lt;/strong&gt; are your tables in?&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-3&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3  &lt;/strong&gt;&lt;/span&gt;
For each table:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Indicate a &lt;strong&gt;minimal set of functional dependencies&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Indicate the normal form that the table satisfies. Justify your answer.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Normalize&lt;/strong&gt; your tables.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-4&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4  &lt;/strong&gt;&lt;/span&gt;
Normalize each table up to the &lt;strong&gt;Boyce-Codd Normal Form (BCNF)&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;the-physical-schema&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The physical schema&lt;/h2&gt;
&lt;p&gt;You can now define the &lt;strong&gt;physical schema&lt;/strong&gt; of your database.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-5&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 5  &lt;/strong&gt;&lt;/span&gt;
Write the SQL code to create the tables. For each table:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Indicate the &lt;strong&gt;primary key&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Indicate the &lt;strong&gt;foreign keys&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Indicate NOT NULL and UNIQUE constraints, if needed.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;database-creation-and-data-import&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Database creation and data import&lt;/h2&gt;
&lt;p&gt;In order to create a database in SQLite,
use DB Browser for SQLite:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Open the program and click on &lt;strong&gt;New Database&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The program will ask you to specify a name for
the database file and the folder where you want to store it.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The program will display a pop-up window where you can create the tables. Alternatively, you can directly
execute the SQL code that you wrote before to create your tables.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-6&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 6  &lt;/strong&gt;&lt;/span&gt;
Create a SQLite database with the tables that you defined in
the previous exercise.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;In order to import the data into a table, you can
select File &lt;span class=&#34;math inline&#34;&gt;\(\rightarrow\)&lt;/span&gt; Import &lt;span class=&#34;math inline&#34;&gt;\(\rightarrow\)&lt;/span&gt; Table from CSV file.
The given CSV file might not correspond exactly to the tables that
you created, so you’ll need to edit them a bit in order to fit
the schema of your tables.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;running-queries&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Running queries&lt;/h2&gt;
&lt;p&gt;Write the following queries in SQL.&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Notice&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You’ll write your queries in a file &lt;em&gt;queries.sql&lt;/em&gt; that you’ll submit
with your project.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Only write the queries without any comment&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Please separate each query in the file by a &lt;strong&gt;blank line&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SELECT *
FROM Airport 

SELECT *
FROM Hotel &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-7&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 7  &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Get the average ticket price on Air France flights.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Count the number of customers by country.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select the names of the airports in Paris, France.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select the name of the cities (city and country name) with the most airports.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select the name of the airline companies that use an Airbus A300.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select the identifier, first and family names of all customers who flew to Sydney, Australia.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select the identifier, name, city and country of the busiest airport (the one with more outbound and inbound flights).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select the average price in the economy class.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select the average price in the business class.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select the name, city and country of the destination airport of french customers.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select the destination cities (specify city and country name) preferred by women.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select the destination cities (specify city and country name) preferred by men.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Count the number of customers by country flying to Paris.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Count the number of hotels by city.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Determine the amount of money spent by Tatiana REZE in flights.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;indexes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Indexes&lt;/h2&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-8&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 8  &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Write a query to get all the information of a customer with a given family name.
Run the query multiple times and note the average running time of the query.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create an index on the column containing the family name of a customer.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Rerun the same query multiple times and note the average running times of the query.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Do you observe any difference? Can you explain what is going on here?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Lectures</title>
      <link>/courses/databases/lectures/lectures/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/databases/lectures/lectures/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: Available &lt;a href=&#34;/courses/databases/intro-db.pdf&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-1&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 1&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: An introduction to database systems and data modeling.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Tuesday 15 September 2020, 9:00 AM - 12 PM.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: Available &lt;a href=&#34;/courses/databases/lecture-1-db-dsba.pdf&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 2&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Normalization theory.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Tuesday 29 September 2020, 9:00 AM - 12 PM.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: Available &lt;a href=&#34;/courses/databases/lecture-2-db-dsba.pdf&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-3&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 3&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Relational database management systems.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Tuesday 6 October 2020, 9:00 AM - 12 AM.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: Available &lt;a href=&#34;/courses/databases/lecture-3-db-dsba.pdf&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-4&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 4&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Advanced relational database concepts.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Tuesday 13 October 2020, 9:00 AM - 12 AM.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: Available &lt;a href=&#34;/courses/databases/lecture-4-db-dsba.pdf&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-5&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 5&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Distributed databases and NoSQL.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Tuesday 20 October 2020, 9:00 AM - 12 AM.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: Available &lt;a href=&#34;/courses/databases/lecture-5-db-dsba.pdf&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-6&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 6&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Document-oriented databases: MongoDB.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Tuesday 3 November 2020, 9:00 AM - 12 AM.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: Available &lt;a href=&#34;/courses/databases/lecture-6-db-dsba.pdf&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-7&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 7&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Graph databases: Neo4j.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Tuesday 10 November 2020, 9:00 AM - 12 AM.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: Available &lt;a href=&#34;/courses/databases/lecture-7-db-dsba.pdf&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>References</title>
      <link>/courses/databases/references/cc-references/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/databases/references/cc-references/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Date, Christopher John. &lt;em&gt;An introduction to database systems&lt;/em&gt;. Pearson Education India, 2004.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Hoffer, Jeffrey A., Venkataraman Ramesh, and Heikki Topi. &lt;em&gt;Modern database management&lt;/em&gt;. Pearson, 2016&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Garcia-Molina, Hector, Jeffrey D. Ullman and Jennifer Widom. &lt;em&gt;Database systems: the complete book&lt;/em&gt;. Pearson Education India, 2008.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Bradshaw, Shannon, Eoin Brazil, and Kristina Chodorow. &lt;em&gt;MongoDB: The Definitive Guide: Powerful and Scalable Data Storage&lt;/em&gt;. O’Reilly Media, 2019.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Robinson, Ian, Jim Webber, and Emil Eifrem. &lt;em&gt;Graph databases&lt;/em&gt;. &amp;quot; O’Reilly Media, Inc.&amp;quot;, 2013.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Docker Cheat Sheet</title>
      <link>/courses/cloud-computing/references/docker-cheat-sheet/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/cloud-computing/references/docker-cheat-sheet/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;infobox cheat&#34;&gt;
&lt;h1 id=&#34;cheat-sheet-run-containers&#34;&gt;Run containers&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Docker command:&lt;/strong&gt; &lt;code&gt;docker run [options] image-name [command] [arg]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt; Running a container from the image &lt;em&gt;alpine&lt;/em&gt;.&lt;/p&gt;
&lt;table class=&#34;infobox-content&#34;&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;strong&gt;docker run image-name&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;docker run image-name command&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;docker run image-name command arg&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;docker run alpine&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker run alpine ls&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker run alpine ping 192.168.3.1&lt;/code&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Common options:&lt;/strong&gt;&lt;/p&gt;
&lt;table class=&#34;infobox-content&#34;&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;strong&gt;Remove the container when it exits&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;Give the container a name&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;Allocate a terminal for the container&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;docker run --rm alpine&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker run --name toto alpine&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker run -it alpine&lt;/code&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;strong&gt;Mount &lt;em&gt;data-volume&lt;/em&gt; at &lt;em&gt;/data&lt;/em&gt;&lt;/strong&gt;**
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;Container port –&amp;gt; random host port&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;Host port 8080 –&amp;gt; container port 80&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;docker run -v data-volume:/data alpine&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker run --P alpine&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker run -p 8080:80 alpine&lt;/code&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;strong&gt;Attach container to network&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;docker run --network mynet alpine&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox cheat&#34;&gt;
&lt;h1 id=&#34;cheat-sheet-manage-containers&#34;&gt;Manage containers&lt;/h1&gt;
&lt;table class=&#34;infobox-content&#34;&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;strong&gt;List all containers&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;List running containers&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;Stop a container&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;docker container ls -a&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker container ls&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker stop my-container&lt;/code&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;strong&gt;Remove a container&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;Remove all stopped containers&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;Start a container&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;docker container rm  my-container&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker container prune&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker start my-container&lt;/code&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;strong&gt;Start a container (I/O)&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;Inspect changes in a container&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;Create image from container&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;docker start -ai my-container&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker  diff my-container&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker commit my-container new-image&lt;/code&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox cheat&#34;&gt;
&lt;h1 id=&#34;cheat-sheet-build-images&#34;&gt;Build images&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Docker command:&lt;/strong&gt; &lt;code&gt;docker build [OPTIONS] PATH | URL&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt; Building an image from a Dockerfile in the current directory:
&lt;code&gt;docker build .&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The command assumes that a file named &lt;em&gt;Dockerfile&lt;/em&gt; is in the current directory.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Common options:&lt;/strong&gt;&lt;/p&gt;
&lt;table class=&#34;infobox-content&#34;&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;strong&gt;Tag the image&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;Name of the Dockerfile&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;docker build -t my-image:latest .&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker build -f my-dockerfile .&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox cheat&#34;&gt;
&lt;h1 id=&#34;cheat-sheet-manage-image&#34;&gt;Manage images&lt;/h1&gt;
&lt;table class=&#34;infobox-content&#34;&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;strong&gt;List all images&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;List images (no intermediate)&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;Remove an image&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;docker image ls -a&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker image ls&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker image rm my-image&lt;/code&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;strong&gt;Remove dangling images&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;Remove unused images&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;Show the history of an image&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;docker image prune&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker image prune -a&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker history my-image&lt;/code&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox cheat&#34;&gt;
&lt;h1 id=&#34;cheat-sheet-dockerfile&#34;&gt;Dockerfile&lt;/h1&gt;
&lt;p&gt;In a &lt;strong&gt;Dockerfile&lt;/strong&gt; the following main keywords
are used:&lt;/p&gt;
&lt;table class=&#34;infobox-content&#34;&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;strong&gt;FROM base-image&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;FROM scratch&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;RUN cmd&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
Specifies the base image
&lt;/td&gt;
&lt;td&gt;
No base image used
&lt;/td&gt;
&lt;td&gt;
Runs a command
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;strong&gt;COPY src dst&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;ADD src dst&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;WORKDIR dir&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
Copy source file to destination
&lt;/td&gt;
&lt;td&gt;
Copy source file (including URL and TAR) to destination
&lt;/td&gt;
&lt;td&gt;
Sets the working directory
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;strong&gt;ENTRYPOINT cmd&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;CMD params&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;EXPOSE port&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
Command to execute when container is run
&lt;/td&gt;
&lt;td&gt;
Parameters of the entrypoint command
&lt;/td&gt;
&lt;td&gt;
Exposes a container port
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox cheat&#34;&gt;
&lt;h1 id=&#34;cheat-sheet-volumes&#34;&gt;Volumes&lt;/h1&gt;
&lt;table class=&#34;infobox-content&#34;&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;strong&gt;Create a volume&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;Remove a volume&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;Remove unused volumes&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;docker volume create my-volume&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker volume rm my-volume&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker volume prune&lt;/code&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;strong&gt;List volumes&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;docker volume ls&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox cheat&#34;&gt;
&lt;h1 id=&#34;cheat-sheet-networks&#34;&gt;Networks&lt;/h1&gt;
&lt;table class=&#34;infobox-content&#34;&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;strong&gt;Create a network&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;Remove a network&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;Remove unused networks&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;docker network create my-network&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker network rm my-network&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker network prune&lt;/code&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;strong&gt;List all the networks&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;Inspect a network&lt;/strong&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;strong&gt;Connect a container to a network&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;code&gt;docker network ls&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker network inspect my-network&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;docker network connect my-network my-container&lt;/code&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Docker primer</title>
      <link>/courses/cloud-computing/references/docker-primer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/cloud-computing/references/docker-primer/</guid>
      <description>


&lt;!-- in order to look at the files of an image: docker run -it --entrypoint sh image_name--&gt;
&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This page is still under construction&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Introduction&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Docker&lt;/strong&gt; is defined as
&lt;a href=&#34;https://docs.docker.com/engine/docker-overview/&#34; target=&#34;_blank&#34;&gt;“an open platform for developing,
shipping and running applications”&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In order to understand the importance of Docker in software development, it is useful
to make an analogy to the transportation industry &lt;span class=&#34;citation&#34;&gt;(Schenker 2018)&lt;/span&gt;.
Before the advent of &lt;em&gt;containers&lt;/em&gt;, goods were packaged in
boxes of different types and dimensions.
As a result, loading and unloading the merchandise from
ships or trucks was a long and tedious
task, because each package needed to be handled in a different way.
Containers, on the other hand, have standard dimensions and thus the process of loading/unloading them
could be standardized as well.&lt;/p&gt;
&lt;p&gt;Similarly, before the advent of Docker,
the development and deployment of a new software application in
an enterprise was extremely complicated.
Different teams of &lt;em&gt;developers&lt;/em&gt; would produce different types of applications
that the &lt;em&gt;operations engineers&lt;/em&gt; would need to install on production servers.
The deployment procedure would depend on the type
of the application; deploying a Python application is not the same
as deploying a Java application.
Moreover, applications usually rely on external libraries that need to be installed
on the production server;
sometimes, two applications may depend on different versions of the same library
that might not be completely compatible between each other.&lt;/p&gt;
&lt;p&gt;Docker addresses this issue by providing the ability of packaging software applications
with all their dependencies into isolated environments called, not suprisingly, &lt;strong&gt;containers&lt;/strong&gt;.
The operations engineers don’t need to know the dependencies of each application, they just see
the container as a black box that can be handled in a standardized way,
regardless of the application it contains.&lt;/p&gt;
&lt;div class=&#34;infobox curiosity&#34;&gt;
&lt;p&gt;&lt;strong&gt;Did you know?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The word &lt;em&gt;docker&lt;/em&gt; refers to a worker whose task is loading and unloading goods from a mean of
transportation, such as a truck, train, ship or airplanes.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-are-containers&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.1&lt;/span&gt; What are containers?&lt;/h2&gt;
&lt;p&gt;A &lt;strong&gt;container&lt;/strong&gt; packages a piece of software with all
its dependencies.
In order to run the application in the container, it suffices to run
the container, with no other action.&lt;/p&gt;
&lt;div class=&#34;infobox definitionbox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Definition&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;definition&#34;&gt;
&lt;p&gt;&lt;span id=&#34;def:unnamed-chunk-1&#34; class=&#34;definition&#34;&gt;&lt;strong&gt;Definition 1.1  &lt;/strong&gt;&lt;/span&gt;
A &lt;strong&gt;container&lt;/strong&gt;
is a standard unit of software
that packages up code and all its dependencies
so the application runs quickly and reliably from one
computing environment to another.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Figure &lt;a href=&#34;#fig:docker-container&#34;&gt;1.1&lt;/a&gt; shows some examples of
Docker containers.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:docker-container&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/courses/cloud-computing/docker-primer/container.png&#34; alt=&#34;Example of Docker containers&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1.1: Example of Docker containers
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The container &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; includes the source code of a Python application, the
Python interpreter and all the Python libraries necessary to
run the application.
This container can be run on any machine where Docker is installed;
no need to install the Python interpreter and the
libraries, since they are already included in the container.&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Good to know&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As we’ll explain later, a container is
created from a template called &lt;strong&gt;image&lt;/strong&gt;.
All containers created from an image
built on a specific hardware
architecture (e.g., on a x86 machine with a processor
that is compatible with Intel 8086 and its successors) can only
be run on machines with the same architecture.
In other words, we cannot
run a container on a Raspberry PI if that container has
been created from an image built on a x86 architecture.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The container &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; in Figure &lt;a href=&#34;#fig:docker-container&#34;&gt;1.1&lt;/a&gt;
includes a PHP application
that interacts with a MySQL database; the container includes
the PHP environment necessary to run the application and
the DBMS MySQL.
Finally, the container &lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt; includes a binary file compiled from a
program written in C and a minimal Linux distribution, called
Linux Alpine, necessary to run the binary file.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hows-a-container-different-from-a-virtual-machine&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.2&lt;/span&gt; How’s a container different from a virtual machine?&lt;/h2&gt;
&lt;p&gt;A virtual machine is another effective way to package
an application with all its dependencies.
Similarly to a container, a virtual machine can be ported
to any machine and easily deployed.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:vm-containers&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/courses/cloud-computing/docker-primer/vm-containers.png&#34; alt=&#34;Virtual machines Vs containers&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1.2: Virtual machines Vs containers
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The main difference between a virtual machine and a
container (Figure &lt;a href=&#34;#fig:vm-containers&#34;&gt;1.2&lt;/a&gt;)
is that the former always includes an operating system,
while the latter is run on the operating system of the host machine;
as a result, a container doesn’t need to include an operating system
and, therefore, is much lighter than a virtual machine.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-is-an-image&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.3&lt;/span&gt; What is an image?&lt;/h2&gt;
&lt;p&gt;An &lt;strong&gt;image&lt;/strong&gt; is a read-only template that contains
the files and the instructions necessary to create and run
containers.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:image&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/courses/cloud-computing/docker-primer/image.png&#34; alt=&#34;A Docker image&#34; width=&#34;50%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1.3: A Docker image
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The image in Figure &lt;a href=&#34;#fig:image&#34;&gt;1.3&lt;/a&gt; contains:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;A file &lt;em&gt;main.py&lt;/em&gt; with the source code of a Python application.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A full-blown Python interpreter.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;All Python libraries necessary to run the Python application.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The command to execute (&lt;code&gt;python main.py&lt;/code&gt;) when a container is
run from this image.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;how-does-docker-work&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.4&lt;/span&gt; How does Docker work?&lt;/h2&gt;
&lt;p&gt;Docker is based on a &lt;strong&gt;client-server architecture&lt;/strong&gt; (Figure &lt;a href=&#34;#fig:docker-architecture&#34;&gt;1.4&lt;/a&gt;).
The &lt;em&gt;client&lt;/em&gt; is any application capable of interacting
with Docker.
Docker provides a command-line interface (CLI)
allowing the user to enter commands to run
containers (&lt;code&gt;docker run&lt;/code&gt;), build images (&lt;code&gt;docker build&lt;/code&gt;)
or download images from a register (&lt;code&gt;docker pull&lt;/code&gt;).&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:docker-architecture&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/courses/cloud-computing/docker-primer/docker-architecture.svg&#34; alt=&#34;[Docker architecture](https://docs.docker.com/engine/docker-overview/)&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1.4: &lt;a href=&#34;https://docs.docker.com/engine/docker-overview/&#34;&gt;Docker architecture&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The client talks to the &lt;strong&gt;Docker daemon&lt;/strong&gt;,
a background process that manages Docker objects
such as containers and images.
More specifically, the Docker daemon can download images
from a special repository called a &lt;strong&gt;registry&lt;/strong&gt; and creates and runs
containers from those images.
There exist public and private Docker registries.
As of the time writing, examples of public registries include
&lt;a href=&#34;https://hub.docker.com/_/registry&#34;&gt;Docker Hub&lt;/a&gt;,
&lt;a href=&#34;https://cloud.google.com/container-registry&#34;&gt;Google&lt;/a&gt;,
&lt;a href=&#34;https://aws.amazon.com/ecr/&#34;&gt;Amazon AWS&lt;/a&gt; and
&lt;a href=&#34;https://azure.microsoft.com/en-us/services/container-registry/&#34;&gt;Microsoft Azure&lt;/a&gt;.
If not instructed otherwise,
the Docker daemon is configured to search for images in the Docker Hub registry.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;high-level-docker-architecture&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.5&lt;/span&gt; High-level Docker architecture&lt;/h2&gt;
&lt;p&gt;The high-level Docker architecture is shown in Figure &lt;a href=&#34;#fig:docker&#34;&gt;1.5&lt;/a&gt;.
At the top stands the &lt;strong&gt;Docker engine&lt;/strong&gt;, a client-server application
for building and containerizing applications.
The Docker engine includes
the Docker daemon (the server), the Docker CLI (the client) and a REST API
used by the client and the server to communicate (Fig. &lt;a href=&#34;#fig:docker-engine&#34;&gt;1.6&lt;/a&gt;).
The Docker engine manages all Docker objects, such as containers, images,
network and volumes (that we’ll discuss later) by using two tools,
namely &lt;strong&gt;containerd&lt;/strong&gt; and &lt;strong&gt;runc&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:docker&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/courses/cloud-computing/docker-primer/docker.png&#34; alt=&#34;High-level Docker architecture&#34; width=&#34;60%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1.5: High-level Docker architecture
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;containerd&lt;/strong&gt; is an &lt;a href=&#34;https://github.com/containerd/containerd&#34; target=&#34;_blank&#34;&gt;industry-standard &lt;strong&gt;container runtime&lt;/strong&gt;&lt;/a&gt;
that manages the complete container lifecycle, including
image transfer and storage,
container execution and supervision, low-level storage and network attachments.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;runc&lt;/strong&gt; is a command-line tool invoked by &lt;strong&gt;containerd&lt;/strong&gt; to run containers
with the proper parameters.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:docker-engine&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/courses/cloud-computing/docker-primer/docker-engine.png&#34; alt=&#34;Docker engine&#34; width=&#34;60%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1.6: Docker engine
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The Docker engine is built on top of several features of the Linux kernel.&lt;/p&gt;
&lt;p&gt;The Linux &lt;strong&gt;namespaces&lt;/strong&gt; are used to partition the system resources
(such as files, usernames, hostnames, network interfaces)
so that a process can only see the resources in one partition and
cannot interfere with the ones in other partitions.
In other words, namespaces provide the mechanism to isolate
containers from one another; when a container runs, it is not
aware that the others are even existing.&lt;/p&gt;
&lt;p&gt;While namespaces are used to partition software resources in the system, &lt;strong&gt;control groups&lt;/strong&gt; (or, &lt;strong&gt;cgroups&lt;/strong&gt;)
are used to limit the access
to the hardware resources, such as the processor or the memory.&lt;/p&gt;
&lt;p&gt;Finally, &lt;strong&gt;layer capabilities&lt;/strong&gt; are a set of features that support
layered filesystems used to build Docker images.&lt;/p&gt;
&lt;p&gt;Although Linux must be entirely credited for setting up
the technology necessary to implement containers,
Docker had the merit of bringing this technology to
the end user.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;docker-on-macos-and-windows&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.6&lt;/span&gt; Docker on macOS and Windows&lt;/h2&gt;
&lt;p&gt;Although Docker rests
on the shoulders of Linux, it can be
used on macOS and Windows as well.&lt;/p&gt;
&lt;p&gt;On these two systems, Docker comes with two flavours: &lt;strong&gt;Docker Toolbox&lt;/strong&gt; and
&lt;strong&gt;Docker Desktop&lt;/strong&gt;.
The &lt;a href=&#34;https://docs.docker.com/toolbox/&#34; target=&#34;_blank&#34;&gt;Docker Toolbox&lt;/a&gt;
is a version that is maintained for older
macOS and Windows systems (Figure &lt;a href=&#34;#fig:docker-for-mac&#34;&gt;1.7&lt;/a&gt;).
It installs a Linux virtual machine by using VirtualBox as the hypervisor
on top of which runs the Docker engine.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:docker-for-mac&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/courses/cloud-computing/docker-primer/docker-for-mac.png&#34; alt=&#34;Docker for macOS&#34; width=&#34;60%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1.7: Docker for macOS
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The Docker Desktop for macOS also uses a Linux virtual machine,
built with &lt;a href=&#34;https://github.com/linuxkit/linuxkit&#34; target=&#34;_blank&#34;&gt;LinuxKit&lt;/a&gt;,
but it uses Hyperkit, an hypervisor built by using a virtualization
framework provided by the operating system (Figure &lt;a href=&#34;#fig:docker-for-mac&#34;&gt;1.7&lt;/a&gt;).&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:docker-for-windows&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/courses/cloud-computing/docker-primer/docker-for-windows.png&#34; alt=&#34;Docker for Windows&#34; width=&#34;90%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1.8: Docker for Windows
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The Docker Toolbox on Windows has the same architecture as in macOS,
with a Linux virtual machine in VirtualBox (Figure &lt;a href=&#34;#fig:docker-for-windows&#34;&gt;1.8&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Windows Server 2016 and higher natively supports Docker; this means that the
Windows Server kernel has added the necessary functionalities to implement
the containers (namespaces, cgroupes and layer capabilities).&lt;/p&gt;
&lt;p&gt;Docker Desktop for Windows (for Windows Professional, Enterprise, or Education)
runs containers in virtual machines called &lt;em&gt;Hyper-V containers&lt;/em&gt;,
using Hyper-V, the native hypervisor provided by Windows.
An Hyper-V container includes
a minimal version of a Windows or Linux kernel, depending on whether
a Windows or Linux Docker container is run.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;running-containers&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; Running containers&lt;/h1&gt;
&lt;p&gt;The command used to run a container
is &lt;code&gt;docker run&lt;/code&gt; followed by four parameters:&lt;/p&gt;
&lt;pre class=&#34;shell&#34;&gt;&lt;code&gt;docker run [options] image-name [command] [arg]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The four parameters are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;options&lt;/em&gt;. List of options.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;image-name&lt;/em&gt;. The fully qualified name of the image used to run the container.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;command&lt;/em&gt;. The command to be executed in the container.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;arg&lt;/em&gt;. The arguments taken by the command executed in the container.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Only the parameter &lt;em&gt;image-name&lt;/em&gt; is mandatory.&lt;/p&gt;
&lt;div id=&#34;fully-qualified-image-names&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.1&lt;/span&gt; Fully-qualified image names&lt;/h2&gt;
&lt;p&gt;The fully qualified name of an image is specified
as a sequence of four fields, formatted as follows:&lt;/p&gt;
&lt;pre class=&#34;shell&#34;&gt;&lt;code&gt;registry_url/user/name:tag&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;registry_url&lt;/em&gt; (optional). The URL of the registry that provides the image.
If its value is not specified, the image
will be looked up for in the
&lt;a href=&#34;https://hub.docker.com&#34; target=&#34;_blank&#34;&gt;DockerHub registry&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;user&lt;/em&gt; (optional). The identifier of the user or organization that created the image.
The default value is &lt;em&gt;library&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;name&lt;/em&gt; (mandatory). The name of the image.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;tag&lt;/em&gt; (optional). It specifies the image version.
If its value is not specified,
the tag &lt;em&gt;latest&lt;/em&gt; is used, pointing to the latest image version.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An image can be associated to several tags.
For instance, the version 18.04 of the&lt;br /&gt;
&lt;a href=&#34;https://hub.docker.com/_/ubuntu/&#34; target=&#34;_blank&#34;&gt;ubuntu image&lt;/a&gt;
on the DockerHub registry is associated with the tags
&lt;em&gt;18.04&lt;/em&gt;, &lt;em&gt;bionic-20200403&lt;/em&gt; and &lt;em&gt;bionic&lt;/em&gt;.
The following names can be used to refer to that version:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;registry.hub.docker.com/library/ubuntu:bionic-20200403 
registry.hub.docker.com/library/ubuntu:18.04 
ubuntu:bionic&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Evidently, one would always choose the last name, as it is shorter.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-happens-when-we-run-a-container&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.2&lt;/span&gt; What happens when we run a container?&lt;/h2&gt;
&lt;p&gt;The command &lt;code&gt;docker run&lt;/code&gt; is a &lt;em&gt;wrapper&lt;/em&gt; for (i.e., uses behind the scenes)
three Docker commands: &lt;code&gt;docker pull&lt;/code&gt;, &lt;code&gt;docker create&lt;/code&gt; and &lt;code&gt;docker start&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let’s see what happens when we execute the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run hello-world&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Docker daemon goes through the following steps (Figure &lt;a href=&#34;#fig:docker-run-actions&#34;&gt;2.1&lt;/a&gt;):&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Look for an image called &lt;em&gt;hello-world&lt;/em&gt; in the host computer.&lt;/li&gt;
&lt;li&gt;If the image is found, go to step 6.&lt;/li&gt;
&lt;li&gt;Otherwise, look for an image called &lt;em&gt;hello-world&lt;/em&gt; in the DockerHub registry.&lt;/li&gt;
&lt;li&gt;If the image is not found, raise an error and stop.&lt;/li&gt;
&lt;li&gt;Otherwise, &lt;em&gt;pull&lt;/em&gt; (i.e., download) the image from the Dockerhub registry
(using the command &lt;code&gt;docker pull hello-world&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Create a container (&lt;code&gt;docker create --name condescending_liskov hello-world&lt;/code&gt;) from
the image.&lt;/li&gt;
&lt;li&gt;Run the container (&lt;code&gt;docker start condescending_liskov&lt;/code&gt;).&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:docker-run-actions&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/courses/cloud-computing/docker-primer/docker-run-actions.png&#34; alt=&#34;Runinng a Docker container&#34; width=&#34;90%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2.1: Runinng a Docker container
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;When we run a container by using the command &lt;code&gt;docker run&lt;/code&gt;,
we can also specify a name for the container with the option &lt;code&gt;--name&lt;/code&gt;;
if we don’t, the Docker daemon will assign a random name obtained by concatenating
an adjective to the name of a famous scientist (e.g., &lt;em&gt;condescending_liskov&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;When the containerized application, that is the application running in the container, stops,
the container is stopped as well.
However, the container is not removed from the host computer.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-list-containers&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.3&lt;/span&gt; How to list containers?&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;single-host-networking&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; Single-host networking&lt;/h1&gt;
&lt;div id=&#34;cnm&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.1&lt;/span&gt; Container network model&lt;/h2&gt;
&lt;p&gt;In order to let containers communicate and, therefore, co-operate,
Docker defines a simple networking model known as
the &lt;strong&gt;container network model&lt;/strong&gt; (CNM), illustrated
in the following figure.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:cnm&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/courses/cloud-computing/docker-primer/cnm.png&#34; alt=&#34;The container network model&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3.1: The container network model
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The figure shows three containers (from left to right, Athos, Porthos and Aramis);
the CNM consists of three elements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Sandbox.&lt;/strong&gt; It contains
the network configuration of the container, such as IP and MAC addresses, routing tables and
DNS records.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Endpoint.&lt;/strong&gt; Connection between the sandbox and a network.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Network.&lt;/strong&gt; Object that provides the function to connect two or more endpoints.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The actual implementation of the network is called a &lt;strong&gt;driver&lt;/strong&gt;.
Docker provides some built-in drivers, such as &lt;em&gt;bridge&lt;/em&gt;, &lt;em&gt;host&lt;/em&gt;, &lt;em&gt;overlay&lt;/em&gt; and &lt;em&gt;null&lt;/em&gt;;
third-party drivers can be used by installing the corresponding plugins.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Schenker2018&#34;&gt;
&lt;p&gt;Schenker, Gabriel. 2018. &lt;em&gt;Learn Docker - Fundamentals of Docker 18.x&lt;/em&gt;. 1st edition. Packt Publishing,&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>MongoDB</title>
      <link>/courses/plp/tutorials/mongodb-tutorial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/plp/tutorials/mongodb-tutorial/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In this lab assignment you’ll run queries in MongoDB.&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Assignment submission&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This lab assignment will be &lt;strong&gt;evaluated&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In order to finalize the submission of the assignment,
submit a report in PDF by using &lt;a href=&#34;https://centralesupelec.edunao.com/mod/assign/view.php?id=43066&#34; target=&#34;_blank&#34;&gt;this link&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The report must not be longer than 4 pages. In the report:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Indicate your first and family name.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Describe briefly the MongoDB query language and the aggregation framework.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Write the queries but not the results of the queries.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The submission deadline is &lt;strong&gt;Thursday, January 28, 2021 8:00 AM&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;setting-up-the-work-environment.&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Setting up the work environment.&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Start the &lt;strong&gt;MongoDB server&lt;/strong&gt;. Refer
to the &lt;a href=&#34;/courses/plp/overview/installation-mongodb&#34;&gt;documentation&lt;/a&gt;
to find out how to start the server depending on your operating system.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Launch &lt;strong&gt;MongoDB compass&lt;/strong&gt;. You should have installed it
with the MongoDB server.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;From within MongoDB compass, connect to the local MongoDB server.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-the-database&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Creating the database&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Download the data by &lt;a href=&#34;/courses/plp/tutorials/mongodb-data.zip&#34;&gt;clicking here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In MongoDB Compass, click on the button “Create database”.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Give the database a name (e.g., &lt;em&gt;cinema&lt;/em&gt;) and create a collection
named &lt;em&gt;movies&lt;/em&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Click on the button &lt;em&gt;Add data&lt;/em&gt; and select &lt;em&gt;Import file&lt;/em&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select JSON as a file format and select the file &lt;em&gt;movies.json&lt;/em&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Click on “Import”; 88 documents should be imported into the database.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Troubleshooting&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In case you experience problems while importing the JSON file, you might want to
try to import the file &lt;em&gt;movies.csv&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;querying-the-data-with-find&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Querying the data with &lt;em&gt;find&lt;/em&gt;&lt;/h1&gt;
&lt;p&gt;At the bottom of the MongoDB window, you should find a link
to open the MongoDB shell (MongoSH Beta).&lt;/p&gt;
&lt;p&gt;After opening the shell, write the following command to
switch to database &lt;em&gt;cinema&lt;/em&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;use cinema&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To verify that you’re actually connected to the database &lt;em&gt;cinema&lt;/em&gt;,
type the following query:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;db.movies.findOne()&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-1&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1  &lt;/strong&gt;&lt;/span&gt;
By using the MongoDB shell, execute the following queries.&lt;/p&gt;
&lt;p&gt;Q1. The release year of the movie “Le parrain III”.&lt;/p&gt;
&lt;p&gt;Q2. The title of the movies released between 1980 and 1990.&lt;/p&gt;
&lt;p&gt;Q3. Same query as b. with the titles must be sorted by alphabetical order.&lt;/p&gt;
&lt;p&gt;Q4. The titles of the french movies.&lt;/p&gt;
&lt;p&gt;Q5. The title of the “crime” or “drama” movies.&lt;/p&gt;
&lt;p&gt;Q6. The names and birth dates of the directors of french movies.&lt;/p&gt;
&lt;p&gt;Q7. The title of the movies in which Sofia Coppola played.&lt;/p&gt;
&lt;p&gt;Q8. The title and the genre of the movies of which Hitchcock is director.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;querying-the-data-with-the-aggregation-framework&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Querying the data with the aggregation framework&lt;/h1&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-2&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2  &lt;/strong&gt;&lt;/span&gt;
By using the MongoDB shell, execute the following queries
by using &lt;strong&gt;aggregation pipelines&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Q1. The number of movies by country. Show by decresing number.&lt;/p&gt;
&lt;p&gt;Q2. The name of the actor in the role “Mary Corleone” in the movie “Le parrain III”.&lt;/p&gt;
&lt;p&gt;Q3. The number of actors by movie. Sort by decreasing number.&lt;/p&gt;
&lt;p&gt;Q4. The average number of actors in a film.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;join-in-mongodb&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Join in MongoDB&lt;/h1&gt;
&lt;p&gt;In the database &lt;em&gt;cinema&lt;/em&gt;, create a new collection called &lt;em&gt;movies_boffice&lt;/em&gt;.
Import the documents in file &lt;em&gt;moviesBoxOffice.json&lt;/em&gt; into this collection.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-3&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3  &lt;/strong&gt;&lt;/span&gt;
By using the operator &lt;em&gt;$lookup&lt;/em&gt; on the collections
&lt;em&gt;movies&lt;/em&gt; and &lt;em&gt;movies_boffice&lt;/em&gt;, find the box office of the
movie “Le parrain III”.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to Linux</title>
      <link>/courses/cloud-computing/references/linux-introduction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/cloud-computing/references/linux-introduction/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This introduction is still under construction.
As of today, it only provides the elements necessary to
have a basic understanding to use Docker.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Introduction&lt;/h1&gt;
&lt;p&gt;Linux is a family of open source &lt;strong&gt;operating systems&lt;/strong&gt; that has
its roots in &lt;strong&gt;Unix&lt;/strong&gt;, an operating system developed in the 1970s
at the Bell Labs research center by, among others, Ken Thompson
and Dennis Ritchie.
For this reason, Linux is said to be a &lt;strong&gt;Unix-like&lt;/strong&gt; operating system.&lt;/p&gt;
&lt;p&gt;A Unix-like operating system is composed of three parts:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;The &lt;strong&gt;kernel&lt;/strong&gt;. It’s the core of the operating system,
acting as an intermediary between the applications and the
hardware devices. Its tasks include
memory management, process scheduling and input-output management.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The &lt;strong&gt;shell&lt;/strong&gt;. This is the command-line terminal that acts as an interface
between the user and the kernel.
The shell interprets and executes the commands typed by the user.
Many variants exist of the shell; the default shell provided by
most Linux distributions is called &lt;strong&gt;Bash&lt;/strong&gt;.
Usually, a shell provides some useful functionalities
to the user, including &lt;em&gt;filename completion&lt;/em&gt; (one can type
part of the name of a command or a file and press the Tab key to have the
shell complete it) and the history (list of all commands typed by the user, so
if the user needs to retype a command, s/he can just
use the cursor keys to retrieve it in the history).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The &lt;strong&gt;applications&lt;/strong&gt;. These are the user programs running on top
of the operating system (e.g., Firefox).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The first Linux kernel has been released as an open source software
by Linus Torvalds on September 17, 1991.
Being open source, the source code can be read, modified
and distributed by anyone under the GNU General Public License.
This has been key to the success and the rapid adoption of Linux.
Since then, many different
Linux &lt;strong&gt;distributions&lt;/strong&gt; have been developed and made available for free;
all distributions are based on the Linux kernel, they mainly differ
in the applications and tools they provide.
Some of the most popular are Ubuntu, Debian and Fedora.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-directory-structure&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; The directory structure&lt;/h1&gt;
&lt;p&gt;In Linux all files are organized in a hierarchical file system
that can be represented as a tree (Figure &lt;a href=&#34;#fig:linux-filesystem&#34;&gt;2.1&lt;/a&gt;).
At the top of the hierarchy stands a special directory called
the &lt;strong&gt;root&lt;/strong&gt;, that is usually written as a slash (/).&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:linux-filesystem&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/courses/cloud-computing/linux-introduction/linux-filesystem.pdf&#34; alt=&#34;Linux directory structure&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2.1: Linux directory structure
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The root directory includes many special directories, such
as &lt;em&gt;boot&lt;/em&gt; (contains configuration files necessary to
boot Linux), &lt;em&gt;lib&lt;/em&gt; (contains shared library files necessary to boot the
system),
&lt;em&gt;bin&lt;/em&gt; (contains user executable files), &lt;em&gt;dev&lt;/em&gt; (contains files that represent
hardware devices) and &lt;em&gt;etc&lt;/em&gt; (contains the local system configuration files).&lt;/p&gt;
&lt;p&gt;Each user is assigned a special directory called &lt;strong&gt;home&lt;/strong&gt;
(i.e., &lt;em&gt;laura&lt;/em&gt;, &lt;em&gt;michel&lt;/em&gt;) that is stored
under the &lt;em&gt;home&lt;/em&gt; directory;
despite its name, the directory named &lt;em&gt;root&lt;/em&gt; is not the root directory, but
the home directory of the user &lt;strong&gt;root&lt;/strong&gt;, that is the administrator of the system.
Each directory (except the root directory /)
has one &lt;strong&gt;parent&lt;/strong&gt; directory and zero or many &lt;strong&gt;children&lt;/strong&gt; directories.
For instance, the parent directory of &lt;em&gt;home&lt;/em&gt; is the root directory / and
its children directories are &lt;em&gt;laura&lt;/em&gt; and &lt;em&gt;michel&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;When a user (e.g., Laura) logs in the system and opens a shell,
her &lt;strong&gt;working directory&lt;/strong&gt; (i.e., the directory where she finds herself in)
is her home directory.
From there, Laura can type any Linux command and reference any
file or directory in the file system (if she has the necessary rights).
In Linux, Laura has two ways to specify the name of a directory or a file:
absolute paths or relative paths.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;absolute path&lt;/strong&gt; to a file or directory is
the full path of that file or directory in the
tree hierarchy starting from the root.
If Laura types the command &lt;code&gt;pwd&lt;/code&gt; (i.e., &lt;strong&gt;p&lt;/strong&gt;rint &lt;strong&gt;w&lt;/strong&gt;orking &lt;strong&gt;d&lt;/strong&gt;irectory), as
in Figure &lt;a href=&#34;#fig:user-pwd&#34;&gt;2.2&lt;/a&gt;, she’ll get the absolute path &lt;em&gt;/home/laura&lt;/em&gt; of her home
directory.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:user-pwd&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/courses/cloud-computing/linux-introduction/user-pwd.png&#34; alt=&#34;Home and current directory&#34; width=&#34;60%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2.2: Home and current directory
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Referring to Figure &lt;a href=&#34;#fig:linux-filesystem&#34;&gt;2.1&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the absolute path of the file &lt;em&gt;meeting.txt&lt;/em&gt; is &lt;em&gt;/home/laura/work/meeting.txt&lt;/em&gt;;&lt;/li&gt;
&lt;li&gt;the absolute path of the file &lt;em&gt;family.jpg&lt;/em&gt; is &lt;em&gt;/home/laura/personal/family.jpg&lt;/em&gt;;&lt;/li&gt;
&lt;li&gt;the absolute path of the directory &lt;em&gt;michel&lt;/em&gt; is &lt;em&gt;/home/michel&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;strong&gt;relative path&lt;/strong&gt; to a file or a directory is
given with respect to the working directory.
In order to specify a relative path, Laura might need to use
the symbol “.”, that indicates the working directory,
and “..”, that indicates the parent of the working directory.
If Laura wants to reference the file &lt;em&gt;family.jpg&lt;/em&gt; and her working directory is
&lt;em&gt;/home/laura&lt;/em&gt;, she’ll type &lt;em&gt;../personal/family.jpg&lt;/em&gt;.
If Laura wants to reference the file &lt;em&gt;meeting.txt&lt;/em&gt;,
she’ll type &lt;em&gt;./meeting.txt&lt;/em&gt;, or simply &lt;em&gt;meeting.txt&lt;/em&gt;, as any path is relative to the
current directory, if Laura doesn’t specify otherwise.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-1&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.1  &lt;/strong&gt;&lt;/span&gt;
If Laura’s current directory is &lt;em&gt;/etc&lt;/em&gt;, what would&lt;br /&gt;
the relative path of the file &lt;em&gt;/home/laura/work/meeting.txt&lt;/em&gt; be?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;&lt;em&gt;../home/laura/work/meeting.txt&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;useful-linux-commands&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; Useful Linux commands&lt;/h1&gt;
&lt;p&gt;Linux provides many useful commands to navigate the file system and
manipulate files and directories.&lt;/p&gt;
&lt;div id=&#34;pwd&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.1&lt;/span&gt; pwd&lt;/h2&gt;
&lt;p&gt;pwd stands for &lt;strong&gt;p&lt;/strong&gt;rint &lt;strong&gt;w&lt;/strong&gt;ork &lt;strong&gt;d&lt;/strong&gt;irectory.
It returns the absolute path of the working directory.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ls&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.2&lt;/span&gt; ls&lt;/h2&gt;
&lt;p&gt;Used to list the content of the working directory.
The command has several options, in particular:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ls -l&lt;/code&gt;. Show a detailed view of the content of the working directory.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ls -a&lt;/code&gt;. Includes the hidden files in the working directory.
In Linux, all files whose name begins with “.” are hidden.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;cd&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3&lt;/span&gt; cd&lt;/h2&gt;
&lt;p&gt;cd stands for &lt;strong&gt;c&lt;/strong&gt;hange &lt;strong&gt;d&lt;/strong&gt;irectory;
the command is used to change
working directory.&lt;/p&gt;
&lt;p&gt;If Laura’s working directory is &lt;em&gt;/home/laura&lt;/em&gt;
and she wants to move to the directory &lt;em&gt;work&lt;/em&gt; she’ll type the
following command:&lt;/p&gt;
&lt;pre class=&#34;shell&#34;&gt;&lt;code&gt;cd work&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If she wants to return to her home directory, she’ll type:&lt;/p&gt;
&lt;pre class=&#34;shell&#34;&gt;&lt;code&gt;cd ..&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mkdir&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.4&lt;/span&gt; mkdir&lt;/h2&gt;
&lt;p&gt;mkdir stands for “make directory”.
This command is used to create a new directory.&lt;/p&gt;
&lt;p&gt;Suppose that Laura’s working directory is &lt;em&gt;/home/laura&lt;/em&gt;;
in order to create a new directory &lt;em&gt;/home/laura/videos&lt;/em&gt;, she’ll type:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir videos&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If she wants to create a new directory &lt;em&gt;/home/laura/videos/birthday&lt;/em&gt;, she’ll type:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir videos/birthday&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;rm&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.5&lt;/span&gt; rm&lt;/h2&gt;
&lt;p&gt;This command is used to remove a file or a directory.
Suppose Laura’s working directory is &lt;em&gt;/home/laura&lt;/em&gt;.
In order to remove the file &lt;em&gt;meeting.txt&lt;/em&gt;, she’ll type:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rm meeting.txt&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If she wants to remove a directory (for example &lt;em&gt;videos&lt;/em&gt;),
she’ll type:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rm -r videos&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will delete the directory &lt;em&gt;videos&lt;/em&gt; and all its content.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cat&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.6&lt;/span&gt; cat&lt;/h2&gt;
&lt;p&gt;This command is useful for different tasks.
One possible use is to show the content of a file.
If Laura types:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat meeting.txt&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;she’ll get the content of the file &lt;em&gt;meeting.txt&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;echo&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.7&lt;/span&gt; echo&lt;/h2&gt;
&lt;p&gt;This command writes to the screen whatever Laura gives it as a parameter.
If Laura types:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;echo hello world&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;the command will print the string “hello world”.
Although this might not sound very useful,
the command &lt;code&gt;echo&lt;/code&gt; comes in handy when combined with
others.
For instance, if Laura types:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;echo hello world &amp;gt; hello.txt&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;a new file named &lt;em&gt;hello.txt&lt;/em&gt; is created in
the working directory containing the string
“hello world”.
This is a very useful way to create a new file with some content.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cp&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.8&lt;/span&gt; cp&lt;/h2&gt;
&lt;p&gt;This command is used to create a copy of a file or directory.
Suppose that Laura’s working directory is &lt;em&gt;/home/laura&lt;/em&gt;.
If she types:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cp meeting.txt ./personal&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;a new copy of &lt;em&gt;meeting.txt&lt;/em&gt; is created in the directory
&lt;em&gt;/home/laura/personal&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mv&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.9&lt;/span&gt; mv&lt;/h2&gt;
&lt;p&gt;This command is used to move a file or directory.
Suppose that Laura’s current directory is &lt;em&gt;/home/laura&lt;/em&gt; that contains
two children directories named &lt;em&gt;personal&lt;/em&gt; and &lt;em&gt;videos&lt;/em&gt;.
If Laura wants to move the directory &lt;em&gt;videos&lt;/em&gt; under &lt;em&gt;personal&lt;/em&gt;, she’ll type:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mv videos personal&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Lectures</title>
      <link>/courses/big-data-marseille/lectures/lectures/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/big-data-marseille/lectures/lectures/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;div id=&#34;lecture-1&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 1&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Introduction and MapReduce programming.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Monday 3 May 2021, 1:45 PAM - 5 PM.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: Available &lt;a href=&#34;/courses/big-data-marseille/big-data-1.pdf&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 2&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Hadoop and its ecosystem: HDFS.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Wednesday 5 May 2021, 8:30 AM - 10 AM.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: Available &lt;a href=&#34;/courses/big-data-marseille/big-data-2.pdf&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-3&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 3&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Introduction to Apache Spark.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Wednesday 5 May 2021, 10 AM - 11:30 AM.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: Available &lt;a href=&#34;/courses/big-data-marseille/big-data-3.pdf&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Spark RDD programming demo&lt;/strong&gt;: Available &lt;a href=&#34;https://colab.research.google.com/drive/1jfCdVVMD_OrTubT0-URqu3SJvQ5mqMfh?usp=sharing&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-4&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 4&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Apache Spark’s Structured APIs and Structured Streaming.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Monday 10 May 2021, 8:30 AM - 11:30 AM.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-5&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 5&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Distributed and NoSQL databases&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Monday 17 May 2021, 10:30 AM - 11:30 AM / 14 PM - 16 PM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-6&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 6&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Document-oriented database systems: MongoDB.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Monday 17 May 2021, 16 PM - 17PM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;:&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Lectures</title>
      <link>/courses/plp/lectures/lectures/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/plp/lectures/lectures/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;div id=&#34;lecture-1&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 1&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Introduction and MapReduce programming.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Monday 4 January 2021, 1:45 PAM - 5 PM.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: &lt;a href=&#34;https://centralesupelec.edunao.com/pluginfile.php/108889/course/section/18615/big-data-ia-1.pdf?time=1609756353689&#34; target=&#34;_blank&#34;&gt;Available on Edunao&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 2&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Hadoop and its ecosystem: HDFS.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Wednesday 6 January 2021, 8:30 AM - 11:45 AM.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: &lt;a href=&#34;https://centralesupelec.edunao.com/pluginfile.php/108889/course/section/18615/big-data-ia-2.pdf?time=1609838857800&#34; target=&#34;_blank&#34;&gt;Available on Edunao&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-3&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 3&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Introduction to Apache Spark.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Thursday 7 January 2021, 8:30 AM - 11:45 AM.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: &lt;a href=&#34;https://centralesupelec.edunao.com/pluginfile.php/108889/course/section/18615/big-data-ia-3.pdf?time=1609844241795&#34; target=&#34;_blank&#34;&gt;Available on Edunao&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Spark programming demo&lt;/strong&gt;: &lt;a href=&#34;https://colab.research.google.com/drive/1bUW3_HVFx3KD5OJZcVCzOEoM26JNIzOF?usp=sharing&#34; target=&#34;_blank&#34;&gt;Available in Google Colab&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-4&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 4&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Advanced Apache Spark.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Monday 11 January 2021, 8:30 AM - 11:45 AM.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: &lt;a href=&#34;https://centralesupelec.edunao.com/pluginfile.php/108889/course/section/18615/big-data-ia-4.pdf?time=1610111613875&#34; target=&#34;_blank&#34;&gt;Available on Edunao&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Spark SQL demo&lt;/strong&gt;: &lt;a href=&#34;https://colab.research.google.com/drive/1ayEq0dh8aNWB0aIMntKOg4irXOveuoz3?usp=sharing&#34; target=&#34;_blank&#34;&gt;Available in Google Colab&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-5&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 5&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Distributed and NoSQL databases&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Thursday 14 January 2021, 8:30 AM - 11:45 AM.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: &lt;a href=&#34;https://centralesupelec.edunao.com/pluginfile.php/108889/course/section/18615/big-data-ia-5.pdf?time=1610117122900&#34; target=&#34;_blank&#34;&gt;Available on Edunao&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-6&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 6&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Document-oriented database systems: MongoDB.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Thursday 21 January 2021, 8:30 AM - 11:45 AM.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: &lt;a href=&#34;https://centralesupelec.edunao.com/pluginfile.php/108889/course/section/18615/big-data-ia-6.pdf?time=1611052284709&#34; target=&#34;_blank&#34;&gt;Available on Edunao&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-7&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lecture 7&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Title&lt;/strong&gt;: Graph-oriented database systems: Neo4j.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Date and time&lt;/strong&gt;: Thursday 28 January 2021, 8:30 AM - 11:45 AM.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slides&lt;/strong&gt;: &lt;a href=&#34;https://centralesupelec.edunao.com/pluginfile.php/108889/course/section/18615/big-data-ia-7.pdf?time=1611586645856&#34; target=&#34;_blank&#34;&gt;Available on Edunao&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>References</title>
      <link>/courses/big-data-marseille/references/cc-references/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/big-data-marseille/references/cc-references/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Singh, Chanchal, and Manish Kumar. &lt;em&gt;Mastering Hadoop 3: Big data processing at scale to unlock unique business insights&lt;/em&gt;. Packt Publishing Ltd, 2019.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Mehrotra, Shrey, and Akash Grade. &lt;em&gt;Apache Spark Quick Start Guide: Quickly learn the art of writing efficient big data applications with Apache Spark&lt;/em&gt;. Packt Publishing Ltd, 2019.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Karau, Holden, et al. &lt;em&gt;Learning spark: lightning-fast big data analysis.&lt;/em&gt; O’Reilly Media, Inc., 2015&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Giamas, Alex. Mastering MongoDB 4.x: &lt;em&gt;Expert techniques to run high-volume and fault-tolerant database solutions using MongoDB 4.x&lt;/em&gt;. Packt Publishing Ltd, 2019.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Bradshaw, Shannon, Eoin Brazil, and Kristina Chodorow. &lt;em&gt;MongoDB: The Definitive Guide: Powerful and Scalable Data Storage&lt;/em&gt;. O’Reilly Media, 2019.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Scifo, Estelle, &lt;em&gt;Hands-on Graph Analytics with Neo4j&lt;/em&gt;. Packt Publishing Ltd, 2020&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>References</title>
      <link>/courses/plp/references/cc-references/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/plp/references/cc-references/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Singh, Chanchal, and Manish Kumar. &lt;em&gt;Mastering Hadoop 3: Big data processing at scale to unlock unique business insights&lt;/em&gt;. Packt Publishing Ltd, 2019.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Mehrotra, Shrey, and Akash Grade. &lt;em&gt;Apache Spark Quick Start Guide: Quickly learn the art of writing efficient big data applications with Apache Spark&lt;/em&gt;. Packt Publishing Ltd, 2019.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Karau, Holden, et al. &lt;em&gt;Learning spark: lightning-fast big data analysis.&lt;/em&gt; O’Reilly Media, Inc., 2015&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Giamas, Alex. Mastering MongoDB 4.x: &lt;em&gt;Expert techniques to run high-volume and fault-tolerant database solutions using MongoDB 4.x&lt;/em&gt;. Packt Publishing Ltd, 2019.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Bradshaw, Shannon, Eoin Brazil, and Kristina Chodorow. &lt;em&gt;MongoDB: The Definitive Guide: Powerful and Scalable Data Storage&lt;/em&gt;. O’Reilly Media, 2019.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Scifo, Estelle, &lt;em&gt;Hands-on Graph Analytics with Neo4j&lt;/em&gt;. Packt Publishing Ltd, 2020&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Advanced Spark programming</title>
      <link>/courses/plp/tutorials/spark-lab-assignment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/plp/tutorials/spark-lab-assignment/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;!-- ############ IMPORTANT: CHANGE THESE VALUES BEFORE ANY LAB ############ --&gt;
&lt;!-- The link to the Edunao page where the students submit their work --&gt;
&lt;!-- The submission deadline --&gt;
&lt;!-- ############ END OF MODIFICATIONS ############ --&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;The goal of this Spark lab assignment is to write Spark programs and run them on a cluster.
&lt;a href=&#34;/courses/plp/overview/cluster-connection&#34; target=&#34;_blank&#34;&gt;Refer to this documentation&lt;/a&gt; to learn how to connect and
interact with the cluster.&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Assignment submission&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This lab assignment will be &lt;strong&gt;evaluated&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In order to finalize the submission of the assignment,
complete &lt;a href=&#34;https://centralesupelec.edunao.com/mod/quiz/view.php?id=47098&#34; target=&#34;_blank&#34;&gt;this form available on Edunao&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The submission deadline is &lt;strong&gt;Tuesday, March 9, 2021 8:00 AM&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;common-friends-in-a-social-network&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Common friends in a social network&lt;/h1&gt;
&lt;p&gt;Consider a social network described by a graph encoded in a text file.
Each line of the file is a list of identifiers separated by commas.
For instance, the line &lt;span class=&#34;math inline&#34;&gt;\(A,B,C,D\)&lt;/span&gt; means that &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; is friend with &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt;.
An excerpt of the file looks like as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;A,B,C,D
B,A,D
C,A,D
D,A,B,C
...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We suppose that the friendship relation is symmetric: &lt;span class=&#34;math inline&#34;&gt;\((A, B)\)&lt;/span&gt; implies
&lt;span class=&#34;math inline&#34;&gt;\((B, A)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We want to obtain the list of the common friends for each pair of individuals&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(A, B), [D]
(A, C), [D] 
(A, D), [B, C] 
(B, C), [D] 
(B, D), [A] 
(C, D), [A]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As an additional constraint, we want to represent a couple only once and avoid
to represent the symmetric couple.
In other words, if we output &lt;span class=&#34;math inline&#34;&gt;\((A, B)\)&lt;/span&gt;, we don’t want to output &lt;span class=&#34;math inline&#34;&gt;\((B, A)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We use the following input files available in folder &lt;code&gt;hdfs://sar01:9000/data/sn/&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;sn_tiny.csv&lt;/code&gt;. Small social network, that you can use to test your implementation.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;sn_10k_100k.csv&lt;/code&gt;. Social network with &lt;span class=&#34;math inline&#34;&gt;\(10^4\)&lt;/span&gt; individuals and &lt;span class=&#34;math inline&#34;&gt;\(10^5\)&lt;/span&gt; links.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;sn_100k_100k.csv&lt;/code&gt;. Social network with &lt;span class=&#34;math inline&#34;&gt;\(10^5\)&lt;/span&gt; individuals and &lt;span class=&#34;math inline&#34;&gt;\(10^5\)&lt;/span&gt; links.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;sn_1k_100k.csv&lt;/code&gt;. Social network with &lt;span class=&#34;math inline&#34;&gt;\(10^3\)&lt;/span&gt; individuals and &lt;span class=&#34;math inline&#34;&gt;\(10^5\)&lt;/span&gt; links.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;sn_1m_1m.csv&lt;/code&gt;. Social network with &lt;span class=&#34;math inline&#34;&gt;\(10^6\)&lt;/span&gt; individuals and &lt;span class=&#34;math inline&#34;&gt;\(10^6\)&lt;/span&gt; links.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-1&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1  &lt;/strong&gt;&lt;/span&gt;
Write an implementation in Spark.
&lt;strong&gt;Test your implementation on file &lt;code&gt;sn_tiny.csv&lt;/code&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-2&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2  &lt;/strong&gt;&lt;/span&gt;
Run your implementation on the other files and write down the execution times.
Comment on the execution times considering the file sizes, the number of nodes and links
and the number of pairs &lt;span class=&#34;math inline&#34;&gt;\(((A, B), X)\)&lt;/span&gt; generated by the algorithm.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-3&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3  &lt;/strong&gt;&lt;/span&gt;
Execute your implementation on the file &lt;code&gt;sn_1m_1m.csv&lt;/code&gt; by varying the
number of cores used by the Spark executors.
You can specify the total number of cores with the option &lt;code&gt;--total-executor-cores&lt;/code&gt;
of the command &lt;code&gt;spark-submit&lt;/code&gt; (you can also refer &lt;a href=&#34;https://spark.apache.org/docs/latest/submitting-applications.html&#34; target=&#34;_blank&#34;&gt;to the Spark documentation&lt;/a&gt;).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is the impact of the number of cores on the execution time? Make a graph and comment.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-4&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4  &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;By using a MapReduce-style algorithm, write a Spark program to compute the minimum, maximum and average degree of
a node in a given graph.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Compute the minimum, maximum and average degree on all the given input files.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Do these values confirm or invalidate the considerations that you made on the execution times of the
algorithm in the first exercise? Justify your answer.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-an-inverted-index&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Creating an inverted index&lt;/h1&gt;
&lt;p&gt;In folder &lt;code&gt;hdfs://sar01:9000/data/bbc/&lt;/code&gt; you’ll find a collection of 50
articles obtained from the BBC website (2004-2005) organized into five subfolders:
&lt;em&gt;business&lt;/em&gt;, &lt;em&gt;entertainment&lt;/em&gt;, &lt;em&gt;politics&lt;/em&gt;, &lt;em&gt;sport&lt;/em&gt; and &lt;em&gt;technology&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;We want to create an &lt;strong&gt;inverted index&lt;/strong&gt;, which associates each word with the list of the
files in which the word occurs.
More specifically, for each word, the inverted index will have a list of the
names of the files (path relative to the folder &lt;code&gt;/data/bbc&lt;/code&gt;) that contain the word.&lt;/p&gt;
&lt;p&gt;The inverted index:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;must not contain the same word twice;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;must not contain any stopwords (the list of stopwords is provided in the
&lt;code&gt;hdfs://sar01:9000/data/stopwords.txt&lt;/code&gt; file);&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Moreover:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Words in the inverted index must only contain letters.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Words in the inverted index must be lowercase.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-5&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 5  &lt;/strong&gt;&lt;/span&gt;
Write a Spark program to create an inverted index and execute it on the
input folder.
You can use the template available at &lt;code&gt;~vialle/DCE-Spark/template_inverted_index.py&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Spark structured streaming</title>
      <link>/courses/plp/tutorials/structured-streaming-lab/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/plp/tutorials/structured-streaming-lab/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;!-- ############ IMPORTANT: CHANGE THESE VALUES BEFORE ANY LAB ############ --&gt;
&lt;!-- The link to the Edunao page where the students submit their work --&gt;
&lt;!-- The submission deadline --&gt;
&lt;!-- ############ END OF MODIFICATIONS ############ --&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;The goal of this lab assignment is to learn how to analyze streams of data with the Spark Structured Streaming API.
&lt;a href=&#34;/courses/plp/overview/cluster-connection&#34; target=&#34;_blank&#34;&gt;Refer to this documentation&lt;/a&gt; to learn how to connect and
interact with the cluster.&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Assignment submission&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This lab assignment will be &lt;strong&gt;evaluated&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In order to finalize the submission of the assignment,
complete &lt;a href=&#34;https://centralesupelec.edunao.com/mod/quiz/view.php?id=48267&#34; target=&#34;_blank&#34;&gt;this form available on Edunao&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The submission deadline is &lt;strong&gt;Tuesday, March 30, 2021 8:00 AM&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Documentation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In order to answer the questions and do the exercises, you might want to refer to the following
documentation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The &lt;a href=&#34;https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html&#34; target=&#34;_blank&#34;&gt;Structured Streaming programing guide&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The &lt;a href=&#34;https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html&#34; target=&#34;_blank&#34;&gt;Spark SQL API reference&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!-- ############ IMPORTANT: CHANGE THESE VALUES BEFORE ANY LAB ############ --&gt;
&lt;!-- The group to which users in the cluster belong--&gt;
&lt;!-- User accounts are numbered from the lower to the upper limit--&gt;
&lt;!-- ############ END OF MODIFICATIONS ############ --&gt;
&lt;/div&gt;
&lt;div id=&#34;warming-up&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Warming up&lt;/h1&gt;
&lt;p&gt;Consider the following program.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from pyspark.sql import SparkSession
from pyspark.sql.types import *
import pyspark.sql.functions as F

port_number = COMPLETE HERE
checkpoint_location = COMPLETE HERE

spark = (SparkSession.builder.appName(&amp;quot;Structured Streaming - exo1&amp;quot;).getOrCreate())

lines = (spark\
        .readStream.format(&amp;quot;socket&amp;quot;)\
        .option(&amp;quot;host&amp;quot;, &amp;quot;localhost&amp;quot;)\
        .option(&amp;quot;port&amp;quot;, port_number)\
        .load())

streamingQuery = lines.writeStream\
                .option(&amp;quot;checkpointLocation&amp;quot;, checkpoint_location)\
                .format(&amp;quot;console&amp;quot;).start()

streamingQuery.awaitTermination()&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-1&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1  &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Where does this program get its input from?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What object type does the variable &lt;code&gt;lines&lt;/code&gt; contain?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Where does this program write its output?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is the output of this program?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is the option &lt;code&gt;checkpointLocation&lt;/code&gt; intended for?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What does the instruction &lt;code&gt;streamingQuery.awaitTermination()&lt;/code&gt;?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;You can now verify your answers to the previous questions by &lt;strong&gt;executing the program&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox activitybox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Activity&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Connect to the cluster, if you haven’t done so yet. &lt;a href=&#34;/courses/plp/overview/cluster-connection&#34; target=&#34;_blank&#34;&gt;Refer to this documentation&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;After running the command &lt;code&gt;srun ...&lt;/code&gt;, you should be connected to a machine on the cluster Kyle.
Note the name of this machine (you should see it at the terminal prompt).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create a checkpoint directory for the first exercise (e.g., &lt;code&gt;checkpoint_exo1&lt;/code&gt;) under your home directory
&lt;code&gt;hdfs://sar01:9000/cpuasi1/cpuasi1_X&lt;/code&gt; &lt;strong&gt;in HDFS&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Copy and paste the code into a Python file (e.g., &lt;code&gt;exo1.py&lt;/code&gt;) that you’ll save into your home directory &lt;strong&gt;in the local filesystem&lt;/strong&gt;
of the cluster machine.
&lt;ul&gt;
&lt;li&gt;Change the value of the variable &lt;code&gt;checkpoint_location&lt;/code&gt; so that it points to the directory that you created at point 3.&lt;/li&gt;
&lt;li&gt;Change the value of the variable &lt;code&gt;port_number&lt;/code&gt; to any value in the range [49152, 65535].&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Open a new terminal window, connect to &lt;code&gt;phome.metz.supelec.fr&lt;/code&gt; and then to the same machine that you noted at point 2.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In the new terminal, start a &lt;strong&gt;netcat server&lt;/strong&gt; listening on the port number that you selected at point 4. Use the following command:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;nc -lk port_number&lt;/code&gt;&lt;/p&gt;
&lt;ol start=&#34;7&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Run the Python code with the command &lt;code&gt;spark-submit&lt;/code&gt;. Wait until Spark does not display any more messages on screen.
&lt;ul&gt;
&lt;li&gt;In case the program stops for an error, read the box “What to do in case of errors” below.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;In the netcat terminal, write few lines of text. Look at the terminal where the Spark program is running and observe the output.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;What to do in case of errors&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If any error arises, &lt;strong&gt;before&lt;/strong&gt; running the &lt;code&gt;spark-submit&lt;/code&gt; again it would be better to remove
all files from the checkpoint directory.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Stop the program&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;When you’re done with your experiments, you can stop the Spark program by simply
typing CTRL-C in the terminal where Spark is running.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Don’t stop the netcat server, you’ll need it in the next exercise.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;triggering-policy&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Triggering policy&lt;/h1&gt;
&lt;p&gt;In a Structured Streaming program we can choose a &lt;strong&gt;triggering policy&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-2&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2  &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;What is a triggering policy?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is the triggering policy in the previous program?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Modify the code of the previous program in order to set the
&lt;code&gt;Fixed interval micro-batch&lt;/code&gt; triggering policy.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Run the program. How is the behaviour of this program different from before?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;checkpoint-location-and-output-mode&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Checkpoint location and output mode&lt;/h1&gt;
&lt;p&gt;We’re now going to see the impact of the checkpoint location and the output modes on a streaming query.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-3&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3  &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;What is an output mode and what are the available options?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;What is the output mode of the previous program?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We’re now going to write a new streaming query.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-4&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4  &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Create a new checkpoint location in HDFS.
You may also keep the same directory as before; in this case, make sure you &lt;strong&gt;remove all files&lt;/strong&gt; from that
directory.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Write a new program that reads a streaming text from a TCP socket and
counts the number of occurrences of each word.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Which output mode are you going to choose and why?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Run the program. Write few lines on the netcat server and observe the output.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Stop the program and run it again with no modifications. Write few lines in the netcat terminal and observe the output.
What can you say about the word counts?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Stop the program and remove the files in the checkpoint location. Run the program again and write few lines
on the netcat terminal. What can you say about the word counts?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Play with the different output modes and observe how the output changes.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;window-operations-on-event-time&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Window operations on event time&lt;/h1&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Netcat and checkpoint&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;You can stop the netcat server now.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Remember to create a new checkpoint location for this exercise.
Alternatively, you can also use the same directory as in the previous exercises, but
you should remove all its files.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;p&gt;We’re now going to find out how to perform aggregations over a sliding event-time window.&lt;/p&gt;
&lt;p&gt;A given data source generates some words for a certain time interval.
Each word is accompanied with a timestamp that indicates the exact moment when the word is
generated. This timestamp is the &lt;strong&gt;event time&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;After generating a word, the data source saves the word and its timestamp into
a CSV file in a directory on HDFS.
For convenience, we’ll refer to this directory as the &lt;strong&gt;source directory&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;At any given moment, the source will contain zero to many CSV files,
where each file only contains exactly one line in the format
&lt;code&gt;word,timestamp&lt;/code&gt; (no whitespace before nor after the comma).&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-5&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 5  &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Write a Spark program that:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Reads the stream of data from the source directory.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Counts the number of occurrences of each word within 10 minute windows that slide every 5 minutes.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Print the output counts to the console. Use triggers of 5 seconds.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We now test the new Spark program.&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Data source and timeline visualization&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We provide two Python programs for this exercise: a data generator and
a tool for visualizing words in a timeline. Instructions to get and run
these two programs are given in the activity below.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;data generator&lt;/strong&gt; is our data source.
It generates two words every second for a certain
amount of time.
Each word is saved in a separate CSV file in source directory.
It also saves the list of all generated
words to a summary CSV file.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;visualization tool&lt;/strong&gt; takes as its input the summary CSV file
written by the data generator and visualizes the words
on a timeline.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox activitybox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Activity&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Create the source directory under your home directory
&lt;code&gt;hdfs://sar01:9000/cpuasi1/cpuasi1_X&lt;/code&gt; &lt;strong&gt;in HDFS&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Copy to your home directory
in the local filesystem
the data generator that you find at the following path&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;/usr/users/cpu-prof/cpu_quercini/structured-streaming/tempws_gen.py&lt;/code&gt;.&lt;/p&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Start your Spark program. When running the first time, you might get some errors. Correct your code accordingly.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In another terminal, run the Python script &lt;code&gt;tempws_gen.py&lt;/code&gt;. Use the
following command to learn how to run this program:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;python3 tempws_gen.py --help&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;For this exercise, do not introduce any delay
(keep the default values of the parameters &lt;code&gt;--delay&lt;/code&gt;, &lt;code&gt;--mindelay&lt;/code&gt;, &lt;code&gt;--maxdelay&lt;/code&gt;).&lt;/p&gt;
&lt;ol start=&#34;5&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;After launching the data generator, you should
see some output in the terminal where you launched the Spark program.
&lt;strong&gt;Wait for the script &lt;code&gt;tempws_gen.py&lt;/code&gt; to terminate the data generation&lt;/strong&gt;.
The output might be a bit overwhelming. Scroll up to identify the results
on each micro-batch.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If you need to rerun the Spark program and the data generator, make sure you delete all the files in the
checkpoint location and the source directory.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;p&gt;We now want to analyze the output of the program.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The script &lt;code&gt;tempws_gen.py&lt;/code&gt; has generated
a file &lt;code&gt;gen_words.csv&lt;/code&gt; in your home directory.
This file contains the list of all words generated with the relative timestamps.
&lt;strong&gt;Download the file to your computer&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Download the visualization tool &lt;code&gt;/usr/users/cpu-prof/cpu_quercini/structured-streaming/timeline_visualization.py&lt;/code&gt;
to your computer.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Visualization tool&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Use the following command to learn how to run the visualization tool:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python timeline_visualization.py --help&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The visualization tool displays a vertical blue bar at each trigger.
To this purpose, you’ll need to pass the tool the timestamps associated to the first
and last trigger and the interval (in seconds) between two consecutive triggers.&lt;/p&gt;
&lt;p&gt;You can get the timestamps associated to the first and last trigger by analyzing the output of Spark.
More specifically, for each micro-batch, Spark outputs the progress details of the streaming query; you’ll need
to look at the timestamp associated to the first and last micro-batch.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-6&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 6  &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Analyze the output of your Spark program and the timeline of the generated words.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Describe how the counts are updated by the Spark program.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;late-data-and-watermarking&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Late data and watermarking&lt;/h1&gt;
&lt;p&gt;We’re now going to learn how Structured Streaming handles
late data in windowed aggregations.&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Remove generated files&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Remove all the files in the directory &lt;code&gt;tempws&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The data generator &lt;code&gt;tempws_gen.py&lt;/code&gt;
can generate a stream of words, some of which
might be written to the directory &lt;code&gt;tempws&lt;/code&gt; with some amount of
delay. In other words, there is a gap between the event time (when the word is generated)
and the arrival time (when the word is written to the directory).&lt;/p&gt;
&lt;p&gt;Use the following command to learn how to do it:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python3 tempws_gen.py --help&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-7&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 7  &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Write a Spark program that does the same aggregation as in the previous exercise.
Additionally, the program must use watermarking to handle late data.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Start the Spark program.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Generate some data with delay with the program &lt;code&gt;tempws_gen.py&lt;/code&gt;.
Once the data generation stops, you can stop the Spark program.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Visualize the generated words with the visualization tool.
Late words have the delay indicated between parentheses.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Observe the output of the Spark program and describe how
the watermarking mechanism works on this example.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Data modeling</title>
      <link>/courses/databases/tutorials/data-modeling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/databases/tutorials/data-modeling/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;p&gt;In this tutorial you’ll learn:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How to &lt;strong&gt;create a conceptual schema&lt;/strong&gt; of a database.&lt;/li&gt;
&lt;li&gt;How to &lt;strong&gt;draw an entity-relationship&lt;/strong&gt; (ER) diagram.&lt;/li&gt;
&lt;li&gt;How to &lt;strong&gt;translate&lt;/strong&gt; a &lt;strong&gt;conceptual model&lt;/strong&gt; into a &lt;strong&gt;logical model&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Having attended &lt;a href=&#34;/courses/cloud-computing/lectures/lectures&#34;&gt;Lecture 1&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;database-of-a-social-network-platform&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Database of a social network platform&lt;/h1&gt;
&lt;p&gt;A social network platform wants to design a relational database
to store information on its users.
For each user, the platform keeps its nickname,
that uniquely identifies the user in the platform, first and family name,
geographic location (city and country) and email address;
the user can register as many email addresses as s/he wishes.
Any user can share content on the platform; each post is characterized by its content,
date, time and, when available, the geolocation (latitude, longitude).
Optionally, users can tag one or more friends in their posts.&lt;/p&gt;
&lt;p&gt;Two users are linked by a friendship relationship
if both agree on befriending each other;
a user can also follow another user without necessarily befriending her.
For any type of relationship (friendship or follower),
the platform registers the date when the relationship is established.&lt;/p&gt;
&lt;div id=&#34;exercises&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.1&lt;/span&gt; Exercises&lt;/h2&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-1&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.1  &lt;/strong&gt;&lt;/span&gt;
Give the &lt;strong&gt;conceptual schema&lt;/strong&gt; of the database with an ER diagram.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;&lt;img src=&#34;/courses/databases/tutorial-1/social-network-solution.png&#34; alt=&#34;Social network solution&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-2&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.2  &lt;/strong&gt;&lt;/span&gt;
Translate the conceptual schema into a logical schema.
For each table, underline the primary key and specify the foreign keys.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;The &lt;strong&gt;collection of tables&lt;/strong&gt; is the following:&lt;/p&gt;
&lt;pre&gt;
&lt;TT&gt;UserAccount&lt;/TT&gt;  (&lt;u&gt;nickname&lt;/u&gt;, first_name, last_name, city, country)

&lt;TT&gt;Post&lt;/TT&gt;         (&lt;u&gt;post_id&lt;/u&gt;, content, date, time, lat, long, nickname)

&lt;TT&gt;EmailAddress&lt;/TT&gt; (&lt;u&gt;email_address&lt;/u&gt;, nickname)

&lt;TT&gt;Relationship&lt;/TT&gt; (&lt;u&gt;nickname_src&lt;/u&gt;, &lt;u&gt;nickname_dst&lt;/u&gt;, type, date)

&lt;TT&gt;Tag&lt;/TT&gt;          (&lt;u&gt;post_id&lt;/u&gt;, &lt;u&gt;nickname&lt;/u&gt;)

&lt;/pre&gt;
&lt;p&gt;The &lt;strong&gt;foreign keys&lt;/strong&gt; are the following:&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Post(nickname)&lt;/TT&gt; → &lt;TT&gt;UserAccount(nickname)&lt;/TT&gt;.&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;EmailAddress(nickname)&lt;/TT&gt; → &lt;TT&gt;EmailAddress(nickname)&lt;/TT&gt;.&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Relationship(nickname_src)&lt;/TT&gt; → &lt;TT&gt;UserAccount(nickname)&lt;/TT&gt;.&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Relationship(nickname_dst)&lt;/TT&gt; → &lt;TT&gt;UserAccount(nickname)&lt;/TT&gt;.&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Tag(post_id)&lt;/TT&gt; → &lt;TT&gt;Post(post_id)&lt;/TT&gt;.&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Tag(nickname)&lt;/TT&gt; → &lt;TT&gt;UserAccount(nickname)&lt;/TT&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;database-of-a-banking-system&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; Database of a banking system&lt;/h1&gt;
&lt;p&gt;The following figure shows the ER diagram with the
conceptual schema of a banking system database.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:banking-system-db&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/courses/databases/tutorial-1/banking-system-er.png&#34; alt=&#34;The conceptual schema of the bank database&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2.1: The conceptual schema of the bank database
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Each bank is identified by a unique code and name,
and has one or several branches.
A branch is responsible for opening accounts and
granting loans to customers.
Each account is identified by
a number (&lt;em&gt;acct_nbr&lt;/em&gt;)
and is either a checking or savings account
(property &lt;em&gt;acct_type&lt;/em&gt;).
Each customer is identified by its social
security number (&lt;em&gt;ssn&lt;/em&gt;);
a customer can be granted several loans and open as many accounts as s/he wishes.&lt;/p&gt;
&lt;div id=&#34;exercises-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.1&lt;/span&gt; Exercises&lt;/h2&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-3&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.1  &lt;/strong&gt;&lt;/span&gt;Which primary key would you choose for the entity Bank? Justify your answer.
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;Since no
two banks have the same &lt;em&gt;code_bank&lt;/em&gt; or &lt;em&gt;name&lt;/em&gt;,
either property can be chosen as the primary key
of the entity &lt;TT&gt;Bank&lt;/TT&gt;.
Both can be considered as valid &lt;strong&gt;candidate keys&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-4&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.2  &lt;/strong&gt;&lt;/span&gt;Would you consider {&lt;em&gt;code_bank&lt;/em&gt;, &lt;em&gt;name&lt;/em&gt;}
as a valid candidate key for the entity &lt;TT&gt;Bank&lt;/TT&gt;? Justify your answer.
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;The answer is &lt;strong&gt;no&lt;/strong&gt;.
While there aren’t any banks that have
the same value for {&lt;em&gt;code_bank&lt;/em&gt;, &lt;em&gt;name&lt;/em&gt;},
two subsets ({&lt;em&gt;code_bank&lt;/em&gt;} and {&lt;em&gt;name&lt;/em&gt;}) are candidate keys.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-5&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.3  &lt;/strong&gt;&lt;/span&gt;Complete the
diagram in the figure
by adding the cardinalities to the relations.
Justify your choices when any ambiguity arises.
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;&lt;img src=&#34;/courses/databases/tutorial-1/banking-system-er-complete.png&#34; alt=&#34;Banking system solution&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-6&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.4  &lt;/strong&gt;&lt;/span&gt;Translate the conceptual schema into a logical schema.
For each table, underline the primary keys and specify the foreign keys.
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;The &lt;strong&gt;collection of tables&lt;/strong&gt; is the following:&lt;/p&gt;
&lt;pre&gt;
&lt;TT&gt;Bank&lt;/TT&gt;     (&lt;u&gt;code_bank&lt;/u&gt;, name, address)

&lt;TT&gt;Branch&lt;/TT&gt;   (&lt;u&gt;branch_id&lt;/u&gt;, address, code_bank)

&lt;TT&gt;Account&lt;/TT&gt;  (&lt;u&gt;acct_nbr&lt;/u&gt;, acct_type, balance, branch_id, ssn)

&lt;TT&gt;Loan&lt;/TT&gt;     (&lt;u&gt;loan_nbr&lt;/u&gt;, loan_type, amount, branch_id, ssn)

&lt;TT&gt;Customer&lt;/TT&gt; (&lt;u&gt;ssn&lt;/u&gt;, first_name, last_name, telephone, address)

&lt;/pre&gt;
&lt;p&gt;The &lt;strong&gt;foreign keys&lt;/strong&gt; are the following:&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Branch(code_bank)&lt;/TT&gt; → &lt;TT&gt;Bank(code_bank)&lt;/TT&gt;.&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Account(branch_id)&lt;/TT&gt; → &lt;TT&gt;Branch(branch_id)&lt;/TT&gt;.&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Account(ssn)&lt;/TT&gt; → &lt;TT&gt;Customer(ssn)&lt;/TT&gt;.&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Loan(branch_id)&lt;/TT&gt; → &lt;TT&gt;Branch(branch_id)&lt;/TT&gt;.&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Loan(ssn)&lt;/TT&gt; → &lt;TT&gt;Customer(ssn)&lt;/TT&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;car-dealership-database&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; Car dealership database&lt;/h1&gt;
&lt;p&gt;We want to design the database of a car dealership.
The dealership sells both new and used cars,
and it operates a service facility.
The database should keep data about the cars
(serial number, make, model, colour, whether it is new or used),
the salespeople (first and family name)
and the customers (first and family name, phone number, address).
Also, the following business rules hold:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A salesperson may sell many cars, but each car is sold by only one salesperson.&lt;/li&gt;
&lt;li&gt;A customer may buy many cars, but each car is bought by only one customer.&lt;/li&gt;
&lt;li&gt;A salesperson writes a single invoice for each car s/he sells.
The invoice is identified by a number and indicates the sale date and the price.&lt;/li&gt;
&lt;li&gt;A customer gets an invoice for each car s/he buys.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When a customer takes one or more cars in for repair,
one service ticket is written for each car.
The ticket is identified by a number and
indicates the date on which the car is received from the customer,
as well as the date on which the car should be returned to the customer.
A car brought in for service can be worked on by many mechanics,
and each mechanic may work on many cars.&lt;/p&gt;
&lt;div id=&#34;exercises-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.1&lt;/span&gt; Exercises&lt;/h2&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:command-in-guest&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3.1  &lt;/strong&gt;&lt;/span&gt;Give the &lt;strong&gt;conceptual schema&lt;/strong&gt; of the database with an ER diagram.
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;&lt;img src=&#34;/courses/databases/tutorial-1/car-dealership.png&#34; alt=&#34;Car dealership solution&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-7&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3.2  &lt;/strong&gt;&lt;/span&gt;Translate the conceptual schema into a logical schema.
For each table, underline the primary keys and specify the foreign keys.
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;The &lt;strong&gt;collection of tables&lt;/strong&gt; is the following:&lt;/p&gt;
&lt;pre&gt;
  Car          (&lt;u&gt;serial_number&lt;/u&gt;, make, model, colour, is_new, owner_id)
  Customer     (&lt;u&gt;cust_id&lt;/u&gt;, cust_first_name, cust_last_name, cust_phone)
  Invoice      (&lt;u&gt;invoice_number&lt;/u&gt;, date, price, car_serial_number, sp_id)
  Salesperson  (&lt;u&gt;sp_id&lt;/u&gt;, sp_first_name, sp_last_name)
  Mechanic     (&lt;u&gt;mec_id&lt;/u&gt;, mec_first_name, mec_last_name)
  Ticket       (&lt;u&gt;ticket_number&lt;/u&gt;, date_open, date_return, car_serial_number)
  Repair       (&lt;u&gt;ticket_number&lt;/u&gt;, &lt;u&gt;mec_id&lt;/u&gt;)&lt;/pre&gt;
&lt;/pre&gt;
&lt;p&gt;The &lt;strong&gt;foreign keys&lt;/strong&gt; are the following:&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Car(owner_id)&lt;/TT&gt; → &lt;TT&gt;Customer(cust_id)&lt;/TT&gt;.&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Invoice(car_serial_number)&lt;/TT&gt; → &lt;TT&gt;Car(serial_number)&lt;/TT&gt;.&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Invoice(sp_id)&lt;/TT&gt; → &lt;TT&gt;Salesperson(sp_id)&lt;/TT&gt;.&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Ticket(car_serial_number)&lt;/TT&gt; → &lt;TT&gt;Car(serial_number)&lt;/TT&gt;.&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Repair(ticket_number)&lt;/TT&gt; → &lt;TT&gt;Ticket(ticket_number)&lt;/TT&gt;.&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Repair(mec_id)&lt;/TT&gt; → &lt;TT&gt;Mechanic(mec_id)&lt;/TT&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Getting started with Docker</title>
      <link>/courses/cloud-computing/tutorials/tutorial-docker/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/cloud-computing/tutorials/tutorial-docker/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;p&gt;In this tutorial you’ll learn:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How to run &lt;strong&gt;containers&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;How to define and build &lt;strong&gt;images&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;How to create and use &lt;strong&gt;volumes&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;How to define and use &lt;strong&gt;networks&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prerequisites:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Having installed Docker on your computer.
See the &lt;a href=&#34;/courses/cloud-computing/overview/installing-docker&#34; target=&#34;_blank&#34;&gt;installation guide&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Being familiar with the notions of containers, images,
volumes and networks in Docker.
See the &lt;a href=&#34;/courses/cloud-computing/references/docker-primer&#34; target=&#34;_blank&#34;&gt;Docker primer&lt;/a&gt;
for an introduction.&lt;/li&gt;
&lt;li&gt;Being familiar with the &lt;a href=&#34;/courses/cloud-computing/references/linux-introduction&#34; target=&#34;_blank&#34;&gt;basic notions of Linux&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Don’t hesitate to look at the &lt;a href=&#34;/courses/cloud-computing/references/docker-cheat-sheet&#34; target=&#34;_blank&#34;&gt;Docker cheat sheet&lt;/a&gt;
to verify the syntax of the Docker commands.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Terminology&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;You’ll use the &lt;strong&gt;terminal&lt;/strong&gt; to run Docker commands.
Referring to the
&lt;a href=&#34;/courses/cloud-computing/references/docker-primer#fig:docker-architecture&#34; target=&#34;_blank&#34;&gt;Docker architecture&lt;/a&gt;,
the terminal is the &lt;strong&gt;client&lt;/strong&gt; that communicates with
the Docker daemon.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Docker runs &lt;strong&gt;containers&lt;/strong&gt; on your computer.
We’ll refer to your computer as the &lt;strong&gt;host&lt;/strong&gt;,
the containers being the &lt;strong&gt;guests&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;last-child&#34;&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;strong&gt;containerized application&lt;/strong&gt;
is an application running in a container.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;running&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Running containers&lt;/h1&gt;
&lt;!--The command used to run a container 
is ``docker run`` followed by four parameters:

```shell
docker run [options] image-name [command] [arg]
```

The four parameters are:

* *options*. List of options. 
* *image-name*. The fully qualified name of the image used to run the container. 
* *command*. The command to be executed in the container.
* *arg*. The arguments taken by the command executed in the container.

Only the parameter *image-name* is mandatory. 
The fully qualified name of an image is specified as a sequence of four fields, 
formatted as follows:

```shell
registry_url/user/name:tag
```

where:

* *registry_url* (optional). The URL of the registry that provides the image. 
If its value is not specified, the image 
will be looked up for in the 
[DockerHub registry](https://hub.docker.com){target=&#34;_blank&#34;}.
* *user* (optional).  The identifier of the user or organization that created the image. 
The default value is *library*.
* *name* (mandatory). The name of the image. 
* *tag* (optional). It specifies the image version.
If its value is not specified, 
the tag *latest* is used, pointing to the latest image version. --&gt;
&lt;!--
::: {.infobox .exercisebox data-latex=&#34;{exercisebox}&#34;}
**Exercise**


\BeginKnitrBlock{exercise}&lt;div class=&#34;exercise&#34;&gt;&lt;span class=&#34;exercise&#34; id=&#34;exr:unnamed-chunk-1&#34;&gt;&lt;strong&gt;(\#exr:unnamed-chunk-1) &lt;/strong&gt;&lt;/span&gt;
For each of the following images, 
specify the registry name, the user, the name and the tag.

1. registry.redhat.io/rhel8/mysql-80

2. alpine:3.11

::::: {.last-child}
3. alpine
:::::
&lt;/div&gt;\EndKnitrBlock{exercise}
:::



&lt;details&gt;

&lt;summary&gt;Solution&lt;/summary&gt;

::: {.infobox .exosolution data-latex=&#34;{exercisebox}&#34;}

1. Registry: *registry.redhat.io*, user: *rhel8*, name: *mysql-80*,
tag: *latest*

2. Registry: *DockerHub*, user: *library*, name: *alpine*, tag: *3.11*

3. Registry: *DockerHub*, user: *library*, name: *alpine*, tag: *latest*
:::

&lt;/details&gt;



::: {.infobox .exercisebox data-latex=&#34;{exercisebox}&#34;}
**Exercise**


\BeginKnitrBlock{exercise}&lt;div class=&#34;exercise&#34;&gt;&lt;span class=&#34;exercise&#34; id=&#34;exr:unnamed-chunk-2&#34;&gt;&lt;strong&gt;(\#exr:unnamed-chunk-2) &lt;/strong&gt;&lt;/span&gt;What&#39;s the difference between the following image names?

1. alpine:latest

2. registry.hub.docker.com/library/alpine

::::: {.last-child}
3. alpine
:::::
&lt;/div&gt;\EndKnitrBlock{exercise}


:::


&lt;details&gt;
&lt;summary&gt;Solution&lt;/summary&gt;

::: {.infobox .exosolution data-latex=&#34;{exercisebox}&#34;}

There&#39;s no difference. They all point to the same image, that is
the latest version of *alpine* in the DockerHub registry.

:::

&lt;/details&gt;
--&gt;
&lt;p&gt;We now learn how to use the command &lt;code&gt;docker run&lt;/code&gt; and some of
its options.
In the following exercises, we’ll run containers from the image named
&lt;em&gt;alpine&lt;/em&gt; that is
&lt;a href=&#34;https://hub.docker.com/_/alpine&#34; target=&#34;_blank&#34;&gt;available on the DockerHub registry&lt;/a&gt;.
This image provides a lightweight distribution
(i.e., it doesn’t contain many features) of Linux.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-3&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.1  &lt;/strong&gt;&lt;/span&gt;You want to run the container from the latest version of
the image &lt;em&gt;alpine&lt;/em&gt;.
Which command would you write in the terminal?
Execute it.
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;The goal of this exercise is to start playing with the
&lt;code&gt;docker run&lt;/code&gt; command.
Since the question doesn’t say anything about the
options, nor does it mention the command to run inside the container,
we’d type:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker run alpine&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;!--::: {.infobox .exercisebox data-latex=&#34;{exercisebox}&#34;}
**Exercise**


\BeginKnitrBlock{exercise}&lt;div class=&#34;exercise&#34;&gt;&lt;span class=&#34;exercise&#34; id=&#34;exr:unnamed-chunk-4&#34;&gt;&lt;strong&gt;(\#exr:unnamed-chunk-4) &lt;/strong&gt;&lt;/span&gt;Execute the command that you proposed in the previous exercise, 
observe the output in the terminal and explain the actions 
taken by Docker to run the container.&lt;/div&gt;\EndKnitrBlock{exercise}


:::


&lt;details&gt;
&lt;summary&gt;Solution&lt;/summary&gt;

::: {.infobox .exosolution data-latex=&#34;{exercisebox}&#34;}

The output obtained from executing the command should 
look like as follows:

```bash
Unable to find image &#39;alpine:latest&#39; locally
latest: Pulling from library/alpine
aad63a933944: Pull complete 
Digest: sha256:b276d875eeed9c7d3f1cfa7edb06b22ed22b14219a7d67c52c56612330348239
Status: Downloaded newer image for alpine:latest
```

Here&#39;s what happens under the hood:

1. Docker looks for an image named *alpine:latest* in the host 
computer and cannot find it.

2. Docker *pulls* (i.e., downloads) the image from the DockerHub registry.

:::

&lt;/details&gt;--&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-5&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.2  &lt;/strong&gt;&lt;/span&gt;Is the container still running?
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;In order to list all containers still running on the host, type the
following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker container ls&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Your container shouldn’t appear in the output,
because it’s not running.
In order to see all containers, including those that are not
running, type the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker container ls -a&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;!--::: {.infobox .exercisebox data-latex=&#34;{exercisebox}&#34;}
**Exercise**


\BeginKnitrBlock{exercise}&lt;div class=&#34;exercise&#34;&gt;&lt;span class=&#34;exercise&#34; id=&#34;exr:unnamed-chunk-6&#34;&gt;&lt;strong&gt;(\#exr:unnamed-chunk-6) &lt;/strong&gt;&lt;/span&gt;What information is displayed for each container?&lt;/div&gt;\EndKnitrBlock{exercise}

:::


&lt;details&gt;
&lt;summary&gt;Solution&lt;/summary&gt;

::: {.infobox .exosolution data-latex=&#34;{exercisebox}&#34;}

* The identifier of the container.

* The name of the image used to run the container (it should be *alpine* for your 
container).

* The command executed within the container (it should be ``/bin/sh`` for your container).

* When the container has been created.

* The container current status (it should be *exited (0) x seconds ago* for your container).

* The network ports used by the container (we&#39;ll study them later).

* The name of the container. If you don&#39;t specify any when you 
run the container (as is our case),
Docker generates a random name by concatenating an adjective and 
a famous scientist&#39;s name (e.g., *agitated_newton*).

:::

&lt;/details&gt;--&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-7&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.3  &lt;/strong&gt;&lt;/span&gt;By looking at the command executed within the container (&lt;code&gt;/bin/sh&lt;/code&gt;),
can you tell why the container stopped without giving any output?
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;The command is &lt;code&gt;/bin/sh&lt;/code&gt;;
the container runs a Linux terminal.
But since we didn’t specify what to do with that terminal
(we didn’t run any Linux command, nor we tried to access the terminal),
the container stopped.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;p&gt;We’re now going to do something useful with the image &lt;em&gt;alpine&lt;/em&gt;.
Make sure you read the &lt;strong&gt;good practices&lt;/strong&gt; that you should
adopt while playing with images and containers.&lt;/p&gt;
&lt;div class=&#34;infobox curiosity&#34;&gt;
&lt;p&gt;&lt;strong&gt;Good practices&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Name your containers.&lt;/strong&gt; Although Docker assigns a default name to a new container,
it’s usually a good practice to give a container a name of your
choice to make it easily distinguishable. You can do it by using the option
&lt;code&gt;--name&lt;/code&gt;. Try the following:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;docker run --name my-alpine alpine&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;As before, the container stops immediately.
If you list all your containers by typing again:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker container ls -a&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;you should see a container named &lt;em&gt;my-alpine&lt;/em&gt;.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Remove automatically a container if you use it once.&lt;/strong&gt;
Unless you want to reuse your container later, you can ask Docker to automatically remove it
when it stops by using the option &lt;code&gt;--rm&lt;/code&gt;.
This will prevent unused containers from taking up too much disk space.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Try the following:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker run --rm --name container-to-remove alpine&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If you list all the containers you should see that there is no container
named &lt;em&gt;container-to-remove&lt;/em&gt;.&lt;/p&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Remove unused containers.&lt;/strong&gt; Stopped containers that have been run without
using the option &lt;code&gt;--rm&lt;/code&gt; are still stored in the host.
If you want to remove a specific
container (e.g., &lt;em&gt;my-alpine&lt;/em&gt;), use the following command:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;docker container rm my-alpine&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If you want to remove all stopped containers, use the
following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker container prune&lt;/code&gt;&lt;/p&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Remove unused images.&lt;/strong&gt; Images can take up a lot of disk space.
As a result, you should remember to remove those that you don’t intend to use
any longer.
The commands to remove a specific image
and prune unused ones are &lt;code&gt;docker image rm&lt;/code&gt;
and &lt;code&gt;docker image prune -a&lt;/code&gt; respectively.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;pass-a-command-to-the-containerized-application&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.1&lt;/span&gt; Pass a command to the containerized application&lt;/h2&gt;
&lt;p&gt;Remember that the template of &lt;code&gt;docker run&lt;/code&gt; is the following:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker run [options] image-name [command] [arg]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The optional parameter &lt;em&gt;command&lt;/em&gt; refers to a command
that you can pass the containerized application, possibly with some arguments
(parameter &lt;em&gt;arg&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;Let’s see an example.
As we saw before, when we run a container from the image &lt;em&gt;alpine&lt;/em&gt;,
a Linux terminal &lt;code&gt;/bin/sh&lt;/code&gt; is launched.&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Notice&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Linux terminal &lt;code&gt;/bin/sh&lt;/code&gt; is run within the
container.
Henceforth, we’ll use the following terms:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Host terminal.&lt;/strong&gt; The terminal that you use to
interact with the operating system of your computer.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;last-child&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Guest terminal.&lt;/strong&gt; The terminal that is run within
the container.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;By using the optional parameter &lt;em&gt;command&lt;/em&gt;, we can run
a command in the guest terminal.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:command-in-guest&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.4  &lt;/strong&gt;&lt;/span&gt;
Run a container from the image &lt;em&gt;alpine&lt;/em&gt; and execute the
Linux command &lt;code&gt;ls&lt;/code&gt; that lists the content of the current directory.&lt;/p&gt;
&lt;div class=&#34;last-child&#34;&gt;
&lt;ul&gt;
&lt;li&gt;Where are the listed files stored?
In the host or in the container?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;&lt;code&gt;docker run --rm --name ls-test alpine ls&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The command &lt;code&gt;ls&lt;/code&gt; is run in the guest terminal, therefore
what we see in the output is a list of files stored in the
container.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Notice&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In Exercise &lt;a href=&#34;#exr:command-in-guest&#34;&gt;1.4&lt;/a&gt; the command
&lt;code&gt;ls&lt;/code&gt; is executed in the guest terminal, but its
output is redirected to the host terminal.&lt;/p&gt;
&lt;p&gt;In other words, when we run the container, we
don’t interact directly with the guest terminal;
we just send a command and the output is redirected
to the host terminal.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Now let’s see how to execute a command in the guest terminal
that also requires an argument.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-8&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.5  &lt;/strong&gt;&lt;/span&gt;By using the Linux utility &lt;code&gt;ping&lt;/code&gt;, check
whether the Web site &lt;code&gt;www.centralesupelec.fr&lt;/code&gt; is reachable.
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;&lt;code&gt;docker run --rm --name ping-test alpine ping www.centralesupelec.fr&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;In order to interrupt &lt;code&gt;ping&lt;/code&gt;
just type the key combination that you’s use to
interrupt any other command in your terminal.
(typically Ctrl-C on Windows and Cmd-C in MacOs).&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;!--An application running in a container might need to interact 
with the user. 
For instance, the Linux 
command ``rev`` reverses whatever 
the user types on the keyboard.
In order to interact with a container, you should use the option
``-it`` of ``docker run``.


::: {.infobox .exercisebox data-latex=&#34;{exercisebox}&#34;}
**Exercise**


\BeginKnitrBlock{exercise}&lt;div class=&#34;exercise&#34;&gt;&lt;span class=&#34;exercise&#34; id=&#34;exr:unnamed-chunk-9&#34;&gt;&lt;strong&gt;(\#exr:unnamed-chunk-9) &lt;/strong&gt;&lt;/span&gt;Run a container from the image *alpine* to execute the 
Linux command `rev` and interact with it.
You can stop interacting with ``rev`` by typing Ctrl+C at any time.&lt;/div&gt;\EndKnitrBlock{exercise}


:::
&lt;details&gt;
&lt;summary&gt;Solution&lt;/summary&gt;

::: {.infobox .exosolution data-latex=&#34;{exercisebox}&#34;}

``
docker run --rm --name rev -it alpine rev
``

After typing the command, type a word on your keyboard
(e.g., *deeps*), press *Return* and 
you should see the same word reversed (e.g., *speed*). 

The option ``-t`` opens a guest terminal (so we can see its
output); the option ``-i`` allows you to write directly 
into the guest terminal.

In order to stop using the guest terminal, 
you&#39;ll need to press Ctrl+D (both in Windows and MacOs).

:::

&lt;/details&gt;

--&gt;
&lt;p&gt;Now run the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker run  --name my-alpine -it alpine&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; we didn’t use the option &lt;code&gt;--rm&lt;/code&gt; (the container will not be removed
when we stop it, we’re going to use it again).
Moreover, we didn’t specify any command to run in the guest terminal.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-10&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.6  &lt;/strong&gt;&lt;/span&gt;What do you obtain?
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;When we run a container from the image &lt;em&gt;alpine&lt;/em&gt;, the command
&lt;code&gt;/bin/sh&lt;/code&gt; is executed within the container.
Since we specified the option &lt;code&gt;-it&lt;/code&gt;, what we obtain is an access to the
Linux terminal running in the container.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;starting-and-stopping-containers.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.2&lt;/span&gt; Starting and stopping containers.&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;docker run&lt;/code&gt; is a shorthand for two Docker commands, namely
&lt;code&gt;docker create&lt;/code&gt;, that creates a container from an image,
and &lt;code&gt;docker start&lt;/code&gt;, that starts the container after its creation.&lt;/p&gt;
&lt;p&gt;Suppose now that you want to download a Web page
by using Linux Alpine.
You can use the Linux command &lt;code&gt;wget&lt;/code&gt; followed by the URL of the page
that you want to download.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:wget-exo&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.7  &lt;/strong&gt;&lt;/span&gt;By using the guest terminal
in the container &lt;em&gt;my-alpine&lt;/em&gt;,
download
&lt;a href=&#34;https://www.centralesupelec.fr/fr/presentation&#34; target=&#34;_blank&#34;&gt;this Web page&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;last-child&#34;&gt;
&lt;ul&gt;
&lt;li&gt;Where will the Web page be saved? The host computer or the container?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;Just type in &lt;em&gt;my-alpine&lt;/em&gt; guest terminal the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;wget https://www.centralesupelec.fr/fr/presentation&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Web page will be saved in the current directory
of the container. You can verify that the file is there
by typing &lt;code&gt;ls&lt;/code&gt; in the guest terminal.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;p&gt;In &lt;em&gt;my-alpine&lt;/em&gt; guest terminal type &lt;code&gt;exit&lt;/code&gt;.
This closes the guest terminal and, as a result, stops the
container.&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;NOTICE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Stopping the container will not erase any of the files
stored in the container. Removing the container will.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;If you want to start the container &lt;em&gt;my-alpine&lt;/em&gt; again, you can
use the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker container start -ai my-alpine&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This will open the guest terminal of the container again;
type &lt;code&gt;ls&lt;/code&gt; to verify that
the Web page that you downloaded before is still there.&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Homework (optional)&lt;/summary&gt;&lt;/p&gt;
&lt;p&gt;Suppose that you need to download all the figures of
&lt;a href=&#34;https://www.centralesupelec.fr/fr/presentation&#34; target=&#34;_blank&#34;&gt;this Web page&lt;/a&gt;.
The Linux utility &lt;code&gt;wget&lt;/code&gt; comes in handy.
However, you don’t have Linux and you’d like to
avoid the hassle of installing it on your computer, or in a virtual machine,
just for this task.&lt;/p&gt;
&lt;p&gt;A great alternative is to run Linux in a Docker container.
Unfortunately, the Alpine distribution that we’ve been playing
with doesn’t provide
an implementation of &lt;code&gt;wget&lt;/code&gt; with all the options that we need.&lt;/p&gt;
&lt;p&gt;We turn to another Linux distribution, &lt;strong&gt;Ubuntu&lt;/strong&gt;,
for which DockerHub has
&lt;a href=&#34;https://hub.docker.com/_/ubuntu/&#34; target=&#34;_blank&#34;&gt;several images&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-11&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.8  &lt;/strong&gt;&lt;/span&gt;Run a container with Ubuntu (latest) and open a guest terminal.
Call the container &lt;em&gt;dl-figures&lt;/em&gt;, and avoid the option
&lt;code&gt;--rm&lt;/code&gt;, we’ll use this container later.
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;&lt;code&gt;docker run --name dl-figures -it ubuntu&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;p&gt;From now on, we’ll be interacting with the guest Ubuntu terminal.
If you type the command &lt;code&gt;wget&lt;/code&gt;,
you’ll get an error (&lt;code&gt;bash: wget: command not found&lt;/code&gt;).&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Notice&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The image &lt;em&gt;Ubuntu&lt;/em&gt; doesn’t include all the commands that you’d find
in a full-blown Ubuntu distribution;
the reason is to keep the size of the image small,
a necessary constraint given that
images are transferred over the Internet.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Luckily, there’s a way to install &lt;code&gt;wget&lt;/code&gt; in our Ubuntu distribution.
Ubuntu provides a powerful command-line package manager called
&lt;strong&gt;Advanced Package Tool&lt;/strong&gt; (APT).
First, you need to run the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;apt-get update&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;which fetches the available packages from a list of sources
available in file &lt;code&gt;/etc/apt/sources.list&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Then, you can install &lt;code&gt;wget&lt;/code&gt; by running the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;apt-get install -y wget&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;In order to obtain all the figures from a
Web page, type the following command:&lt;/p&gt;
&lt;pre class=&#34;shell&#34;&gt;&lt;code&gt;wget -nd -H -p -P /my-figures -A jpg,jpeg,png,gif -e robots=off -w 0.5 https://www.centralesupelec.fr/fr/presentation&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should see in the current directory a new folder
named &lt;em&gt;my-figures&lt;/em&gt; containing the downloaded figures;
verify it by typing &lt;code&gt;ls my-figures&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Before terminating, don’t forget to read your fortune cookie.
In the shell, run the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;apt-get install -y fortune&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;and then:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;/usr/games/fortune -s&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;When you’re done, you can simply type the command &lt;code&gt;exit&lt;/code&gt; to quit
the guest terminal and stop the container.&lt;/p&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-images&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; Creating Images&lt;/h1&gt;
&lt;p&gt;A Docker image can be thought of as a template to create and run a container.
An image is a file that contains a &lt;strong&gt;layered filesystem&lt;/strong&gt; with each layer being &lt;strong&gt;immutable&lt;/strong&gt;;
this means that the files that belong to a layer cannot be
modified or deleted, nor can files be added to a layer.&lt;/p&gt;
&lt;p&gt;When a container is created from an image, it
will be composed of all the image read-only layers and, on top of
them, a writable layer (termed the &lt;strong&gt;container layer&lt;/strong&gt;),
where all the new files created in the container will be written.
For example, the Web page that you downloaded in Exercise &lt;a href=&#34;#exr:wget-exo&#34;&gt;1.7&lt;/a&gt;
were stored in the writable layer of that container (cf &lt;a href=&#34;https://centralesupelec.edunao.com/mod/resource/view.php?id=50468&#34; target=&#34;_blank&#34;&gt;Slide 64&lt;/a&gt;).&lt;/p&gt;
&lt;!--## Interactive image creation

When we run the container *dl-figures*  in Section \@ref(simple-use-case), 
we modified the container to
install the command ``wget``. 
You can see the modifications by typing the 
following command:

``
docker diff dl-figures
``

The output consists of a list of files tagged with the letter A, C or D, indicating 
respectively that the file has been added (A), changed (C) or deleted (D). 
In this list you&#39;ll find the downloaded figures, as well as 
other files that have been added or modified or deleted 
when we installed ``wget``.

::: {.infobox .exercisebox data-latex=&#34;{exercisebox}&#34;}
**Exercise**


\BeginKnitrBlock{exercise}&lt;div class=&#34;exercise&#34;&gt;&lt;span class=&#34;exercise&#34; id=&#34;exr:unnamed-chunk-12&#34;&gt;&lt;strong&gt;(\#exr:unnamed-chunk-12) &lt;/strong&gt;&lt;/span&gt;If layers, except the top one, are immutable, 
how can files that belong to the lower layers be modified or deleted?&lt;/div&gt;\EndKnitrBlock{exercise}
:::

&lt;details&gt;
&lt;summary&gt;Solution&lt;/summary&gt;

::: {.infobox .exosolution data-latex=&#34;{exercisebox}&#34;}

All files marked with A are new and therefore are 
added to the writable layer of the container.

As for the existing files, they live in the immutable layers 
of the image, and therefore cannot be touched directly. 
Instead, they are copied from the bottom layers to the writable layer where 
they are modified.
This strategy is called **copy-on-write**.

The structure of layers generates a **layered filesystem** in the image; 
if different copies of the same file exist in different layers, 
the copy in the uppermost layer 
overwrites the others.

:::

&lt;/details&gt;



We can create a new image from the container *dl-figures*, one that provides
a Ubuntu distribution with the command ``wget`` already installed, 
with the following command:


```shell
docker commit dl-figures ubuntu-with-wget
```

The command creates a new image called *ubuntu-with-wget*.

::: {.infobox .exercisebox data-latex=&#34;{exercisebox}&#34;}
**Exercise**


\BeginKnitrBlock{exercise}&lt;div class=&#34;exercise&#34;&gt;&lt;span class=&#34;exercise&#34; id=&#34;exr:unnamed-chunk-14&#34;&gt;&lt;strong&gt;(\#exr:unnamed-chunk-14) &lt;/strong&gt;&lt;/span&gt;Run a container from the image *ubuntu-with-wget* and verify that the command
*wget* is actually installed. &lt;/div&gt;\EndKnitrBlock{exercise}

:::

&lt;details&gt;
&lt;summary&gt;Solution&lt;/summary&gt;

::: {.infobox .exosolution data-latex=&#34;{exercisebox}&#34;}

Just type the following command:

``
docker run --rm -it ubuntu-with-wget
``
In the guest terminal type ``wget``: you should see the 
following output:

``
wget: missing URL
Usage: wget [OPTION]... [URL]...

Try `wget --help` for more options.
``

:::

&lt;/details&gt;--&gt;
&lt;div id=&#34;dockerfiles&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.1&lt;/span&gt; Dockerfiles&lt;/h2&gt;
&lt;p&gt;The most common way to create an image is to use a &lt;strong&gt;Dockerfile&lt;/strong&gt;, a
text file that contains all the instructions necessary to
build the image.
The advantage of the Dockerfile is that it can be interpreted
by the Docker engine, which makes the creation of images an automated
and repeatable task.&lt;/p&gt;
&lt;p&gt;Suppose that we want to create a containerized
application to download figures from a Web page.
As a template for this application, we need to build a new
image, that we’ll call &lt;em&gt;fig-downloader&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The Dockerfile containing the instructions to build the image
&lt;em&gt;fig-downloader&lt;/em&gt; is as follows:&lt;/p&gt;
&lt;pre class=&#34;dockerfile&#34;&gt;&lt;code&gt;FROM ubuntu
RUN apt-get update
RUN apt-get install -y wget
RUN mkdir -p /my-figures
WORKDIR /my-figures
ENTRYPOINT [&amp;quot;wget&amp;quot;, &amp;quot;-nd&amp;quot;, &amp;quot;-r&amp;quot;, &amp;quot;-A&amp;quot;, &amp;quot;jpg,jpeg,bmp,png,gif&amp;quot;]
CMD [&amp;quot;https://www.centralesupelec.fr/fr/presentation&amp;quot;]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s the explanation:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;We use the image &lt;em&gt;ubuntu&lt;/em&gt; as the &lt;strong&gt;base image&lt;/strong&gt;.
This corresponds to the instruction &lt;code&gt;FROM ubuntu&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We install the utility &lt;code&gt;wget&lt;/code&gt; in the base image.
This corresponds to the
instructions &lt;code&gt;RUN apt-get update&lt;/code&gt; and &lt;code&gt;RUN apt-get install -y wget&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We create a directory &lt;code&gt;my-figures&lt;/code&gt; under the root directory of the image.
This corresponds to the instruction &lt;code&gt;RUN mkdir -p /my-figures&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We set the newly created directory &lt;em&gt;/my-figures&lt;/em&gt; as the
&lt;strong&gt;working directory&lt;/strong&gt; of the image. This corresponds to the
instruction &lt;code&gt;WORKDIR /my-figures&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We specify the command to be executed when a container is run from this image.
This corresponds to the instruction&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;ENTRYPOINT [&amp;quot;wget&amp;quot;, &amp;quot;-nd&amp;quot;, &amp;quot;-r&amp;quot;, &amp;quot;-A&amp;quot;, &amp;quot;jpg,jpeg,bmp,png,gif&amp;quot;]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This instruction means: execute &lt;code&gt;wget&lt;/code&gt; with the options
&lt;code&gt;-nd&lt;/code&gt;, &lt;code&gt;-r&lt;/code&gt;, &lt;code&gt;-A&lt;/code&gt;;
the last option takes a list of file
extensions (&lt;code&gt;jpg,jpeg,bmp,png,gif&lt;/code&gt;) as its argument.&lt;/p&gt;
&lt;ol start=&#34;6&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Remember that the utility &lt;code&gt;wget&lt;/code&gt; takes the URL of the Web page as
an argument. The URL will be specified when we run the container from
the image &lt;em&gt;fig-downloader&lt;/em&gt;.
Optionally, we can specify a default argument by using the
keyword CMD. The meaning of the instruction:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;CMD [&amp;quot;https://www.centralesupelec.fr/fr/presentation&amp;quot;]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;is: if we don’t give any URL when we run the container, the figures will
be downloaded from
&lt;a href=&#34;https://www.centralesupelec.fr/fr/presentation&#34; class=&#34;uri&#34; target=&#34;_blank&#34;&gt;https://www.centralesupelec.fr/fr/presentation&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-15&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.1  &lt;/strong&gt;&lt;/span&gt;What’s the relation between the Dockerfile lines and the image layers?
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;Each line corresponds to a new layer.
The first line corresponds to the bottom layer;
the last line to the top layer.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:dockerfile-creation&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.2  &lt;/strong&gt;&lt;/span&gt;Could you identify a problem in this Dockerfile?
Modify the Dockerfile accordingly.
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;When creating an image, we should keep the number of layers relatively
small; in fact, the more the layers, the bigger the image will be.
Here we create three separate layers with three RUN commands; we can
simply merge the three layers.
The resulting Dockerfile will be:&lt;/p&gt;
&lt;pre class=&#34;dockerfile&#34;&gt;&lt;code&gt;FROM ubuntu
RUN apt-get update &amp;amp;&amp;amp; \
    apt-get install -y wget &amp;amp;&amp;amp; \
    mkdir -p /my-figures
WORKDIR /my-figures
ENTRYPOINT [&amp;quot;wget&amp;quot;, &amp;quot;-nd&amp;quot;, &amp;quot;-r&amp;quot;, &amp;quot;-A&amp;quot;, &amp;quot;jpg,jpeg,bmp,png,gif&amp;quot;]
CMD [&amp;quot;https://www.centralesupelec.fr/fr/presentation&amp;quot;]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;building-an-image&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.2&lt;/span&gt; Building an image&lt;/h2&gt;
&lt;p&gt;We’re now going to build an image from a Dockerfile.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Create a directory named &lt;em&gt;fig-downloader&lt;/em&gt; in your computer with
a file named &lt;em&gt;Dockerfile&lt;/em&gt; inside.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In the &lt;em&gt;Dockerfile&lt;/em&gt; write the set of instructions that
you proposed in Exercise &lt;a href=&#34;#exr:dockerfile-creation&#34;&gt;2.2&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In the terminal, set the working directory to &lt;em&gt;fig-downloader&lt;/em&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Build an image called &lt;em&gt;fig-downloader&lt;/em&gt; by executing the following command:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;docker build -t fig-downloader .&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;.&lt;/code&gt; at the end of the command means that the Docker engine will
look for a file named &lt;em&gt;Dockerfile&lt;/em&gt; in the working directory.&lt;/p&gt;
&lt;!--

::: {.infobox .exercisebox data-latex=&#34;{exercisebox}&#34;}
**Exercise**


\BeginKnitrBlock{exercise}&lt;div class=&#34;exercise&#34;&gt;&lt;span class=&#34;exercise&#34; id=&#34;exr:unnamed-chunk-16&#34;&gt;&lt;strong&gt;(\#exr:unnamed-chunk-16) &lt;/strong&gt;&lt;/span&gt;Once the image is built, type the command ``docker image ls -a``. 
What are the images with repository and tag ``&lt;none&gt;``?
Why are there three of such images?&lt;/div&gt;\EndKnitrBlock{exercise}


:::

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;Solution&lt;/summary&gt;

::: {.infobox .exosolution data-latex=&#34;{exercisebox}&#34;}

These are the **intermediate images**. 
Once a layer is compiled, an intermediate image is created that 
contains that layer and all the layers underneath.
In other words, the intermediate image 
corresponding to the layer $i$ contains all files 
up to the layer $i$, including layers 1 through $i-1$.

The intermediate layers are used by the **build cache**, 
of which we&#39;ll see an example later.

Although there are five layers in the new image, there are only 
three intermediate images because:

* the base image is *ubuntu:eoan*.
* the image corresponding to the top layer is the final image *fig-downloader*.

:::

&lt;/details&gt;
--&gt;
&lt;div class=&#34;infobox curiosity&#34;&gt;
&lt;p&gt;&lt;strong&gt;Good to know&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If you give the Dockerfile a different name (say, &lt;em&gt;Dockerfile-fig-downloader&lt;/em&gt;),
the command to build the image will be:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker build -t fig-downloader -f Dockerfile-fig-downloader .&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The option &lt;code&gt;-f&lt;/code&gt; is used to specify the name of the Dockerfile.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In order to verify that the new image has been created, type the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker images&lt;/code&gt;&lt;/p&gt;
&lt;!-- Let&#39;s dive deeper into the anatomy of an image.

::: {.infobox .exercisebox data-latex=&#34;{exercisebox}&#34;}
**Exercise**


\BeginKnitrBlock{exercise}&lt;div class=&#34;exercise&#34;&gt;&lt;span class=&#34;exercise&#34; id=&#34;exr:unnamed-chunk-17&#34;&gt;&lt;strong&gt;(\#exr:unnamed-chunk-17) &lt;/strong&gt;&lt;/span&gt;Run the following command:

``
docker history fig-downloader
`` 

and analyze the layers of the new image. 

* Why do some layers have an ID, while others 
are marked as &lt;i&gt;missing&lt;/i&gt;?

::::: {.last-child}
* Can you find the identifiers of the intermediate images?
:::::
&lt;/div&gt;\EndKnitrBlock{exercise}


:::

&lt;details&gt;
&lt;summary&gt;Solution&lt;/summary&gt;

::: {.infobox .exosolution data-latex=&#34;{exercisebox}&#34;}

The layers with an ID correspond to the layers of 
the new image, including the top layer and the base image.
The layers marked as *missing* are those that compose the 
base image. Those layers are not stored in  
your computer, 
simply because they belong to an image 
that hasn&#39;t been built on your computer 
and you downloaded from the DockerHub registry.

By looking at the output of ``docker image ls -a`` and the output of this command,
we see that the layers between the base image and the top layer have the 
same identifiers as the intermediate images.

:::

&lt;/details&gt;

--&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:dl-1-container&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.3  &lt;/strong&gt;&lt;/span&gt;Run the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker run --name dl-1 fig-downloader&lt;/code&gt;&lt;/p&gt;
What does it do? Where are the downloaded pictures?
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;We downloaded the figures
&lt;a href=&#34;https://www.centralesupelec.fr/fr/presentation&#34; target=&#34;_blank&#34;&gt;of this page&lt;/a&gt;.
The downloaded pictures are in the folder &lt;em&gt;/my-figures&lt;/em&gt;
of the container &lt;em&gt;dl-1&lt;/em&gt;.
For now, don’t worry about accessing them.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-18&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.4  &lt;/strong&gt;&lt;/span&gt;Run the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run --name dl-2 fig-downloader https://www.centralesupelec.fr/&lt;/code&gt;&lt;/pre&gt;
What does it do? Where are the downloaded pictures?
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;We downloaded the figures
&lt;a href=&#34;https://www.centralesupelec.fr&#34; target=&#34;_blank&#34;&gt;of this page&lt;/a&gt;.
We basically overwrote the URL specified by the CMD keyword with a new
one.
The downloaded pictures are in the folder &lt;em&gt;/my-figures&lt;/em&gt;
of the container &lt;em&gt;dl-2&lt;/em&gt;.
For now, don’t worry about accessing these figures.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;containerized-python-application&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.3&lt;/span&gt; Containerized Python application&lt;/h2&gt;
&lt;p&gt;Download &lt;a href=&#34;/courses/cloud-computing/tutorial-docker/word-frequency.zip&#34;&gt;this archive file&lt;/a&gt;
and unzip it into your working directory.
In this archive you’ll find:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A Dockerfile.&lt;/li&gt;
&lt;li&gt;A Python script &lt;em&gt;main.py&lt;/em&gt; that asks the user to enter the URL and the language of a Web page,
and prints the 10 most frequent words occurring in that page.&lt;/li&gt;
&lt;li&gt;A file &lt;em&gt;requirements.txt&lt;/em&gt; with the list of the Python packages
needed to run the given script.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The content of the Dockerfile is as follows:&lt;/p&gt;
&lt;pre class=&#34;dockerfile&#34;&gt;&lt;code&gt;FROM python:3.7-slim
RUN mkdir -p /app
WORKDIR /app
COPY ./main.py ./requirements.txt /app/
RUN pip install -r requirements.txt
ENTRYPOINT [&amp;quot;python&amp;quot;, &amp;quot;main.py&amp;quot;]&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-19&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.5  &lt;/strong&gt;&lt;/span&gt;Describe what this Dockerfile does.
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;ul&gt;
&lt;li&gt;Takes &lt;em&gt;python:3.7-slim&lt;/em&gt; as the base image.&lt;/li&gt;
&lt;li&gt;Creates a new folder &lt;em&gt;app&lt;/em&gt; in the image under the root directory.&lt;/li&gt;
&lt;li&gt;Changes the working directory to &lt;em&gt;/app&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Copies the files &lt;em&gt;main.py&lt;/em&gt; and &lt;em&gt;requirements.txt&lt;/em&gt; from the local
computer to the directory &lt;em&gt;/app&lt;/em&gt; in the image.&lt;/li&gt;
&lt;li&gt;Runs the command &lt;code&gt;pip install&lt;/code&gt; to install the Python libraries
specified in the file &lt;em&gt;requirements.txt&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Executes the command &lt;code&gt;python main.py&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34; word-latex=&#34;{exercisebox}&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-20&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.6  &lt;/strong&gt;&lt;/span&gt;Build an image called &lt;em&gt;wordfreq&lt;/em&gt; from this Dockerfile.
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;&lt;code&gt;docker build -t wordfreq .&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-21&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.7  &lt;/strong&gt;&lt;/span&gt;Without changing the Dockerfile, rebuild the same image.
What do you notice?
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;The build is very fast.
Since we didn’t change the Dockerfile, the image
is rebuilt by using the image layers created
previously.
This is clearly indicated by the phrase &lt;strong&gt;using cache&lt;/strong&gt; written
at each layer.
Using the already stored layers is called &lt;strong&gt;build cache&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-22&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.8  &lt;/strong&gt;&lt;/span&gt;What happens if you modify a line in the Python script and
you rebuild the image?
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;Add any instruction at the end of &lt;em&gt;main.py&lt;/em&gt;, such as:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;print(&amp;quot;Finish!&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;then rebuild the image.
The three bottom layers are not affected by the modification, therefore
they benefit from the build cache.
Layer 4 is the first affected by the modification.
This layer, and those above, need therefore to be
rebuilt.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-23&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.9  &lt;/strong&gt;&lt;/span&gt;Based on the previous considerations,
can you tell what’s wrong with this Dockerfile?
Modify the Dockerfile accordingly and rebuild the image.
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;Each time we modify &lt;em&gt;main.py&lt;/em&gt; and we rebuild the image,
the layer 4 and 5 are recreated, meaning that all the Python packages
are downloaded and installed.
Depending on the size and number of the packages, this might
take some while.
A better way to structure the Dockerfile is to install the
packages before copying the Python script to the image.
Here is how we should modify the Dockerfile:&lt;/p&gt;
&lt;pre class=&#34;dockerfile&#34;&gt;&lt;code&gt;FROM python:3.7-slim
RUN mkdir -p /app
WORKDIR /app
COPY ./requirements.txt /app/
RUN pip install -r requirements.txt
COPY ./main.py /app/
ENTRYPOINT [&amp;quot;python&amp;quot;, &amp;quot;main.py&amp;quot;]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-24&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.10  &lt;/strong&gt;&lt;/span&gt;Modify &lt;em&gt;main.py&lt;/em&gt; by adding a new line of code and rebuild the image.
What changed?
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;The Python packages are not reinstalled, as a result rebuilding the image&lt;br /&gt;
takes much less time than before.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;p&gt;Play with the application by running the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker run --rm -it  wordfreq&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The containerized application will prompt you to insert the URL of a webpage and
the language of the page (in English).
The output will be the 20 most used words in the webpage.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-volumes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; Data Volumes&lt;/h1&gt;
&lt;p&gt;In Exercise &lt;a href=&#34;#exr:dl-1-container&#34;&gt;2.3&lt;/a&gt; you’ve been asked to run a container named
&lt;em&gt;dl-1&lt;/em&gt; to download some figures from a Web page.
The figures were downloaded into the
directory &lt;em&gt;/my-figures&lt;/em&gt; of the container.
But we left a question unanswered.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How do we transfer those figures from the container to the host computer?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The solution is to use &lt;strong&gt;volumes&lt;/strong&gt;.&lt;/p&gt;
&lt;!--One way to go about that is to run the following command in the host terminal:

``
docker cp dl-1:/my-figures .
``

This will copy the directory */my-figures* from the container *dl-1* to
the host computer working directory.
You can verify it by yourself.

::: {.infobox .exercisebox data-latex=&#34;{exercisebox}&#34;}
**Exercise**


\BeginKnitrBlock{exercise}&lt;div class=&#34;exercise&#34;&gt;&lt;span class=&#34;exercise&#34; id=&#34;exr:unnamed-chunk-25&#34;&gt;&lt;strong&gt;(\#exr:unnamed-chunk-25) &lt;/strong&gt;&lt;/span&gt;Can you tell why this solution is less than ideal?&lt;/div&gt;\EndKnitrBlock{exercise}


:::
&lt;details&gt;
&lt;summary&gt;Solution&lt;/summary&gt;

::: {.infobox .exosolution data-latex=&#34;{exercisebox}&#34;}

1. After running the container we need to do an additional action to copy
the figures from the container to the host computer.

2. The container is created and run only to download some figures.
We&#39;d like to remove it automatically (with the option ``--rm``) when its 
execution is over. However, if we do so, the pictures will be lost before 
we can copy them to the host computer.

:::

&lt;/details&gt;

## Using a host volume

A better solution is to **mount** (i.e., attach) 
a directory of the host computer at the container&#39;s directory 
*/my-figures* when we run it.
Let&#39;s see how it works.

**Step 1.** Create a directory named *figs-volume* in your working directory.

**Step 2.** Type and execute the following command:

```shell
docker run --rm -v $(pwd)/figs-volume:/my-figures fig-downloader
```

This command runs a container from the image *fig-downloader*. 

* With the option ``-v`` we specify  that we want to mount the directory
*\$(pwd)/figs-volume* (*\$(pwd)* indicates the host working directory)
at the directory *figs-volume* in the container;

* The option ``--rm`` indicates that we want the container to be 
removed when its execution is over.

**Step 3.** Verify that the pictures are in the folder *figs-volume*.

In this example, we&#39;ve used the directory *figs-volume* as a 
**volume** (essentially, an external storage area) of the container;
when the container is destroyed, the volume remains with all its data.--&gt;
&lt;div id=&#34;docker-volumes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.1&lt;/span&gt; Docker volumes&lt;/h2&gt;
&lt;p&gt;A volume can be seen as a virtual storage device attached to a container.
All files there are written to a volume survive the containerized application that
created them. In other words, when a container is destroyed,
all the files created by the application in the container remain in the volume.&lt;/p&gt;
&lt;p&gt;Let’s create a new Docker volume called &lt;em&gt;data-volume&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker volume create data-volume&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;infobox curiosity&#34;&gt;
&lt;p&gt;&lt;strong&gt;Good to know (advanced notion)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Where the data will be actually stored?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You can inspect the new volume by typing the
following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker volume inspect data-volume&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;A &lt;em&gt;mount point&lt;/em&gt; is indicated; that’s the folder where the data
will be actually stored.
If your computer runs Linux, that folder will be available
on the host; if your computer runs Windows or MacOS,
you’ll not find that folder on your computer.
Instead, it will be available in the virtual machine
that Docker use on MacOS and Windows.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Do you want to see the directory? (Instructions for MacOS)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;One way to look into the hidden VM is to run
the following containerized application:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker run -it --rm --privileged --pid=host justincormack/nsenter1&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This application will open a guest terminal into the VM.
You can then use the commands &lt;code&gt;cd&lt;/code&gt; and &lt;code&gt;ls&lt;/code&gt;
to browse to the directory indicated as the mount path
of the new volume.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sharing-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.1.1&lt;/span&gt; Sharing data&lt;/h3&gt;
&lt;p&gt;A Docker volume can be used to share data between containers.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-26&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3.1  &lt;/strong&gt;&lt;/span&gt;Run a container from the image &lt;code&gt;ubuntu&lt;/code&gt;,
specifying the options to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Remove the container once its execution is over.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Interact with the guest Linux terminal in the container.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;last-child&#34;&gt;
&lt;ul&gt;
&lt;li&gt;Mount the volume &lt;em&gt;data-volume&lt;/em&gt; at the container’s directory &lt;em&gt;/data&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;Feel free to use the &lt;a href=&#34;/courses/cloud-computing/references/docker-cheat-sheet&#34; target=&#34;_blank&#34;&gt;Docker cheat sheet&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;&lt;code&gt;docker run --rm -it -v data-volume:/data ubuntu&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Type the following command in the guest Linux terminal to create a file
&lt;em&gt;test-file.txt&lt;/em&gt; in the directory &lt;em&gt;/data&lt;/em&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;echo &amp;quot;This is a new file&amp;quot; &amp;gt; /data/test-file.txt&lt;/code&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Print to the console the content of the file with the following command:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;cat /data/test-file.txt&lt;/code&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Type &lt;code&gt;exit&lt;/code&gt; to leave the guest terminal. Since we’ve specified the option &lt;code&gt;--rm&lt;/code&gt;, the container
is &lt;strong&gt;destroyed&lt;/strong&gt;. Now we’re going to verify that &lt;code&gt;test-file.txt&lt;/code&gt; is still accessible.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-27&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3.2  &lt;/strong&gt;&lt;/span&gt;Run a container from the image &lt;em&gt;alpine:latest&lt;/em&gt;,
specifying the options to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Remove the container once its execution is over.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Interact with the guest Linux terminal in the container.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;last-child&#34;&gt;
&lt;ul&gt;
&lt;li&gt;Mount the volume &lt;em&gt;data-volume&lt;/em&gt; to the directory &lt;em&gt;/my-data&lt;/em&gt;
of the container.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;&lt;code&gt;docker container run --rm -it -v data-volume:/my-data alpine&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-28&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3.3  &lt;/strong&gt;&lt;/span&gt;Verify that you can read the file &lt;em&gt;test-file.txt&lt;/em&gt;.
Which folder would you look in?
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;We need to look in the folder &lt;em&gt;/my-data&lt;/em&gt; because this is where
we mounted &lt;em&gt;data-volume&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;cat /my-data/test-file.txt&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;p&gt;Type &lt;code&gt;exit&lt;/code&gt; to exit the guest terminal and terminate the container.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;single-host-networking&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;4&lt;/span&gt; Single-Host Networking&lt;/h1&gt;
&lt;p&gt;In order to let containers communicate and, therefore, co-operate,
Docker defines a simple networking model known as
the &lt;a href=&#34;/courses/cloud-computing/references/docker-primer#single-host-networking&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;container network model&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-29&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.1  &lt;/strong&gt;&lt;/span&gt;Describe the output of the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker network ls&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;The command lists all the networks created by Docker on
your computer.
For each network, the values of four attributes are shown:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The identifier.&lt;/li&gt;
&lt;li&gt;The name.&lt;/li&gt;
&lt;li&gt;The driver used by the network.&lt;/li&gt;
&lt;li&gt;The scope of the network (local or global).
A local scope means that the network connects containers
running on the same host, as opposed to a global scope that
means that containers on different hosts can communicate.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Depending on the containers that you used
in the past, you might see different networks.
However, three networks are worth noting:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The network named &lt;strong&gt;bridge&lt;/strong&gt;, that uses the driver &lt;strong&gt;bridge&lt;/strong&gt; and a local scope.
By default, any new container is attached to this network.&lt;/li&gt;
&lt;li&gt;The network named &lt;strong&gt;host&lt;/strong&gt;, that uses the driver &lt;strong&gt;host&lt;/strong&gt; and a local scope.
It’s used when we want a container to directly use the network interface of the host.
It’s important to remember that this network should only be used when analyzing the
host’s network traffic. In the other cases, using this network exposes
the container to all sorts of security risks.&lt;/li&gt;
&lt;li&gt;The network named &lt;strong&gt;none&lt;/strong&gt;, that uses the driver &lt;strong&gt;null&lt;/strong&gt; and a local scope.
Attaching a container to this network means that the container
isn’t connected to any network, and therefore it’s completely isolated.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-30&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.2  &lt;/strong&gt;&lt;/span&gt;The following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker network inspect bridge&lt;/code&gt;&lt;/p&gt;
outputs the configuration of the network &lt;strong&gt;bridge&lt;/strong&gt;.
By looking at this configuration, can you tell
what IP addresses will be given to the containers attached to this
network? What’s the IP address of the router of this network?
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;The information is specified in the field named &lt;strong&gt;IPAM&lt;/strong&gt;, more specifically:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Subnet&lt;/strong&gt; indicates the range of IP addresses used by the network.
The value of this field should be 172.17.0.0/16;
the addresses range from 172.17.0.1 to 172.17.255.255.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Gateway&lt;/strong&gt; indicates the IP address of the router of the network.
The value should be 172.17.0.1&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div id=&#34;creating-networks&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.1&lt;/span&gt; Creating networks&lt;/h2&gt;
&lt;p&gt;By default, any new container is attached to the network named &lt;em&gt;bridge&lt;/em&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-31&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.3  &lt;/strong&gt;&lt;/span&gt;
Explain why it is not a good practice to
attach all our containers to the same network.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;All new containers will be able to communicate over this network.
This is not a good idea.
If a hacker can compromise any of these containers, s/he might
be able to attack the other containers as well.
As a rule of thumb, we should attach two containers to the same network &lt;strong&gt;only&lt;/strong&gt; on a
need-to-communicate basis.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;p&gt;In order to create a new network, you can use the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker network create network_name&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-32&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.4  &lt;/strong&gt;&lt;/span&gt;Create two networks named &lt;em&gt;buckingham&lt;/em&gt; and &lt;em&gt;rochefort&lt;/em&gt; that
use the driver &lt;em&gt;bridge&lt;/em&gt;.
By using the &lt;code&gt;docker network inspect&lt;/code&gt; command,
look at the IP addresses of the new networks and write them down.
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;Just run the following commands:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker network create buckingham&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker network create rochefort&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The IP addresses for the network &lt;em&gt;buckingham&lt;/em&gt; are
172.18.0.0/16 (addresses from 172.18.0.1 to 172.18.255.255);
The IP addresses for the network &lt;em&gt;rochefort&lt;/em&gt; are:
172.19.0.0/16 (assuming that you create &lt;em&gt;buckingham&lt;/em&gt;
before &lt;em&gt;rochefort&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;The IP addresses may be different on your machines.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-33&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.5  &lt;/strong&gt;&lt;/span&gt;Create three containers &lt;em&gt;athos&lt;/em&gt;, &lt;em&gt;porthos&lt;/em&gt; and &lt;em&gt;aramis&lt;/em&gt; and attach them
to the two networks &lt;em&gt;buckingham&lt;/em&gt; and &lt;em&gt;rochefort&lt;/em&gt; as displayed
&lt;a href=&#34;/courses/cloud-computing/references/docker-primer#fig:cnm&#34; target=&#34;_blank&#34;&gt;in this figure&lt;/a&gt;.
&lt;strong&gt;The three containers will open a Linux Alpine shell&lt;/strong&gt;.
You’ll need to launch the commands in three separate tabs of your terminal window.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What will the IP addresses of the three containers be in the two networks?
Remember that &lt;em&gt;porthos&lt;/em&gt; is attached to two networks, therefore it’ll have two
network interfaces (endpoints) and, as a result, two IP addresses.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;last-child&#34;&gt;
&lt;ul&gt;
&lt;li&gt;Verify your answers by inspecting the two networks (use the
command &lt;code&gt;docker network inspect&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;Here are the commands to run &lt;em&gt;athos&lt;/em&gt; and &lt;em&gt;aramis&lt;/em&gt; while connecting
them to &lt;em&gt;buckingham&lt;/em&gt; and &lt;em&gt;rochefort&lt;/em&gt; respectively.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker run --rm -it --name athos --network buckingham  alpine docker run --rm -it --name aramis --network rochefort   alpine&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Here’s the command to run &lt;em&gt;porthos&lt;/em&gt; and attach it to
&lt;em&gt;buckingham&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker run --rm -it --name porthos --network buckingham   alpine&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The following command attaches &lt;em&gt;porthos&lt;/em&gt; to the second network &lt;em&gt;rochefort&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker network connect rochefort porthos&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;As for the IP addresses, each network has IP addresses
in the range 172.x.0.0/16, where x is 18 in the
network &lt;em&gt;buckingham&lt;/em&gt; and 19 in the network &lt;em&gt;rochefort&lt;/em&gt;.
The address 172.x.0.1 is reserved for the router.
Therefore, the containers will be assigned
IP addresses from 172.x.0.2.
In this solution, we created &lt;em&gt;athos&lt;/em&gt;, &lt;em&gt;aramis&lt;/em&gt; and &lt;em&gt;portos&lt;/em&gt;
in this order.
Therefore, the IP addresses will be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In network &lt;em&gt;buckingham&lt;/em&gt;:
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;athos&lt;/em&gt;: 172.18.0.2&lt;/li&gt;
&lt;li&gt;&lt;em&gt;porthos&lt;/em&gt;: 172.18.0.3&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;In network &lt;em&gt;rochefort&lt;/em&gt;:
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;aramis&lt;/em&gt;: 172.19.0.2&lt;/li&gt;
&lt;li&gt;&lt;em&gt;porthos&lt;/em&gt;: 172.19.0.3&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can actually verify this configuration by inspecting
the two networks with the following commands:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker network inspect buckingham docker network inspect rochefort&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The IP addresses might be different on your machines.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;communication-between-containers&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.2&lt;/span&gt; Communication between containers&lt;/h2&gt;
&lt;p&gt;Let’s see if and when the three containers can communicate.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-34&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.6  &lt;/strong&gt;&lt;/span&gt;Which containers are able to communicate?
Justify your answer.
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;The only containers that cannot communicate are &lt;em&gt;athos&lt;/em&gt; and &lt;em&gt;aramis&lt;/em&gt;,
because they’re not connected to the same network.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-35&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.7  &lt;/strong&gt;&lt;/span&gt;Try to ping &lt;em&gt;porthos&lt;/em&gt; from &lt;em&gt;athos&lt;/em&gt; by using its IP address.&lt;/p&gt;
&lt;div class=&#34;last-child&#34;&gt;
&lt;ul&gt;
&lt;li&gt;Which IP address of &lt;em&gt;porthos&lt;/em&gt; would you use?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;We need to use the IP address assigned to the endpoint linking
&lt;em&gt;porthos&lt;/em&gt; to the network &lt;em&gt;buckingham&lt;/em&gt;, to which &lt;em&gt;athos&lt;/em&gt; is connected.
In our case, this is 172.18.0.3.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-36&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.8  &lt;/strong&gt;&lt;/span&gt;Try to ping &lt;em&gt;porthos&lt;/em&gt; from &lt;em&gt;athos&lt;/em&gt; by using its name.
Do you succeed? Are you surprised?
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;We succeed. Indeed, the network &lt;em&gt;buckingham&lt;/em&gt; provides a DNS server, that
can translate names into IP addresses.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;p&gt;You can now exit the three containers.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Multi-service applications</title>
      <link>/courses/cloud-computing/tutorials/tutorial-kube/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/cloud-computing/tutorials/tutorial-kube/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If you use the Linux VM&lt;/strong&gt;, you need to change the hardware configuration of the VM before
booting it. You can also &lt;a href=&#34;https://webtv.centralesupelec.fr/permalink/v12619ffbdbb7mpc6xbp/&#34; target=&#34;_blank&#34;&gt;watch this video&lt;/a&gt;.
Here are the necessary modifications:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Increase the main memory to 4GB.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Set the number of CPUs to 2.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Without these modifications you’re not going to have a good experience with Kubernetes.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In this tutorial you’ll learn:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;How to &lt;strong&gt;build&lt;/strong&gt; and &lt;strong&gt;deploy&lt;/strong&gt; a &lt;strong&gt;multi-service application&lt;/strong&gt; with &lt;strong&gt;Docker Compose&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;How to &lt;strong&gt;push an image&lt;/strong&gt; to &lt;strong&gt;DockerHub&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;How to &lt;strong&gt;deploy&lt;/strong&gt; a &lt;strong&gt;multi-service application&lt;/strong&gt; with &lt;strong&gt;Kubernetes&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This tutorial is adapted from the examples presented in Chapters
14 and 20 of the book &lt;a href=&#34;https://www.packtpub.com/product/learn-docker-fundamentals-of-docker-19-x-second-edition/9781838827472&#34; target=&#34;_blank&#34;&gt;G. Schenker, &lt;em&gt;Learn Docker - Fundamentals of Docker 19.x&lt;/em&gt; (March 2020)&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;docker-compose&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Docker Compose&lt;/h1&gt;
&lt;p&gt;In this section, you’re going to build and deploy a multi-service application
by using &lt;a href=&#34;https://docs.docker.com/compose/&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;Docker Compose&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Download &lt;a href=&#34;/courses/cloud-computing/tutorial-kube/pet-store.zip&#34;&gt;this archive file&lt;/a&gt; and unzip it into a folder on your
own computer.
The archive contains all the necessary files to build and run
a web application consisting of two services:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;web&lt;/strong&gt;. This is the &lt;strong&gt;frontend&lt;/strong&gt; (the part the user interacts with)
of the application.
It consists of HTML and JavaScript code.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;db&lt;/strong&gt;. This is the &lt;strong&gt;backend&lt;/strong&gt; (the part hidden to the user).
It is a &lt;a href=&#34;https://www.postgresql.org/&#34; target=&#34;_blank&#34;&gt;PostgreSQL&lt;/a&gt; (relational) database.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The structure of the application is shown in Figure &lt;a href=&#34;#fig:pet-store-struct&#34;&gt;1.1&lt;/a&gt;.
The root directory of the application contains two subdirectories, one for each service
(&lt;code&gt;database&lt;/code&gt; and &lt;code&gt;web&lt;/code&gt;).&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:pet-store-struct&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/courses/cloud-computing/tutorial-kube/pet-store-files.png&#34; alt=&#34;Structure of the application&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1.1: Structure of the application
&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox curiosity&#34;&gt;
&lt;p&gt;&lt;strong&gt;Good to know&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The files with extension &lt;code&gt;.conf&lt;/code&gt; under the directory &lt;code&gt;database&lt;/code&gt; contain
configuration parameters of the PostgreSQL database.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The file &lt;code&gt;init-db.sql&lt;/code&gt; under the directory &lt;code&gt;database&lt;/code&gt; contains the SQL queries
to populate the database with some data (photos of cats).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The directory &lt;code&gt;web&lt;/code&gt; contains the HTML and JavaScript code of the web application.
The file &lt;code&gt;package.json&lt;/code&gt; contains the dependencies to install.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;Both directories contain a &lt;strong&gt;Dockerfile&lt;/strong&gt;.
The one in directory &lt;code&gt;database&lt;/code&gt; is as follows:&lt;/p&gt;
&lt;pre class=&#34;dockerfile&#34;&gt;&lt;code&gt;FROM postgres:10.2-alpine
COPY init-db.sql /docker-entrypoint-initdb.d/
RUN chown postgres:postgres /docker-entrypoint-initdb.d/*.sql
ENV POSTGRES_USER dockeruser
ENV POSTGRES_PASSWORD dockerpass
ENV POSTGRES_DB pets&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Dockerfile builds on an existing image called &lt;code&gt;postgres:10-2-alpine&lt;/code&gt;,
that is &lt;a href=&#34;https://hub.docker.com/_/postgres&#34; target=&#34;_blank&#34;&gt;documented here&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-1&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.1  &lt;/strong&gt;&lt;/span&gt;
Consider the following line in the Dockerfile:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;COPY init-db.sql /docker-entrypoint-initdb.d/&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;By looking at the documentation of the image &lt;code&gt;postgres:10-2-alpine&lt;/code&gt;,
answer the two following questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Where is the directory &lt;code&gt;/docker-entrypoint-initdb.d/&lt;/code&gt;?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Why do we copy the file &lt;code&gt;init-db.sql&lt;/code&gt; to this directory?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The directory already exists in the base image.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;By looking at the documentation, we learn that
we can put any initialization script in this directory.
In other words, at the startup the database will execute the
SQL queries in file &lt;code&gt;init-db.sql&lt;/code&gt; so that the database
is populated with new data.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;From the documentation, we also learn that the script is not executed
if the data directory is not empty. This means that already existing databases
will not be touched.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;p&gt;The last three lines of the Dockerfile contain a keyword (&lt;code&gt;ENV&lt;/code&gt;)
that we never came across before.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-2&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.2  &lt;/strong&gt;&lt;/span&gt;
Look again at the documentation of the image &lt;code&gt;postgres:10-2-alpine&lt;/code&gt;
and try to explain the meaning of the last three lines of the Dockerfile.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;These lines set the value of three &lt;strong&gt;environment variables&lt;/strong&gt;, useful
to pass some parameters to the database.
From the documentation we learn that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;POSTGRES_USER&lt;/code&gt; is the name of the database user. If not set,
the default is the user &lt;code&gt;postgre&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;POSTGRES_PASSWORD&lt;/code&gt; is the password associated with the
user. This is the only mandatory variable.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;POSTGRES_DB&lt;/code&gt; is the name given to the database.
If not specified, the database name would be the same as the username.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;p&gt;The Dockerfile of the web application is as follows:&lt;/p&gt;
&lt;pre class=&#34;dockerfile&#34;&gt;&lt;code&gt;FROM node:9.6-alpine
RUN mkdir /app
WORKDIR /app
COPY package.json /app/
RUN npm install
COPY ./src /app/src
EXPOSE 3000
CMD node src/server.js&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Dockerfile builds on the image &lt;code&gt;node:9.6-alpine&lt;/code&gt; that contains
a Node.js environment, a JavaScript-based platform for server-side
applications.
The instructions in the Dockerfile look like the ones of the examples
that we’ve seen in the first tutorial and in the lectures.&lt;/p&gt;
&lt;div class=&#34;infobox curiosity&#34;&gt;
&lt;p&gt;&lt;strong&gt;Good to know&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The command &lt;code&gt;npm install&lt;/code&gt; installs all the dependencies specified
in the file &lt;code&gt;package.json&lt;/code&gt;
from the &lt;a href=&#34;https://docs.npmjs.com/about-npm&#34; target=&#34;_blank&#34;&gt;software registry npm&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The instruction &lt;code&gt;EXPOSE 3000&lt;/code&gt; informs that the container
listens on port 3000 when it is executed from the image.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;From the &lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#expose&#34; target=&#34;_blank&#34;&gt;Docker documentation&lt;/a&gt;
we learn
that the &lt;em&gt;“&lt;code&gt;EXPOSE&lt;/code&gt; instruction
does not actually publish the port.
It functions as a type of
documentation between
the person who builds the image
and the person who runs the container, about which ports are intended to be published”&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In order to actually publish the port, we’ll use the file
&lt;code&gt;docker-compose.yml&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;describing-the-application&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.1&lt;/span&gt; Describing the application&lt;/h2&gt;
&lt;p&gt;The application showcases a building block of a pet store.
In the current version, the application lets users look at few pictures
of cats.&lt;/p&gt;
&lt;p&gt;The root directory of the application contains a file named
&lt;code&gt;docker-compose.yml&lt;/code&gt; that contains the &lt;strong&gt;declarative configuration&lt;/strong&gt;
of the application.
The content of the file is as follows. It is a sequence of key-value pairs.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;version: &amp;quot;3.6&amp;quot;
services:
  web:
    build: web
    image: pet-store-web
    networks:
      - backend
    ports:
      - 5000:3000
  db:
    build: database
    image: pet-store-db
    networks:
      - backend
    volumes:
      - pets-data:/var/lib/postgresql/data

networks:
  backend:

volumes:
  pets-data:&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are three main sections:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;services&lt;/code&gt;. Defines the services of the application. Here two services
are defined: &lt;code&gt;web&lt;/code&gt; and &lt;code&gt;db&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;networks&lt;/code&gt;. Defines the networks used by the application.
Here one network is defined: &lt;code&gt;backend&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;volumes&lt;/code&gt;. Defines the volumes used by the application.
Here one volume is defined: &lt;code&gt;pets-data&lt;/code&gt;.
The volume is attached to the directory &lt;code&gt;/var/lib/postgresql/data&lt;/code&gt;
(that is in the container).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-3&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.3  &lt;/strong&gt;&lt;/span&gt;
What key informs &lt;code&gt;docker compose&lt;/code&gt; where to find the
Dockerfile of the two services?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;The value of the key &lt;code&gt;build&lt;/code&gt; is the name of the directory that contains
the Dockefile. For the service &lt;code&gt;web&lt;/code&gt;, this is the directory
&lt;code&gt;web&lt;/code&gt;; for the service &lt;code&gt;db&lt;/code&gt;, it is the directory &lt;code&gt;database&lt;/code&gt;.
All paths are relative to the position of the file &lt;code&gt;docker-compose.yml&lt;/code&gt;
itself.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;p&gt;When we’ll build the application from the file &lt;code&gt;docker-compose.yml&lt;/code&gt;,
two images will be created, one for each service.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-4&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.4  &lt;/strong&gt;&lt;/span&gt;
What will the name of the two images be?
What key in the file &lt;code&gt;docker-compose.yml&lt;/code&gt; gives you this information?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;The name of the image corresponding to the service &lt;code&gt;web&lt;/code&gt;
will be &lt;code&gt;pet-store-web&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The name of the image corresponding to the service &lt;code&gt;db&lt;/code&gt;
will be &lt;code&gt;pet-store-db&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This information is given by the key &lt;code&gt;image&lt;/code&gt;
in the file &lt;code&gt;docker-compose.yml&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;building-the-application&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.2&lt;/span&gt; Building the application&lt;/h2&gt;
&lt;p&gt;We now build the application.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Open the command-line terminal and by using the command &lt;code&gt;cd&lt;/code&gt;
position yourself in the root directory
&lt;code&gt;pet-store&lt;/code&gt; of the application.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Execute the following command:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;docker-compose build&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When the build is complete, verify that the two images corresponding
to the two services have been created (which docker command do you need here?).&lt;/li&gt;
&lt;/ul&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;docker images&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;executing-the-application&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.3&lt;/span&gt; Executing the application&lt;/h2&gt;
&lt;p&gt;We now execute the application with the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker-compose up -d&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;infobox curiosity&#34;&gt;
&lt;p&gt;&lt;strong&gt;Good to know&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The option &lt;code&gt;-d&lt;/code&gt; in the previous command means that the application is
executed &lt;strong&gt;in the background&lt;/strong&gt; or, in other words,
the containers are run as &lt;strong&gt;daemons&lt;/strong&gt; (hence, the &lt;code&gt;-d&lt;/code&gt;).
This means that any output of the application is not
shown in the terminal.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-5&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.5  &lt;/strong&gt;&lt;/span&gt;
Verify that the network and the volumes associated with the
application have been correctly created.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;Type the commands:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker volume ls&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker network ls&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;to verify respectively that the volumes and the networks have been created&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-6&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.6  &lt;/strong&gt;&lt;/span&gt;
How many containers do you expect to be associated to
the application?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;Each &lt;strong&gt;image&lt;/strong&gt; corresponds to a &lt;strong&gt;service&lt;/strong&gt;.
Here we have two.
Each &lt;strong&gt;container&lt;/strong&gt; corresponds to a &lt;strong&gt;service instance&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;We didn’t specify any parameter when we launched the application,
so by default one instance of each service is executed.&lt;/p&gt;
&lt;p&gt;So, we expect to have &lt;strong&gt;two containers&lt;/strong&gt; associated to the application:
one container for the service &lt;code&gt;web&lt;/code&gt; and one for the
service &lt;code&gt;db&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;p&gt;You can verify the answer to the previous question by typing the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker-compose ps&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This command is exactly equivalent to &lt;code&gt;docker container ls&lt;/code&gt;, except that
it only shows the containers associated with the application
that we’ve just executed.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-7&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.7  &lt;/strong&gt;&lt;/span&gt;
In the output of the command &lt;code&gt;docker-compose ps&lt;/code&gt;, can you explain
the meaning of the following?&lt;/p&gt;
&lt;p&gt;&lt;code&gt;0.0.0.0:5000-&amp;gt;3000/tcp&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;The notation 5000-&amp;gt;3000 means that the port
5000 of the host computer is &lt;strong&gt;mapped&lt;/strong&gt;
to the port 3000 of the container.
This mechanism is explained in
&lt;a href=&#34;https://centralesupelec.edunao.com/pluginfile.php/135595/mod_resource/content/2/cm2-slides.pdf&#34; target=&#34;blank&#34;&gt;slide 77 of the lecture on Docker&lt;/a&gt;.
More specifically,
when a client application connects to the port 5000 of the host computer,
the connection is redirected to the port 3000 of the container.&lt;/p&gt;
&lt;p&gt;The IP address 0.0.0.0 means that we can connect to the container by
using any IP address on the host computer.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-8&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.8  &lt;/strong&gt;&lt;/span&gt;
Can you
tell which URL you have to type in your web browser
to access the application?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;&lt;code&gt;http://localhost:5000&lt;/code&gt; or &lt;code&gt;http://127.0.0.1:5000/&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In the network settings of you computer, you can also
get the IP address associated by the DHCP server of your&lt;br /&gt;
local network and use that address to connect to the application
from another device &lt;strong&gt;connected to the same network&lt;/strong&gt;
(for instance, your mobile phone).&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If you want to see the cats, you need to append
&lt;code&gt;/pet&lt;/code&gt; to the URL that you found in the previous question.
This is determined in file &lt;code&gt;server.js&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;shutting-down-the-application&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.4&lt;/span&gt; Shutting down the application&lt;/h2&gt;
&lt;p&gt;You can shut down the application by typing the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker-compose down&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-9&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.9  &lt;/strong&gt;&lt;/span&gt;
Does shutting down the application remove the networks created
for the application?
What about the volumes?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;Just type the command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker network ls&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;and you’ll see that the network &lt;code&gt;backend&lt;/code&gt; is not there anymore.&lt;/p&gt;
&lt;p&gt;Type the command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker volume ls&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;and you’ll see that the volume &lt;code&gt;pet-store_pets-data&lt;/code&gt; is still there.&lt;/p&gt;
&lt;p&gt;By default volumes are not removed, to avoid the risk of permanently deleting
data that might still be useful later.
If you wish to remove the volumes when shutting down the application,
you can type:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker-compose down -v&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;scaling-a-service&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.5&lt;/span&gt; Scaling a service&lt;/h2&gt;
&lt;p&gt;When we launch the application, we can specify the
number of instances of each service.
This is useful when we expect our application to be solicited by many users;
the workload will be automatically balanced across all the instances of the service.&lt;/p&gt;
&lt;p&gt;Let’s launch our application with 3 instances of the service &lt;code&gt;web&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker-compose up --scale web=3 -d&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-10&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.10  &lt;/strong&gt;&lt;/span&gt;
Running the previous command results in an error.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Can you explain why?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;What fix would you propose in file &lt;code&gt;docker-compose.yml&lt;/code&gt;?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;We’re trying to bind three instances to the port 5000 on the host computer. This is not
possible.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In the section &lt;code&gt;ports&lt;/code&gt; of file
&lt;code&gt;docker-compose.yml&lt;/code&gt; we need to remove 5000 and we only leave 3000. This way, each time we run a container, a random port will be chosen on the host computer to bind it
with port 3000 of the container.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You need to shut down the application before relaunching it again.
In fact, even if we got an error, an instance of the &lt;code&gt;db&lt;/code&gt; service and
an instance of the service &lt;code&gt;web&lt;/code&gt; are still running.&lt;/p&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Modify the file &lt;code&gt;docker-compose.yml&lt;/code&gt; and relaunch the application.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Run the following command and verify that you actually have three running instances of the
service &lt;code&gt;web&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;docker-compose ps&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Try to connect to the application by using the three port numbers indicated in the output
of the previous command.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Don’t forget to shut down the application before you
go on.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;pushing-an-application&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; Pushing an application&lt;/h1&gt;
&lt;p&gt;Once we have built an application, we might want to
share it by pushing it to the DockerHub registry or any
other container registry, be it private or public.&lt;/p&gt;
&lt;div id=&#34;creating-an-account-on-dockerhub&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.1&lt;/span&gt; Creating an account on DockerHub&lt;/h2&gt;
&lt;p&gt;You need to create an account on the &lt;a href=&#34;https://hub.docker.com/&#34; target=&#34;_blank&#34;&gt;DockerHub website&lt;/a&gt;
in order to perform this activity.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;renaming-the-images&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.2&lt;/span&gt; Renaming the images&lt;/h2&gt;
&lt;p&gt;In order to push your images to the registry, you need to rename them, so as the new name
has the following structure:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;yourusername/image-name:image-tag&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;For instance, since my username is &lt;code&gt;quercinigia&lt;/code&gt;, I’ll rename
the two images &lt;code&gt;pet-store-web&lt;/code&gt; and &lt;code&gt;pet-store-db&lt;/code&gt; with the
&lt;code&gt;docker tag&lt;/code&gt; command as follows:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker tag pet-store-web quercinigia/pet-store-web:1.0&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker tag pet-store-db quercinigia/pet-store-db:1.0&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;I chosen 1.0 as a tag, but feel free to pick another one.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;logging-in&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.3&lt;/span&gt; Logging in&lt;/h2&gt;
&lt;p&gt;You need to log in to your DockerHub account.&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Instructions for Docker Desktop (macOS and Windows)&lt;/summary&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;macOS users: to see how to log in &lt;a href=&#34;https://webtv.centralesupelec.fr/videos/log-in-docker-macos/&#34; target=&#34;_blank&#34;&gt;click here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Windows users: to see how to log in &lt;a href=&#34;https://webtv.centralesupelec.fr/videos/log-in-docker-windows/&#34; target=&#34;_blank&#34;&gt;click here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Instructions for the Linux VM&lt;/summary&gt;&lt;/p&gt;
&lt;p&gt;Log in to DockerHub by typing the following command in the terminal
(replace YOUR-USERNAME with your actual username).&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker login -u YOUR-USERNAME&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You might get a warning that
your password will be stored unencrypted.
There are methods to prevent this from happening.
These methods being out of the scope of this course,
the interested reader can
look them up &lt;a href=&#34;https://www.techrepublic.com/article/how-to-setup-secure-credential-storage-for-docker/&#34; target=&#34;_blank&#34;&gt;at this link&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;pushing-the-images&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.4&lt;/span&gt; Pushing the images&lt;/h2&gt;
&lt;p&gt;Once you’re successfully logged in, you can type the following
commands in the terminal to push the two images of your application:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker push YOUR-USERNAME/pet-store-web:1.0&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker push YOUR-USERNAME/pet-store-db:1.0&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Remember to replace YOUR-USERNAME with your actual username in the commands above.&lt;/p&gt;
&lt;p&gt;After the task is completed, verify that the images appear
in &lt;a href=&#34;https://hub.docker.com/repositories&#34; target=&#34;_blank&#34;&gt;your Docker registry&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox curiosity&#34;&gt;
&lt;p&gt;&lt;strong&gt;Good to know&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Here we manually tagged and uploaded the two images.
This method becomes quickly annoying when the application consists of
more than two images.
Another way to go about this task is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Specify the image names with your username in file &lt;strong&gt;docker-compose.yml&lt;/strong&gt;.
For instance, in my &lt;strong&gt;docker-compose.yml&lt;/strong&gt; I would write:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;services:
  web:
    build: web
    image: quercinigia/pet-store-web:1.0
  ...
  db:
    build: database
    image: quercinigia/pet-store-db:1.0
  ...&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Build the application with the following command:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;docker-compose build&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Push the images of the application with the following command:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;docker-compose push&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This way, with just two commands we push to the registry all the images
of the application, no matter how many they are.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction-to-kubernetes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; Introduction to Kubernetes&lt;/h1&gt;
&lt;p&gt;Kubernetes is the most popular &lt;strong&gt;orchestrator&lt;/strong&gt; to date.
It is used to manage a multi-service application, usually deployed
across multiple &lt;strong&gt;hosts&lt;/strong&gt; in a &lt;strong&gt;cluster&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;While using Docker Compose, a &lt;strong&gt;service&lt;/strong&gt; corresponds
to a &lt;strong&gt;Docker image&lt;/strong&gt; and
a &lt;strong&gt;service instance&lt;/strong&gt; to a &lt;strong&gt;Docker container&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;As opposed to that, in Kubernetes the computation unit is a &lt;strong&gt;pod&lt;/strong&gt;, that is
a &lt;strong&gt;collection of containers&lt;/strong&gt;.
In other words, we don’t reason in terms of containers anymore,
but in terms of pods. Of course, a pod can also consist of just one container.&lt;/p&gt;
&lt;div class=&#34;infobox curiosity&#34;&gt;
&lt;p&gt;&lt;strong&gt;Good to know&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In practice, we rarely have to manipulate pods directly in Kubernetes,
as there are higher-level objects that manage them.
We’ll use these objects in the next sections.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;activate-kubernetes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.1&lt;/span&gt; Activate Kubernetes&lt;/h2&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Instructions for Docker Desktop (macOS and Windows)&lt;/summary&gt;&lt;/p&gt;
&lt;p&gt;You need to follow all the instructions documented
&lt;a href=&#34;https://docs.docker.com/desktop/kubernetes/&#34; target=&#34;_blank&#34;&gt;on this page&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Before moving on, don’t forget to type the following command to verify that Kubernetes is correctly activated&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubectl get nodes&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Before moving on, don’t forget to type the following command to verify that Kubernetes is correctly activated&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubectl get nodes&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;You should see a node called &lt;code&gt;docker-desktop&lt;/code&gt; whose status is set to READY.
If the status is NOT READY, just wait few seconds before typing the command again.&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This solution might not be working for you.
In that case, disable Kubernetes in Docker Desktop and install
minikube, by following &lt;a href=&#34;https://minikube.sigs.k8s.io/docs/start/&#34; target=&#34;_blank&#34;&gt;these instructions&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Instructions for the Linux VM&lt;/summary&gt;&lt;/p&gt;
&lt;p&gt;In the Linux VM you’ll find &lt;strong&gt;Minikube&lt;/strong&gt;, a single-node Kubernetes cluster
in VirtualBox.
Please follow &lt;strong&gt;all the instructions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Start the cluster, type the following command:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;minikube start&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Verify that Kubernetes is correctly activated by typing the following command:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;kubectl get nodes&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;You should see a node called &lt;code&gt;minikube&lt;/code&gt; whose status is set to READY.
If the status is NOT READY, just wait few seconds before typing the command again.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open a &lt;strong&gt;new terminal&lt;/strong&gt; and type the command:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;minikube tunnel&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;When prompted to enter a password, just type ENTER.
The command will start to produce some output.
&lt;strong&gt;Leave that terminal open&lt;/strong&gt; and go back to the previous terminal.&lt;/p&gt;
&lt;div class=&#34;infobox curiosity&#34;&gt;
&lt;p&gt;&lt;strong&gt;Tunnel&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Minikube tunnel is used to create a route to services deployed
with type &lt;code&gt;LoadBalancer&lt;/code&gt;. If you don’t activate the tunnel,
you won’t be able to use these services in the exercises below.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;deploying-a-pod&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.2&lt;/span&gt; Deploying a pod&lt;/h2&gt;
&lt;p&gt;In order to deploy &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/pods/&#34; target=&#34;_blank&#34;&gt;a pod&lt;/a&gt;,
we first have to give its &lt;strong&gt;specification&lt;/strong&gt;, basically its name
and the containers that compose it with their settings.
Similarly to Docker Compose, a pod is specified in a &lt;strong&gt;declarative way&lt;/strong&gt; with a
YAML configuration file.&lt;/p&gt;
&lt;p&gt;Consider the following specification.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Pod
metadata:
  name: web-pod
  labels:
    app: web-pod
spec:
  containers:
  - name: web
    image: nginx:alpine
    ports:
    - containerPort: 80&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is an explanation of the properties in the specification.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;apiVersion&lt;/em&gt;. Defines the versioned schema of this representation.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;kind&lt;/em&gt;. The type of the resource that we intend to create.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;metadata&lt;/em&gt;. The resource metadata. The list of
all metadata is specified &lt;a href=&#34;https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.21/#objectmeta-v1-meta&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;spec&lt;/em&gt;. The specification of the desired behaviour of the pod.
The list of the possible specifications can be found &lt;a href=&#34;https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.21/#podspec-v1-core&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Essentially, the previous specification defines a pod with a container that is launched from the
image &lt;code&gt;nginx:alpine&lt;/code&gt; (a Web server) and listens to ports 80 and 443.&lt;/p&gt;
&lt;div class=&#34;infobox activitybox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Activity&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Copy the previous specification to a file named &lt;code&gt;sample-pod.yaml&lt;/code&gt; (or any other name
of your liking).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;By using the command &lt;code&gt;cd&lt;/code&gt; in the terminal, place yourself in the directory
where the file &lt;code&gt;sample-pod.yaml&lt;/code&gt; is stored.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Deploy the pod by typing the following command:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;kubectl create -f sample-pod.yaml&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Verify that the pod is deployed by typing the following command:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;kubectl get pods&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The first time you run the last command, you might see that the pod is not
ready yet. You need to wait for the image &lt;code&gt;nginx:alpine&lt;/code&gt; to be pulled from DockerHub.
Wait few seconds and try the command again until the pod is marked as running.&lt;/p&gt;
&lt;p&gt;You can also get more information on the running pod (e.g., its assigned IP address)
by typing the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubectl get pod -o wide web-pod&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-11&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3.1  &lt;/strong&gt;&lt;/span&gt;
Open a web browser and type &lt;code&gt;http://localhost:80&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;What do you get? What if you try to use the IP of the pod instead of &lt;code&gt;locahost&lt;/code&gt;?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;What should we define in order to fix the problem?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The connection is refused both when using &lt;code&gt;localhost&lt;/code&gt; and
the IP address of the pod.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In order to connect to the service instance, we need to
define a &lt;strong&gt;Service&lt;/strong&gt; object in Kubernetes, that exposes an IP address
that client applications can use.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;p&gt;The following configuration
defines a Service object of type &lt;strong&gt;LoadBalancer&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  type: LoadBalancer
  ports:
  - port: 8080
    targetPort: 80
    protocol: TCP
    name: http
  selector:
      app: web-pod&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;infobox curiosity&#34;&gt;
&lt;p&gt;&lt;strong&gt;Good to know&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A &lt;strong&gt;LoadBalancer&lt;/strong&gt; service is a &lt;strong&gt;NodePort&lt;/strong&gt; service (cf slide 64 in &lt;a href=&#34;https://centralesupelec.edunao.com/pluginfile.php/136097/mod_resource/content/2/cm3-slides.pdf&#34; target=&#34;_blank&#34;&gt;Lecture 3&lt;/a&gt;)
that offers load balancing capabilities.
It is intended to expose an IP address
that client applications (external to the Kubernetes cluster) can use to access
the service.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-12&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3.2  &lt;/strong&gt;&lt;/span&gt;
What is the field &lt;code&gt;selector&lt;/code&gt; in the definition of the service?
(cf slide 57 in &lt;a href=&#34;https://centralesupelec.edunao.com/pluginfile.php/136097/mod_resource/content/2/cm3-slides.pdf&#34; target=&#34;_blank&#34;&gt;Lecture 3&lt;/a&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;The selector is used internally by Kubernetes to identify the pods that
are the instances of the service.
If you look at the specification of the pod above, the field &lt;code&gt;metadata&lt;/code&gt;
contains a field &lt;code&gt;labels&lt;/code&gt;.
One of the labels is &lt;code&gt;app: web-pod&lt;/code&gt; ;
the selector matches this label.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-13&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3.3  &lt;/strong&gt;&lt;/span&gt;
In the specification of the service, what &lt;code&gt;port&lt;/code&gt; and &lt;code&gt;targetPort&lt;/code&gt; mean?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;port&lt;/code&gt; specifies the port number where the service will be available.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;targetPort&lt;/code&gt; specifies the port number opened at the pods that are instances of the service.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox activitybox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Activity&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Copy and paste the service specification into a file named &lt;code&gt;sample-service.yaml&lt;/code&gt; (or any other name of your liking).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;By using the command &lt;code&gt;cd&lt;/code&gt; in the terminal, place yourself in the directory
where the file &lt;code&gt;sample-service.yaml&lt;/code&gt; is stored.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Deploy the service by typing the following command:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;kubectl create -f sample-service.yaml&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Verify that the service is deployed by typing the following command:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;kubectl get services&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This command returns all services running in Kubernetes.
For each service, you also get a name.
In order to only target the service that you’ve just created, simply type
the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubectl get svc/nginx-service&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Your service’s name is &lt;code&gt;nginx-service&lt;/code&gt; (as specified in file &lt;code&gt;sample-service.yml&lt;/code&gt;);
&lt;code&gt;svc&lt;/code&gt; is only the namespace where all Kubernetes services are
put.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-14&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3.4  &lt;/strong&gt;&lt;/span&gt;
By looking at the output of the command &lt;code&gt;kubectl get svc/nginx-service&lt;/code&gt;,
which URL do you need to type in the Web browser in order to access the service?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The &lt;code&gt;CLUSTER-IP&lt;/code&gt; is an IP address that is only visible &lt;strong&gt;within the cluster&lt;/strong&gt;.
In other words, only the services running within the cluster can connect to our
&lt;code&gt;nginx-service&lt;/code&gt; by using this IP address.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What we need to use is the IP address specified under &lt;code&gt;EXTERNAL-IP&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;If you’re using Docker Desktop&lt;/summary&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;EXTERNAL-IP&lt;/code&gt; is likely to be &lt;code&gt;localhost&lt;/code&gt;
or &lt;code&gt;127.0.0.1&lt;/code&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;If you’re using Minikube in the Linux VM&lt;/summary&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;EXTERNAL-IP&lt;/code&gt; will be whatever IP address assigned to the service.&lt;/p&gt;
&lt;/details&gt;
&lt;ul&gt;
&lt;li&gt;As for the port number, under PORT(S) you should see something like 8080:30548
(the second number is likely different, but it should be something in the range [30000-32767]).
The port 30548 is opened on each node of the Kubernetes cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In practice, when we type &lt;code&gt;http://localhost:8080&lt;/code&gt;, the load balancer replaces it
with the IP address of a node in the cluster,
followed by port number 30548.
When the &lt;code&gt;kube-proxy&lt;/code&gt; on that node receives this request,
it forwards it to an instance of the service,
even if that instance runs in another node
(mechanism of slide 64 in &lt;a href=&#34;https://centralesupelec.edunao.com/pluginfile.php/136097/mod_resource/content/2/cm3-slides.pdf&#34; target=&#34;_blank&#34;&gt;Lecture 3&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Stop the pod and the service before moving on. Here are the commands to do so:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubectl delete po/web-pod&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubectl delete svc/nginx-service&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;kubernetes-deploying-an-application&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;4&lt;/span&gt; Kubernetes: deploying an application&lt;/h1&gt;
&lt;p&gt;In this section, we’re going to deploy our pet store in Kubernetes.
As a reminder, our application consists of two services: &lt;code&gt;web&lt;/code&gt; and &lt;code&gt;db&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In order to define an application in Kubernetes,
we need to use two types of objects &lt;strong&gt;for each service&lt;/strong&gt; of the application:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;A &lt;strong&gt;workload resource&lt;/strong&gt; that gives the specification of the service, such as
the pods that make up the service itself (images, network settings) and metadata, such as
the desired number of instances.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A &lt;strong&gt;Service&lt;/strong&gt; object. As we have seen previously, a service object
exposes an IP address that allows client applications,
both inside and outside the Kubernetes cluster, to connect to the service.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When we define an application in Kubernetes, we rarely,
if ever, need to play directly with pods.
Instead, we can resort to higher-level objects, called &lt;strong&gt;Controllers&lt;/strong&gt;, for an easier
definition of the &lt;strong&gt;desired state&lt;/strong&gt; of the application itself.
The type of the controller that we need to use depends on the nature of the service
itself: &lt;strong&gt;stateless&lt;/strong&gt; or &lt;strong&gt;stateful&lt;/strong&gt; (slides 14-15 of &lt;a href=&#34;https://centralesupelec.edunao.com/pluginfile.php/136097/mod_resource/content/2/cm3-slides.pdf&#34; target=&#34;_blank&#34;&gt;Lecture 3&lt;/a&gt;.).&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-15&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.1  &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Is the service &lt;code&gt;web&lt;/code&gt; of our application stateless or stateful?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Is the service &lt;code&gt;db&lt;/code&gt; of our application stateless of stateful?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Stateful&lt;/strong&gt; service: one that manages permanent data and is bound to that data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stateless&lt;/strong&gt; service: one that is not bound to permanent data.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The service &lt;code&gt;web&lt;/code&gt; is &lt;strong&gt;stateless&lt;/strong&gt; because it does not have to be tightly bound to the data.
In other words, the service &lt;code&gt;web&lt;/code&gt; uses the data that is stored in the backend database, but
it can be scheduled on any node of the cluster independently of that data.&lt;/p&gt;
&lt;p&gt;The service &lt;code&gt;db&lt;/code&gt; is &lt;strong&gt;stateful&lt;/strong&gt; because it directly manages permanent data.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div id=&#34;the-web-service-deployment&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.1&lt;/span&gt; The &lt;code&gt;web&lt;/code&gt; service: deployment&lt;/h2&gt;
&lt;p&gt;For &lt;strong&gt;stateless application services&lt;/strong&gt;, we can use
a &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;Deployment&lt;/strong&gt;&lt;/a&gt; for the deployment of a set of identical pods
that are launched across several nodes in the Kubernetes cluster.&lt;/p&gt;
&lt;div class=&#34;infobox curiosity&#34;&gt;
&lt;p&gt;&lt;strong&gt;Deployment and ReplicaSet&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Deployments and ReplicaSets have been introduced
in slides 51-52-53 of the &lt;a href=&#34;https://centralesupelec.edunao.com/pluginfile.php/136097/mod_resource/content/2/cm3-slides.pdf&#34; target=&#34;_blank&#34;&gt;third lecture&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;We here define the specification of
a Deployment corresponding to the service &lt;code&gt;web&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: apps/v1
kind: Deployment
metadata:
  name: web
spec:
  replicas: 3
  selector:
    matchLabels:
      app: pets
      service: web
  template:
    metadata:
      labels:
        app: pets
        service: web
    spec:
      containers:
      - image: quercinigia/pet-store-web:1.0
        name: web
        ports:
        - containerPort: 3000
          protocol: TCP&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is the explanation of the specification:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;A Deployment named &lt;code&gt;web&lt;/code&gt; is created, as indicated by the field &lt;code&gt;metadata.name&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The Deployment creates three replicated pods, as indicated by the field
&lt;code&gt;spec.replicas&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The Deployment considers that the pods with &lt;strong&gt;both&lt;/strong&gt; labels &lt;code&gt;app: pets&lt;/code&gt; and
&lt;code&gt;service: web&lt;/code&gt; are part of the deployment.
This is indicated by the field &lt;code&gt;spec.selector.matchLabels&lt;/code&gt;.
This field is used to let the Deployment know how to find its pods.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The configuration of the pods that are part of the Deployment is
given in the field &lt;code&gt;spec.template&lt;/code&gt; and its subfields.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Each pod of the Deployment is given labels &lt;code&gt;app: pets&lt;/code&gt; and &lt;code&gt;service: web&lt;/code&gt;.
This is indicated by the field &lt;code&gt;spec.template.metadata.labels&lt;/code&gt;.
Note that here we specify exactly the same values as in &lt;code&gt;spec.selector.matchLabels&lt;/code&gt;.
This field is used to give pods labels so that they can be identified and located in
Kubernetes.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Each pod has exactly one container, named &lt;code&gt;web&lt;/code&gt;, run from the
image &lt;code&gt;quercinigia/pet-store-web:1.0&lt;/code&gt; stored in the DockerHub. The container listens on port 3000
and uses the TCP protocol. This is specified in the field &lt;code&gt;spec.template.spec.containers&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;infobox activitybox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Activity&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Copy and paste the previous specification to a new file &lt;code&gt;web-deployment.yaml&lt;/code&gt;
(or any name of your liking).
Make sure that you &lt;strong&gt;replace&lt;/strong&gt; the image &lt;code&gt;quercinigia/pet-store-web:1.0&lt;/code&gt;
with the one that you pushed to your DockerHub registry.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use the command &lt;code&gt;cd&lt;/code&gt; in the terminal to position yourself in the directory
where the file &lt;code&gt;web-deployment.yaml&lt;/code&gt; is stored.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Deploy this Deployment in Kubernetes by typing the following command:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;kubectl create -f web-deployment.yaml&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-16&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.2  &lt;/strong&gt;&lt;/span&gt;
Type the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubectl get all&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Which objects have been created following the creation of the
Deployment?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;We can clearly see three types of objects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Three pods, that correspond to the three replicas that we specified in the configuration.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;One deployment. Note that the 3/3 indicates that the deployment has
3 identical pods, of which 3 are running.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;One ReplicaSet. The Deployment creates a ReplicaSet, that is the actual object that
controls the three pods. The Deployment provides some additional services (i.e., updates)
on top of a ReplicaSet.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-17&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.3  &lt;/strong&gt;&lt;/span&gt;
Get the name of one of the running pods and
kill it by using the following command&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubectl delete name-of-pod&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If the command hangs in the terminal, feel free to type Ctrl-C to
get back control of the terminal.&lt;/p&gt;
&lt;p&gt;Type again following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubectl get all&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;How many pods do you see? Is it surprising?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;If we type the command right after deleting the pod, it is likely that we’ll see
four pods, one that is &lt;em&gt;terminating&lt;/em&gt; and another one that is &lt;em&gt;running&lt;/em&gt;.
Try to type the command until you see three running pods.&lt;/p&gt;
&lt;p&gt;This is not surprising.
If we kill the pod, the orchestrator detects a
deviation from the &lt;strong&gt;desired state&lt;/strong&gt; (which is, we want three replicas) and
reschedules immediately another pod.
This is what we mean by a &lt;strong&gt;self-healing system&lt;/strong&gt;. This is one of the major roles
of an orchestrator.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;the-web-service-service&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.2&lt;/span&gt; The &lt;code&gt;web&lt;/code&gt; service: service&lt;/h2&gt;
&lt;p&gt;Now we need to define a &lt;strong&gt;Service&lt;/strong&gt; in order to expose the web service to the public.
Here is the definition:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  name: web
spec:
  type: LoadBalancer
  ports:
  - port: 8080
    targetPort: 3000
    protocol: TCP
  selector:
    app: pets
    service: web&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-18&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.4  &lt;/strong&gt;&lt;/span&gt;
Describe the specification of this service.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;We create a service named &lt;code&gt;web&lt;/code&gt;. This indicated in the field
&lt;code&gt;metadata.name&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The service has type &lt;code&gt;LoadBalancer&lt;/code&gt;. This is indicated in the field
&lt;code&gt;spec.type&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The service listens on port 8080 and uses the TCP protocol.
Each service instance (i.e., pod) listens on port 3000.
This is indicated in the field &lt;code&gt;spec.ports&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The instances of the service (i.e., the pods) are those with labels
&lt;code&gt;app: pets&lt;/code&gt; and &lt;code&gt;service: web&lt;/code&gt;.
This is indicated in the field &lt;code&gt;spec.selector&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox activitybox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Activity&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Copy and paste the previous specification to a new file &lt;code&gt;web-service.yaml&lt;/code&gt;
(or any name of your liking).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use the command &lt;code&gt;cd&lt;/code&gt; in the terminal to position yourself in the directory
where the file &lt;code&gt;web-service.yaml&lt;/code&gt; is stored.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create the service with the following command:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;kubectl create -f web-service.yaml&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Verify that the service has been created with the following command:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;kubectl get services&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Locate the external IP (let’s call it EXTERNAL-IP) of the web service and type
the URL &lt;code&gt;http://EXTERNAL-IP:8080&lt;/code&gt; in your Web browser. You should
see a Web page where the phrase &lt;em&gt;Pet store&lt;/em&gt; appears.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;the-db-service-statefulset&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.3&lt;/span&gt; The &lt;code&gt;db&lt;/code&gt; service: StatefulSet&lt;/h2&gt;
&lt;p&gt;Kubernetes has defined a special type of ReplicaSet for stateful services that
is called &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;StatefulSet&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let’s define a StatefulSet to give the specification of
the &lt;code&gt;db&lt;/code&gt; service.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: db
spec:
  selector:
    matchLabels:
      app: pets
      service: db
  serviceName: db
  template:
    metadata:
      labels:
        app: pets
        service: db
    spec:
      containers:
      - image: quercinigia/pet-store-db:1.0
        name: db
        ports:
        - containerPort: 5432
        volumeMounts:
        - mountPath: /var/lib/postgresql/data
          name: pets-data
  volumeClaimTemplates:
  - metadata:
      name: pets-data
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 100Mi&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By now you shouldn’t have any problem understanding the meaning of the fields
in this specification.
The fields are also
documented in the &lt;a href=&#34;https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.21/#statefulsetspec-v1-apps&#34; target=&#34;_blank&#34;&gt;official Kubernetes documentation&lt;/a&gt;.
The only novelty is the field &lt;code&gt;volumeClaimTemplates&lt;/code&gt;.
It describes additional constraints on the volumes defined in the specification, in this case the volume
named &lt;code&gt;pets-data&lt;/code&gt; (where PostgreSQL keeps the data). In particular, two claims are given:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The access mode &lt;code&gt;ReadWriteOnce&lt;/code&gt; means that the volume can be mounted
as read-write by a single node in the Kubernetes cluster.
Access modes are &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes&#34; target=&#34;_blank&#34;&gt;documented here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We request at least 100MB of storage for the database.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;infobox activitybox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Activity&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Copy and paste the previous specification to a new file &lt;code&gt;db-stateful-set.yaml&lt;/code&gt;
(or any name of your liking).
Make sure that you &lt;strong&gt;replace&lt;/strong&gt; the image &lt;code&gt;quercinigia/pet-store-db:1.0&lt;/code&gt;
with the one that you pushed to your DockerHub registry.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use the command &lt;code&gt;cd&lt;/code&gt; in the terminal to position yourself in the directory
where the file &lt;code&gt;db-stateful-set.yaml&lt;/code&gt; is stored.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Deploy this StatefulSet in Kubernetes by typing the following command:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;kubectl create -f db-stateful-set.yaml&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-19&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.5  &lt;/strong&gt;&lt;/span&gt;
Type the command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubectl get all&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Which objects have been created when you deployed the StatefulSet?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;A pod (likely to be called &lt;code&gt;pod/db-0&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A new StatefulSet that governs the pod.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that the StatefulSet has only one pod, which is normal,
since we didn’t specify a higher number of replicas.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-20&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.6  &lt;/strong&gt;&lt;/span&gt;
Open the Web browser and type the following URL:&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;If you’re using Docker Desktop&lt;/summary&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;http://localhost:8080/pet&lt;/code&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;If you’re using Minikube on the Linux VM&lt;/summary&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;http://minikube-ip:8080/pet&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;where you’ll replace &lt;code&gt;minikube-ip&lt;/code&gt; with the external IP address associated with the
&lt;code&gt;web&lt;/code&gt; service.&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;Right after, type the command &lt;code&gt;kubectl get all&lt;/code&gt;.
What do you observe? Can you explain the reason?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;We cannot access the application.
If you type the command &lt;code&gt;kubectl get all&lt;/code&gt; quickly, you should show that the
three pods that are instances of the service &lt;code&gt;web&lt;/code&gt; are in an error state.
If you were too slow, you should see that the restart count of each pod has changed.
This means that the pods have been restarted because of an error.&lt;/p&gt;
&lt;p&gt;What happens here is that we launched the database,
but we didn’t create the Service that lets the clients
access the database.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;p&gt;In the output of the command &lt;code&gt;get kubectl all&lt;/code&gt;, look at the names of the
pods that are instances of the &lt;code&gt;web&lt;/code&gt; service.
&lt;!-- in the TP you can even ask why all the three instances got an error--&gt;
Take the name of any these pods,
and put it in place of NAME-OF-POD in the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubectl logs NAME-OF-POD --previous&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-21&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.7  &lt;/strong&gt;&lt;/span&gt;
Does the output of the previous command confirm the explanation
given in the previous question?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;Yes, we can clearly read ENOTFOUND db db:5432.
This means that Kubernetes cannot resolve the name &lt;code&gt;db&lt;/code&gt; to an IP address.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;the-db-service-service-object&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;5&lt;/span&gt; The &lt;code&gt;db&lt;/code&gt; service: Service object&lt;/h1&gt;
&lt;p&gt;From the above observations, we understand that we need to define
a service to expose the database to the clients.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-22&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 5.1  &lt;/strong&gt;&lt;/span&gt;
Should the &lt;code&gt;db&lt;/code&gt; service be accessible to client applications that are external to
the Kubernetes cluster?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;No, this component is the backend of the application. The only client
that needs to access the database is the frontend, that is the
&lt;code&gt;web&lt;/code&gt; service, that runs inside the cluster.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-23&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 5.2  &lt;/strong&gt;&lt;/span&gt;
Given the answer to the previous question, what should the type of this service be?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;&lt;strong&gt;ClusterIP&lt;/strong&gt;; this is the type of a service that does not need to
be exposed to the outside world.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-24&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 5.3  &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Write the specification of the &lt;code&gt;db&lt;/code&gt; service in a file
named &lt;code&gt;db-service.yaml&lt;/code&gt; (or any other name of your liking).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Caution.&lt;/strong&gt; In the file &lt;code&gt;db-stateful-set.yaml&lt;/code&gt; the field &lt;code&gt;spec.serviceName&lt;/code&gt; indicates the name
that the service must have.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  name: db
spec:
  type: ClusterIP
  ports:
  - port: 5432
    protocol: TCP
  selector:
    app: pets
    service: db&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox activitybox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Activity&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Deploy the service by typing the following command:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;kubectl create -f db-service.yaml&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Verify that the service has been created with the following command:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;kubectl get all&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Verify that you can reach the application at &lt;code&gt;http://localhost:8080/pet&lt;/code&gt; (Minikube users:
replace &lt;code&gt;localhost&lt;/code&gt; with the external IP address associated to the &lt;code&gt;web&lt;/code&gt; service!).
&lt;strong&gt;It might happen&lt;/strong&gt; that the database service is not ready yet, and so you’ll get
a connection error. Just wait and retry later.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;shutting-down-the-application-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;5.1&lt;/span&gt; Shutting down the application&lt;/h2&gt;
&lt;p&gt;After you’re done with the application, you can shut it down with the following commands:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubectl delete svc/web&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubectl delete svc/db&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubectl delete deploy/web&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubectl delete statefulset/db&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The order in which you type these commands doesn’t matter.&lt;/p&gt;
&lt;p&gt;If you type multiple times the command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubectl get all&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;you should see that the resources progressively disappear.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;5.2&lt;/span&gt; Conclusion&lt;/h2&gt;
&lt;p&gt;In the previous exercises, we deployed an application with two services, for which we had to create
four files and type as many commands.
For larger applications this gets a bit annoying.
We can write all the definitions in a single file (e.g., &lt;code&gt;pets.yaml&lt;/code&gt;)
where each specification is terminated by - - -.&lt;/p&gt;
&lt;p&gt;Here is an example, where we write the specification of the
Service and Deployment associated with the service &lt;code&gt;web&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  name: web
spec:
  type: LoadBalancer
  ports:
  - port: 8080
    targetPort: 3000
    protocol: TCP
  selector:
    app: pets
    service: web
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web
spec:
  replicas: 3
  selector:
    matchLabels:
      app: pets
      service: web
  template:
    metadata:
      labels:
        app: pets
        service: web
    spec:
      containers:
      - image: quercinigia/pet-store-web:1.0
        name: web
        ports:
        - containerPort: 3000
          protocol: TCP&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Multi-service applications in the Cloud</title>
      <link>/courses/cloud-computing/labs/kube-lab/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/cloud-computing/labs/kube-lab/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;div id=&#34;objectives&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;Objectives&lt;/h1&gt;
&lt;p&gt;In this lab assignment you will:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Gain a deeper understanding of the &lt;strong&gt;Docker networking model&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Build and deploy a multi-service application with &lt;strong&gt;Docker Compose&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Deploy a multi-service application on a &lt;strong&gt;local Kubernetes cluster&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Deploy a multi-service application on a &lt;strong&gt;Kubernetes cluster&lt;/strong&gt; in &lt;strong&gt;Microsoft Azure&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;submission&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;Submission&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Each submission must be &lt;strong&gt;individual&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In order to submit your work, you need to answer all the questions
that you &lt;strong&gt;&lt;a href=&#34;https://centralesupelec.edunao.com/mod/quiz/view.php?id=51255&#34; target=&#34;_blank&#34;&gt;find here&lt;/a&gt;&lt;/strong&gt;.
Each question corresponds to an exercise that you find in this page.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;You can answer either &lt;strong&gt;in French&lt;/strong&gt; or &lt;strong&gt;in English&lt;/strong&gt;. Your pick!&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Deadline: 21 May 2021, 23h59&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This lab assignment is &lt;strong&gt;evaluated&lt;/strong&gt;.
You won’t have access to the solutions.
You &lt;strong&gt;can ask questions anytime&lt;/strong&gt; (even after the Friday 7 May lab session),
should you run into problems
with the implementation of the assignment.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;docker-networking-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Docker networking model&lt;/h1&gt;
&lt;p&gt;We developed a simple chat room in Python that you can download
&lt;a href=&#34;/courses/cloud-computing/kube-lab/chat-room.zip&#34;&gt;here&lt;/a&gt;.
The code has been adapted from &lt;a href=&#34;https://github.com/pricheal/python-client-server/&#34; target=&#34;_blank&#34;&gt;this GitHub project&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Participants use a &lt;em&gt;client&lt;/em&gt; program to connect to the chat room;
the chat room is managed by a &lt;em&gt;server&lt;/em&gt; application that receives the
client connections and forwards the messages between the users.
The archive contains the following files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;client.py&lt;/em&gt;. Implementation of the chat room client.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;server.py&lt;/em&gt;. Implementation of the chat room server.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;utils.py&lt;/em&gt;. Library with utility functions used in both &lt;em&gt;client.py&lt;/em&gt; and &lt;em&gt;server.py&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Only one instance of the server is running.
Several instances of the client can run at the same time.
Client instances might not be running on the same host.&lt;/p&gt;
&lt;p&gt;In order to execute the server, we need to specify the port number as a parameter.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:client-server-methodology&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.1  &lt;/strong&gt;&lt;/span&gt;Explain the methodology that you’re going to follow to containerize the client and
the server by using Docker. In particular explain:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;How many images you’re creating and why.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What you need to build the images in Docker.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Which command are you using to build the images.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-1&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.2  &lt;/strong&gt;&lt;/span&gt;Containerize the application by following the methodology that you outlined in Exercise &lt;a href=&#34;#exr:client-server-methodology&#34;&gt;1.1&lt;/a&gt;.&lt;/p&gt;
&lt;strong&gt;Upload the Dockerfiles in the corresponding question on Edunao.&lt;/strong&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The size of the images should be kept as small as possible.
Remember to include in the images only what you need to build and run the application.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox curiosity&#34;&gt;
&lt;p&gt;&lt;strong&gt;Good to know&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If you need to inspect the file system of an
image that you create (e.g., to verify that the files that you
copied are actually there), you can open a terminal
in the image by using the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker run -it --entrypoint sh IMAGE_NAME&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-2&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.3  &lt;/strong&gt;&lt;/span&gt;
If you built more than one image:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Do they have some common layers?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;If so, is it something that has an impact on the build time and how?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;client-and-server-on-the-same-network&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.1&lt;/span&gt; Client and server on the same network&lt;/h2&gt;
&lt;p&gt;We want to execute:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;One instance of the server.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Two instances of the client.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The server, as well as the clients, will
&lt;strong&gt;run in Docker containers attached to the same network&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-3&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.4  &lt;/strong&gt;&lt;/span&gt;
We want to make sure that:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;The server and the clients can communicate with each other.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Other Docker containers &lt;strong&gt;cannot&lt;/strong&gt; communicate neither with the server nor with the clients.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;How can you satisfy both requirements in Docker? Explain your solution
and justify it.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:client-server-single-network&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.5  &lt;/strong&gt;&lt;/span&gt;
Execute the server and the two clients by using the network configuration that you
explained in the previous exercise.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The server writes messages on the terminal. Remember to launch the container with the appropriate
options in order to actually see those messages.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Users need to interact with the client, that is: read and write messages.
Remember to launch the container with the appropriate options in order to actually see those messages.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Write the &lt;strong&gt;exact commands&lt;/strong&gt; that you typed for both configuring the network and
launching the server and the clients. &lt;strong&gt;Explain these commands.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Shut down the application!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Shut down both the clients and the server before you move on.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;On the client-side, type &lt;code&gt;#quit&lt;/code&gt; at any moment to exit the chat room.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Type Ctrl-C to stop the server.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;client-and-server-on-different-networks&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.2&lt;/span&gt; Client and server on different networks&lt;/h2&gt;
&lt;p&gt;We want to execute:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;One instance of the server.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Two instances of the client.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, &lt;strong&gt;neither client&lt;/strong&gt; is connected to the same network as the server.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-4&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.6  &lt;/strong&gt;&lt;/span&gt;
Why can’t you launch the containers with the same settings as
in Exercise &lt;a href=&#34;#exr:client-server-single-network&#34;&gt;1.5&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;What do you propose as a solution instead?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;HINT.&lt;/strong&gt; You might want to look at &lt;a href=&#34;https://centralesupelec.edunao.com/pluginfile.php/135595/mod_resource/content/2/cm2-slides.pdf&#34; target=&#34;_blank&#34;&gt;slide 77 of the second lecture&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-5&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.7  &lt;/strong&gt;&lt;/span&gt;
Execute the server and the two clients by making sure that neither client is connected to the
same network as the server.&lt;/p&gt;
&lt;p&gt;Write the &lt;strong&gt;exact commands&lt;/strong&gt; that you typed
for both configuring the network and launching the server and the clients.
&lt;strong&gt;Explain these commands.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Shut down the application!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Shut down both the clients and the server before you move on.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;On the client-side, type &lt;code&gt;#quit&lt;/code&gt; at any moment to exit the chat room.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Type Ctrl-C to stop the server.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;!-- docker run -it --entrypoint sh quercinigia/webmeal this is to look into an image --&gt;
&lt;!-- exercise on docker-compose. Look at what Clara Gross did last year --&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;multi-service-application-docker-compose&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; Multi-service application: Docker Compose&lt;/h1&gt;
&lt;p&gt;We intend to build and deploy the application &lt;em&gt;TripMeal&lt;/em&gt;
by using &lt;strong&gt;Docker Compose&lt;/strong&gt;.
You can download the application
&lt;a href=&#34;/courses/cloud-computing/kube-lab/tripmeal.zip&#34;&gt;here&lt;/a&gt;.
The source code has been readapted from
&lt;a href=&#34;https://github.com/DanielAndreasen/TripMeal&#34; target=&#34;_blank&#34;&gt;this GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The downloaded file is an archive.
Extracting the archive will create a folder named
&lt;code&gt;tripmeal_sujet&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-6&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.1  &lt;/strong&gt;&lt;/span&gt;
Explain the structure of the content of the folder &lt;code&gt;tripmeal_sujet&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-7&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.2  &lt;/strong&gt;&lt;/span&gt;
How many services has the application?
Specify the technologies (a.k.a., programming languages) used to implement each service.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;Dockerfile&lt;/code&gt; in the directory &lt;code&gt;db&lt;/code&gt; is already implemented.&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Warning for those using Linux&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In order to avoid an &lt;code&gt;Exec format error&lt;/code&gt; when you launch the application,
you’ll need to add to your Dockerfile an instruction:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;RUN chmod -x path_to_file_app&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;where &lt;code&gt;path_to_file_app&lt;/code&gt; is the path to the file &lt;code&gt;app.py&lt;/code&gt;
&lt;strong&gt;inside the image&lt;/strong&gt;.&lt;/p&gt;
&lt;!-- https://stackoverflow.com/questions/55271912/flask-cli-throws-oserror-errno-8-exec-format-error-when-run-through-docker--&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-8&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.3  &lt;/strong&gt;&lt;/span&gt;
Write the &lt;code&gt;Dockerfile&lt;/code&gt; in the directory &lt;code&gt;web&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Upload the Dockerfile to Edunao&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;In the folder &lt;code&gt;tripmeal_sujet&lt;/code&gt;, you’ll find a file named &lt;code&gt;tripmeal.env&lt;/code&gt;.
It contains the definition of &lt;strong&gt;environment variables&lt;/strong&gt; that
are used in the application.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-9&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.4  &lt;/strong&gt;&lt;/span&gt;
By reading the values of the environment variables, you can already
know the values to assign to some of the keys in &lt;code&gt;docker-compose.yml&lt;/code&gt;.
Can you tell which ones?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-10&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.5  &lt;/strong&gt;&lt;/span&gt;
What do you need to define in file &lt;code&gt;docker-compose.yml&lt;/code&gt;
to enable the communication between the different services?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The database management system used by the application is MySQL.
You can see it by reading the &lt;code&gt;Dockerfile&lt;/code&gt; in the directory &lt;code&gt;tripmeal_sujet/db&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-11&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.6  &lt;/strong&gt;&lt;/span&gt;
Which base image is used to build a container for the database?
Where is this base image stored?
Can you find the documentation of this image in the Internet?
Write down the link to the documentation page in the answer.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-12&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.7  &lt;/strong&gt;&lt;/span&gt;
By looking at the documentation of the database image,
what do you need to define in &lt;code&gt;docker-compose.yml&lt;/code&gt;
to make sure that the data is not deleted once the application is taken down?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;You’re finally ready to complete the file &lt;code&gt;docker-compose.yml&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Remember that you need to pass the &lt;strong&gt;environment variables&lt;/strong&gt;
to your application.&lt;/p&gt;
&lt;p&gt;As a documentation of Docker Compose you can use:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The &lt;a href=&#34;/courses/cloud-computing/tutorials/tutorial-kube&#34; target=&#34;_blank&#34;&gt;examples that we’ve seen together&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The overview presented on the &lt;a href=&#34;https://docs.docker.com/compose/&#34; target=&#34;_blank&#34;&gt;official Docker website&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;You can also find the full specification of Compose &lt;a href=&#34;https://github.com/compose-spec/compose-spec/blob/master/spec.md&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-13&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.8  &lt;/strong&gt;&lt;/span&gt;
Write the file &lt;code&gt;docker-compose.yml&lt;/code&gt;.
Build, deploy and test your application.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Upload the file &lt;code&gt;docker-compose.yml&lt;/code&gt; to Edunao.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-14&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.9  &lt;/strong&gt;&lt;/span&gt;
Push all the images that you built in this section to
your DockerHub registry.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;In the answer to this exercise write the complete names of these images.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Shut down the application!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Shut down both the application before you move on.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;local-kubernetes-cluster&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; Local Kubernetes cluster&lt;/h1&gt;
&lt;p&gt;We intend to deploy the application &lt;em&gt;TripMeal&lt;/em&gt; on
a &lt;strong&gt;local Kubernetes cluster&lt;/strong&gt; (either Docker Desktop or Minikube).&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-15&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3.1  &lt;/strong&gt;&lt;/span&gt;
For each service of the application &lt;em&gt;TripMeal&lt;/em&gt;, specify which are &lt;strong&gt;stateless&lt;/strong&gt;
and which are &lt;strong&gt;stateful&lt;/strong&gt;. Justify your answer.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-16&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3.2  &lt;/strong&gt;&lt;/span&gt;
For each service of the application &lt;em&gt;TripMeal&lt;/em&gt;, specify
which Kubernetes objects you need to create and their types.
Justify your answers.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-17&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3.3  &lt;/strong&gt;&lt;/span&gt;
For each Kubernetes object:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Configure.&lt;/strong&gt; Write a Yaml configuration file. Remember that you need to pass the application the environment variables.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Create.&lt;/strong&gt; Create the object in Kubernetes. Which command are you using?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Analyze.&lt;/strong&gt; Execute the command &lt;code&gt;kubectl get all&lt;/code&gt; and explain in detail which objects appear in the output as the result of step 2.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox activitybox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Activity&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Play with the application in order to verify that everything works as expected.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Shut down the application!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Shut down the application by removing all the Kubernetes objects.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-18&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3.4  &lt;/strong&gt;&lt;/span&gt;
Create a new file called &lt;code&gt;tripmeal.yml&lt;/code&gt; that contains the
definition of all the Kubernetes objects of the application, as we have seen
in the &lt;a href=&#34;/courses/cloud-computing/tutorials/tutorial-kube#conclusion&#34; target=&#34;_blank&#34;&gt;conclusion of the tutorial 2&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Upload this file to Edunao.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;kubernetes-cluster-on-microsoft-azure&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;4&lt;/span&gt; Kubernetes cluster on Microsoft Azure&lt;/h1&gt;
&lt;p&gt;You’re now going to create a Kubernetes cluster on &lt;strong&gt;Microsoft Azure&lt;/strong&gt;
and deploy &lt;em&gt;TripMeal&lt;/em&gt; on that cluster.&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In order to perform this activity, you need a &lt;strong&gt;student subscription&lt;/strong&gt; on Microsoft Azure.
If you haven’t activated it yet:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Connect to &lt;a href=&#34;https://azure.microsoft.com/en-us/free/students/&#34; target=&#34;_blank&#34;&gt;this webpage&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Click on &lt;code&gt;Start free&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Sign in by using your CentraleSupélec credentials.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Follow the instructions.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;During this activity, you’ll need to answer some questions that encourage you to
gain a deeper knowledge of the Azure platform and better understand the commands that you type.
&lt;strong&gt;Feel free to read the documentation on the Azure platform in order to answer the questions.&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;installing-the-azure-cli&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.1&lt;/span&gt; Installing the Azure CLI&lt;/h2&gt;
&lt;p&gt;In order to create the Kubernetes cluster and deploy the application,
you need to install the &lt;strong&gt;Azure Command Line Interface (CLI)&lt;/strong&gt;.
It’s a terminal where you’ll type the commands to create the resources
on Azure.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;Windows users&lt;/summary&gt;
Follow the instructions at &lt;a href=&#34;https://docs.microsoft.com/en-us/cli/azure/install-azure-cli-windows?tabs=azure-cli&#34; target=&#34;_blank&#34;&gt;this Web page&lt;/a&gt;.
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;macOS users&lt;/summary&gt;
Follow the instructions at &lt;a href=&#34;https://docs.microsoft.com/en-us/cli/azure/install-azure-cli-macos&#34; target=&#34;_blank&#34;&gt;this Web page&lt;/a&gt;.
&lt;/details&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;VM Linux users&lt;/summary&gt;
Open a terminal and type the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;When prompted for a password, just type ENTER and wait for the installation to finish.&lt;/p&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;login-to-azure-through-cli&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.2&lt;/span&gt; Login to Azure through CLI&lt;/h2&gt;
&lt;p&gt;Whether you’re on Windows, macOS or Linux, you need to &lt;strong&gt;open a terminal&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In order to log in to your Azure account, type the following command:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;az login&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A Web page will open in your default Web browser, where you can type your username and
password (your CentraleSupélec credentials).
After authenticating your Azure account, you can go back to the terminal, where you should see
some information about your account, such as:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[
  {
    &amp;quot;cloudName&amp;quot;: &amp;quot;AzureCloud&amp;quot;,
    &amp;quot;homeTenantId&amp;quot;: &amp;quot;&amp;lt;id&amp;gt;&amp;quot;,
    &amp;quot;id&amp;quot;: &amp;quot;&amp;lt;id&amp;gt;&amp;quot;,
    &amp;quot;isDefault&amp;quot;: true,
    &amp;quot;managedByTenants&amp;quot;: [],
    &amp;quot;name&amp;quot;: &amp;quot;Azure for Students&amp;quot;,
    &amp;quot;state&amp;quot;: &amp;quot;Enabled&amp;quot;,
    &amp;quot;tenantId&amp;quot;: &amp;quot;&amp;lt;id&amp;gt;&amp;quot;,
    &amp;quot;user&amp;quot;: {
      &amp;quot;name&amp;quot;: &amp;quot;&amp;lt;email-address&amp;gt;&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;user&amp;quot;
    }
  }
]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;deploy-and-use-azure-container-registry&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.3&lt;/span&gt; Deploy and use Azure Container Registry&lt;/h2&gt;
&lt;p&gt;When we run TripMeal on a local Kubernetes cluster, we assumed that our computer
could have a direct access to the Internet and, therefore, to the DockerHub registry, where we
could pull the images of the TripMeal services.
When we run a containerized application in production, we cannot make this assumption
as the production servers have often no direct access to the Internet.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-20&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.1  &lt;/strong&gt;&lt;/span&gt;
In your view, why isn’t it a good idea to have production servers directly
connected to the Internet?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We need to place the images in a container registry that is in the same context
as our production servers.
Since we’re going to run the application on Azure, we can use the
&lt;strong&gt;Azure Container Registry (ACR)&lt;/strong&gt;.&lt;/p&gt;
&lt;div id=&#34;registry-creation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.3.1&lt;/span&gt; Registry creation&lt;/h3&gt;
&lt;p&gt;First, we need to create a &lt;strong&gt;resource group&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-21&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.2  &lt;/strong&gt;&lt;/span&gt;
What is a &lt;strong&gt;resource group&lt;/strong&gt; in Azure and how is it useful?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The command to create a new resource group is the following
(replace RES_GRP_NAME with a name of your choice).&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;az group create --name  RES_GRP_NAME --location eastus&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-23&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.3  &lt;/strong&gt;&lt;/span&gt;
In the previous command, what does the &lt;code&gt;location&lt;/code&gt; refer to?
Briefly describe this notion (presented in &lt;a href=&#34;https://centralesupelec.edunao.com/pluginfile.php/135424/mod_resource/content/5/cm1-slides.pdf&#34; target=&#34;_blank&#34;&gt;Lecture 1&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Next, we need to create a &lt;strong&gt;container registry&lt;/strong&gt; with the following command
(replace RES_GRP_NAME with the name of your resource group and REG_NAME with a name of your choice for the registry).&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;az acr create --resource-group RES_GRP_NAME --name REG_NAME --sku Basic&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-25&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.4  &lt;/strong&gt;&lt;/span&gt;
In the previous command, what does the &lt;code&gt;sku&lt;/code&gt; refer to?
Feel free to look up on the Azure website to find the answer.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;registry-login&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.3.2&lt;/span&gt; Registry login&lt;/h3&gt;
&lt;p&gt;After creating the registry, we can log into it with the following command:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;az acr login --name REG_NAME&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;image-tagging&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.3.3&lt;/span&gt; Image tagging&lt;/h3&gt;
&lt;p&gt;We’re almost ready to push the images that compose the application &lt;em&gt;TripMeal&lt;/em&gt; to the registry.
In order to do that, we need to &lt;strong&gt;tag&lt;/strong&gt; (i.e., rename) our images so that their names are
preceded by the &lt;strong&gt;login server name&lt;/strong&gt; of the registry.&lt;/p&gt;
&lt;p&gt;In order to get the name of the &lt;strong&gt;login server name&lt;/strong&gt;
(that we denote here as &lt;code&gt;acrloginserver&lt;/code&gt;) of your registry, you can type
the following command:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;az acr list --resource-group RES_GRP_NAME --query &amp;quot;[].{acrLoginServer:loginServer}&amp;quot; --output table&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Your &lt;code&gt;acrloginserver&lt;/code&gt; will be something like &lt;code&gt;xxx.azurecr.io&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-28&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.5  &lt;/strong&gt;&lt;/span&gt;
Tag the images that correspond to the services of the application &lt;em&gt;TripMeal&lt;/em&gt; so that
their name is similar to: &lt;code&gt;acrloginserver/nameofimage:latest&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Write the &lt;strong&gt;exact Docker command&lt;/strong&gt; that you use to tag the images.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;pushing-the-images&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.3.4&lt;/span&gt; Pushing the images&lt;/h3&gt;
&lt;p&gt;We can push the images with the following command (use your image name
instead of &lt;code&gt;xxx.azurecr.io/imagename:latest&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;docker push xxx.azurecr.io/imagename:latest&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Make sure to &lt;strong&gt;type this command for each image&lt;/strong&gt; that you want to push.&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It might take few minutes before the images are completely pushed to the registry.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Finally, verify that the images are actually in the registry with the following command:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;az acr repository list --name REG_NAME --output table&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;deploy-a-kubernetes-cluster&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.4&lt;/span&gt; Deploy a Kubernetes cluster&lt;/h2&gt;
&lt;p&gt;We now deploy a &lt;strong&gt;Kubernetes cluster on Azure&lt;/strong&gt;.&lt;/p&gt;
&lt;div id=&#34;cluster-creation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.4.1&lt;/span&gt; Cluster creation&lt;/h3&gt;
&lt;p&gt;We create the cluster with the following command (replace CLUSTER_NAME
with a name of your choice. As before, RES_GRP_NAME is the name of your resource group
and REG_NAME is the name of the container registry).&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;az aks create \
    --resource-group RES_GRP_NAME \
    --name CLUSTER_NAME \
    --node-count 2 \
    --generate-ssh-keys \
    --attach-acr REG_NAME&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The cluster will take a while to start. Time for a coffee!
But before, answer the following question!&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-32&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.6  &lt;/strong&gt;&lt;/span&gt;
Can you tell the meaning of the options in the previous command?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;connect-to-the-cluster&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.4.2&lt;/span&gt; Connect to the cluster&lt;/h3&gt;
&lt;p&gt;We can configure &lt;code&gt;kubectl&lt;/code&gt; to connect to the newly created cluster.
You need to type the following command:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;az aks get-credentials --resource-group RES_GRP_NAME --name CLUSTER_NAME&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, your Kubernetes cluster should be visible locally.
To verify it, type the following command:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;kubectl config get-contexts&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here &lt;em&gt;context&lt;/em&gt; refers to the Kubernetes clusters that &lt;em&gt;kubectl&lt;/em&gt; has access to.
The Kubernetes cluster that you created on Azure should be visible in the output; an asterisk
should appear in front of its name, indicating that it is the &lt;em&gt;current context&lt;/em&gt;
(that is the Kubernetes cluster being currently referenced by &lt;code&gt;kubectl&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Type the following command:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;kubectl get nodes&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should see that the Kubernetes cluster has &lt;strong&gt;two nodes&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;deploy-the-application&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.5&lt;/span&gt; Deploy the application&lt;/h2&gt;
&lt;p&gt;We’re almost done! The images are in the registry, the Kubernetes cluster is up and running.
The only missing piece of the puzzle is our application &lt;em&gt;TripMeal&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;First thing to do is to slightly modify the file &lt;code&gt;tripmeal.yml&lt;/code&gt; that you created at the end
of the previous section.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-36&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.7  &lt;/strong&gt;&lt;/span&gt;
Look at the names of the images of each service in that file. How must these names change?
Modify the file accordingly (&lt;strong&gt;no need to upload it on Edunao&lt;/strong&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;It is the moment of truth!
Deploy your application by typing the following command:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;kubectl apply -f tripmeal.yml&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Look at Kubernetes objects created after this command:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;kubectl get all&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Get the external IP address of the web service and try to connect to the application,
in the same way you did in the previous section.&lt;/p&gt;
&lt;p&gt;If you can play with the application like you did in your local deployment it means that you reached
the conclusion of this assignment! Bravo!&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-39&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.8  &lt;/strong&gt;&lt;/span&gt;
Submit a &lt;strong&gt;video&lt;/strong&gt; like that the one that &lt;a href=&#34;https://webtv.centralesupelec.fr/permalink/v1261a00b74dbbzwk2vr/&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;you can see here&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The video must &lt;strong&gt;clearly&lt;/strong&gt; show that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;You’re connected to &lt;strong&gt;your Azure portal&lt;/strong&gt; (Email address on the top right corner of the portal).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;All the passages that you see in the sample video: you need to show the &lt;strong&gt;public IP address&lt;/strong&gt;
of the application that you deployed, use that address to connect to your application and play
with the application to show that it works correctly.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The next exercise is &lt;strong&gt;optional&lt;/strong&gt;.
Before you leave, &lt;strong&gt;make sure to read the conclusion of this document!!&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-40&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.9  &lt;/strong&gt;&lt;/span&gt;
The title of this exercise is &lt;em&gt;Cerise sur le gâteau&lt;/em&gt; (aka, this is &lt;strong&gt;optional&lt;/strong&gt;!).&lt;/p&gt;
&lt;p&gt;At this point, you can connect to &lt;em&gt;TripMeal&lt;/em&gt; by using an IP address.
It would be nice if you could use a URL, like in the real websites.
Can you find a way to assign a URL to your web service? &lt;strong&gt;Describe your procedure.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You need a bit of Googling here….&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Make sure you follow these instructions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Take down your application in Kubernetes by using the &lt;code&gt;kubectl delete&lt;/code&gt; command on each
object that you created.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Change the context of the &lt;code&gt;kubectl&lt;/code&gt; command so that it points back
to a local Kubernetes cluster.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If your local Kubernetes cluster is &lt;code&gt;docker-desktop&lt;/code&gt; type the following command:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;kubectl config use-context docker-desktop&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If your local Kubernetes cluster is &lt;code&gt;minikube&lt;/code&gt; type the following command:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;kubectl config use-context minikube&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;On your Azure portal &lt;strong&gt;destroy all the resources&lt;/strong&gt; linked to the application
&lt;em&gt;TripMeal&lt;/em&gt;, otherwise you’ll get billed even if you don’t use them!&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;You can check the balance of your Azure credit &lt;a href=&#34;https://www.microsoftazuresponsorships.com/Balance&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;You can stop Docker and Kubernetes if you don’t need it anymore.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>MapReduce</title>
      <link>/courses/big-data-marseille/tutorials/map-reduce/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/big-data-marseille/tutorials/map-reduce/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;div id=&#34;computing-averages&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Computing averages&lt;/h1&gt;
&lt;p&gt;We are given a dataset that
contains the average monthly
temperature measurements
over the course of some years.
More precisely, the dataset is stored in a CSV file,
where each row corresponds to a monthly
measurement and the columns contain the following values:
year, month, average temperature in the month.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1980,1,5
1980,2,2
1980,3,10
1980,4,14
1980,5,17
....
1981,1,2
1981,2,1
1981,3,3
1981,4,10
....&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We intend to get the average monthly temperature for each year.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-1&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.1  &lt;/strong&gt;&lt;/span&gt;
Write a MapReduce algorithm that generates key-value pairs
&lt;span class=&#34;math inline&#34;&gt;\((year, average\_temperature)\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;map: &lt;span class=&#34;math inline&#34;&gt;\((year, month, temperature) \rightarrow (year, temperature)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;reduce: &lt;span class=&#34;math inline&#34;&gt;\((year, temps) \rightarrow\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\((year, sum(temps)/len(temps))\)&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(temps\)&lt;/span&gt; is the list of all temperatures in the same &lt;span class=&#34;math inline&#34;&gt;\(year\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(sum(temps)\)&lt;/span&gt; sums all the elements in the list &lt;span class=&#34;math inline&#34;&gt;\(temps\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(len(temps)\)&lt;/span&gt; gives the length of the list &lt;span class=&#34;math inline&#34;&gt;\(temps\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;p&gt;Suppose now that we have a large CSV file
stored in a distributed file system (e.g., HDFS),
containing a series of measurements in the format “Year, Month, Day, Minute, Second, Temperature”.
We can have up to one measurement per second in some years.
Like before, we’d like to compute key-value pairs (year, average_temperature) by using
a MapReduce algorithm.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-2&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.2  &lt;/strong&gt;&lt;/span&gt;
What is the maximum number of measurements in a year?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;Since we can have up to one measurement per second, the maximum number of
measurements &lt;span class=&#34;math inline&#34;&gt;\(M_{max}\)&lt;/span&gt; for a certain year is given by the following formula:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
M_{max} = 365 \times 24 \times 60 \times 60 \approx 31.5 \times 10^6 
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-3&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.3  &lt;/strong&gt;&lt;/span&gt;
Considering the answer to the previous question, discuss the efficiency
of the first implementation of the algorithm.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;Since there might be up to 31 million values
associated with a key, the bottleneck of the computation would be
the shuffle operation, since we need to copy a high number of
(key,value) pairs from the mappers to the reducers.&lt;/p&gt;
&lt;p&gt;Also, a reducer might have to
loop over a huge list of values in order to compute their average.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-4&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.4  &lt;/strong&gt;&lt;/span&gt;
Based on the answer to the previous question,
propose a better implementation to handle the CSV file.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;map: &lt;span class=&#34;math inline&#34;&gt;\((year, mo, d, mi, sec, temperature) \rightarrow (year, temperature)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;combine: &lt;span class=&#34;math inline&#34;&gt;\((year, temps) \rightarrow\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\((year, (sum(temps), len(temps)))\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;reduce: &lt;span class=&#34;math inline&#34;&gt;\((year, [(s_i, l_i),\ i=1\dots n]) \rightarrow\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\((year, \frac{\sum_{i=1}^n s_i}{\sum_{i=1}^n l_i})\)&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(temps\)&lt;/span&gt; is the list of all temperatures in the same &lt;span class=&#34;math inline&#34;&gt;\(year\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(sum(temps)\)&lt;/span&gt; sums all the elements in the list &lt;span class=&#34;math inline&#34;&gt;\(temps\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(len(temps)\)&lt;/span&gt; gives the length of the list &lt;span class=&#34;math inline&#34;&gt;\(temps\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;computing-average-and-standard-deviation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; Computing average and standard deviation&lt;/h1&gt;
&lt;p&gt;We consider again the large CSV file
with a series of measurements in the format “Year, Month, Day, Minute, Second, Temperature”.
We now intend to generate a series of key-value pairs (year, (avg_temperature, std_deviation)).&lt;/p&gt;
&lt;p&gt;We can express the standard deviation of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; values &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; (&lt;span class=&#34;math inline&#34;&gt;\(1 \leq i \leq n\)&lt;/span&gt;) with two different
equations.&lt;/p&gt;
&lt;p&gt;The first equation is as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\sigma = \sqrt{\frac{\sum_{i=1}^n (x_i - \overline{x})^2}{n}} 
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The second equation is as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\sigma = \sqrt{\overline{x^2} - \overline{x}^2} = \sqrt{\frac{\sum_{i=1}^n (x_i)^2}{n} - \Bigg(\frac{\sum_{i=1}^n x_i}{n}\Bigg)^2} 
\]&lt;/span&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-5&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.1  &lt;/strong&gt;&lt;/span&gt;
Which equation of the standard deviation
is more appropriate in a Map-Reduce algorithm?
Why?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;The second equation is more appropriate because it allows the computation
of the sum of the elements and of the square of the elements step by step
by using map and combine together.&lt;/p&gt;
&lt;p&gt;Instead, if we use the first equation, we need first to compute the average and then use it
to compute the variance.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-6&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.2  &lt;/strong&gt;&lt;/span&gt;
Propose a MapReduce implementation to compute the average and the standard
deviation of the temperatures for each year.
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;map: &lt;span class=&#34;math inline&#34;&gt;\((year, mo, d, mi, sec, temperature) \rightarrow (year, temperature)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;combine: &lt;span class=&#34;math inline&#34;&gt;\((year, T) \rightarrow\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\((year, (sum(T), sum(T^2), len(T)))\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;reduce: &lt;span class=&#34;math inline&#34;&gt;\((year, [(s_{i}, sq_{i}, l_{i}),\ i=1\dots n]) \rightarrow\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\((year, (\mu, \sigma))\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; is the list of all temperatures in the same &lt;span class=&#34;math inline&#34;&gt;\(year\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(sum(T)\)&lt;/span&gt; sums all the elements in the list &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(T^2 = [x^2 | x\in T]\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(len(T)\)&lt;/span&gt; gives the length of the list &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu = \sum_{i=1}^n s_{i}/ \sum_{i=1}^n l_{i}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma = \sqrt{ (\sum_{i=1}^n sq_{i}/ \sum_{i=1}^n l_{i}) - \mu^2 }\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;common-friends&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; Common friends in a social network&lt;/h1&gt;
&lt;p&gt;Consider a social network described by a graph encoded in a text file.
Each line of the file is a list of identifiers separated by commas.
For instance, the line &lt;span class=&#34;math inline&#34;&gt;\(A,B,C,D\)&lt;/span&gt; means that &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; is friend with &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt;.
An excerpt of the file looks like as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;A,B,C,D
B,A,D
C,A,D
D,A,B,C
...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We suppose that the friendship relation is symmetric: &lt;span class=&#34;math inline&#34;&gt;\((A, B)\)&lt;/span&gt; implies
&lt;span class=&#34;math inline&#34;&gt;\((B, A)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We want to obtain the list of the common friends for each pair of individuals:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(A, B), [D]
(A, C), [D] 
(A, D), [B, C] 
(B, C), [D] 
(B, D), [A] 
(C, D), [A]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As an additional constraint, we want to represent a couple only once and avoid
to represent the symmetric couple.
In other words, if we output &lt;span class=&#34;math inline&#34;&gt;\((A, B)\)&lt;/span&gt;, we don’t want to output &lt;span class=&#34;math inline&#34;&gt;\((B, A)\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-7&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3.1  &lt;/strong&gt;&lt;/span&gt;
Propose a MapReduce implementation to find the common friends in a
social network satisifying the given constraints.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;map: &lt;span class=&#34;math inline&#34;&gt;\((x, F) \rightarrow [((u, v), x)\ \forall (u, v) \in F\ |\ u &amp;lt; v ]\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;reduce: &lt;span class=&#34;math inline&#34;&gt;\([(u, v), LCF] \rightarrow [(u, v), LCF]\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is the first item in a line.&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt; is the list containing the items in a line except the first one (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;’s friends).&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(LCF\)&lt;/span&gt; is the list of all individuals that are friends with both &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We note that the reduce function is the identity.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-an-inverted-index&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;4&lt;/span&gt; Creating an inverted index&lt;/h1&gt;
&lt;p&gt;We have a collection of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; documents in a directory and we want to create
an &lt;strong&gt;inverted index&lt;/strong&gt;, one that associates each word
to the list of the files the word occurs in.
More precisely, for each word, the inverted index will
have a list of the names of the documents that contain the word.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-8&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.1  &lt;/strong&gt;&lt;/span&gt;
Propose a MapReduce implementation to create an inverted index over a
collection of documents.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;The input to the map will be a key-value pair, where
the key is the name of a file &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; and the value is the
content &lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt; of the file.&lt;/p&gt;
&lt;p&gt;map: &lt;span class=&#34;math inline&#34;&gt;\((f, C) \rightarrow [(w, f)\ \forall w \in C]\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;reduce: &lt;span class=&#34;math inline&#34;&gt;\((w, L) \rightarrow (w, L)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(L\)&lt;/span&gt; is the list of the files containing the word &lt;span class=&#34;math inline&#34;&gt;\(w\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We note that the reduce function is the identity.&lt;/p&gt;
&lt;p&gt;Note also that in the map function we can add instructions
to preprocess the text. For example, we can eliminate some words
that are not useful in the index (e.g., the stopwords) or remove
special symbols.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>MapReduce</title>
      <link>/courses/plp/tutorials/map-reduce/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/plp/tutorials/map-reduce/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;div id=&#34;computing-averages&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Computing averages&lt;/h1&gt;
&lt;p&gt;We are given a dataset that
contains the average monthly
temperature measurements
over the course of some years.
More precisely, the dataset is stored in a CSV file,
where each row corresponds to a monthly
measurement and the columns contain the following values:
year, month, average temperature in the month.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1980,1,5
1980,2,2
1980,3,10
1980,4,14
1980,5,17
....
1981,1,2
1981,2,1
1981,3,3
1981,4,10
....&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We intend to get the average monthly temperature for each year.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-1&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.1  &lt;/strong&gt;&lt;/span&gt;
Write a MapReduce algorithm that generates key-value pairs
&lt;span class=&#34;math inline&#34;&gt;\((year, average\_temperature)\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Suppose now that we have a large CSV file
stored in a distributed file system (e.g., HDFS),
containing a series of measurements in the format “Year, Month, Day, Minute, Second, Temperature”.
We can have up to one measurement per second in some years.
Like before, we’d like to compute key-value pairs (year, average_temperature) by using
a MapReduce algorithm.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-2&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.2  &lt;/strong&gt;&lt;/span&gt;
What is the maximum number of measurements in a year?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-3&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.3  &lt;/strong&gt;&lt;/span&gt;
Considering the answer to the previous question, discuss the efficiency
of the first implementation of the algorithm.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-4&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.4  &lt;/strong&gt;&lt;/span&gt;
Based on the answer to the previous question,
propose a better implementation to handle the CSV file.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;computing-average-and-standard-deviation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; Computing average and standard deviation&lt;/h1&gt;
&lt;p&gt;We consider again the large CSV file
with a series of measurements in the format “Year, Month, Day, Minute, Second, Temperature”.
We now intend to generate a series of key-value pairs (year, (avg_temperature, std_deviation)).&lt;/p&gt;
&lt;p&gt;We can express the standard deviation of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; values &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; (&lt;span class=&#34;math inline&#34;&gt;\(1 \leq i \leq n\)&lt;/span&gt;) with two different
equations.&lt;/p&gt;
&lt;p&gt;The first equation is as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\sigma = \sqrt{\frac{\sum_{i=1}^n (x_i - \overline{x})^2}{n}} 
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The second equation is as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\sigma = \sqrt{\overline{x^2} - \overline{x}^2} = \sqrt{\frac{\sum_{i=1}^n (x_i)^2}{n} - \Bigg(\frac{\sum_{i=1}^n x_i}{n}\Bigg)^2} 
\]&lt;/span&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-5&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.1  &lt;/strong&gt;&lt;/span&gt;
Which equation of the standard deviation
is more appropriate in a Map-Reduce algorithm?
Why?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-6&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.2  &lt;/strong&gt;&lt;/span&gt;
Propose a MapReduce implementation to compute the average and the standard
deviation of the temperatures for each year.
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;common-friends&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; Common friends in a social network&lt;/h1&gt;
&lt;p&gt;Consider a social network described by a graph encoded in a text file.
Each line of the file is a list of identifiers separated by commas.
For instance, the line &lt;span class=&#34;math inline&#34;&gt;\(A,B,C,D\)&lt;/span&gt; means that &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; is friend with &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt;.
An excerpt of the file looks like as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;A,B,C,D
B,A,D
C,A,D
D,A,B,C
...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We suppose that the friendship relation is symmetric: &lt;span class=&#34;math inline&#34;&gt;\((A, B)\)&lt;/span&gt; implies
&lt;span class=&#34;math inline&#34;&gt;\((B, A)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We want to obtain the list of the common friends for each pair of individuals:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(A, B), [D]
(A, C), [D] 
(A, D), [B, C] 
(B, C), [D] 
(B, D), [A] 
(C, D), [A]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As an additional constraint, we want to represent a couple only once and avoid
to represent the symmetric couple.
In other words, if we output &lt;span class=&#34;math inline&#34;&gt;\((A, B)\)&lt;/span&gt;, we don’t want to output &lt;span class=&#34;math inline&#34;&gt;\((B, A)\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-7&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3.1  &lt;/strong&gt;&lt;/span&gt;
Propose a MapReduce implementation to find the common friends in a
social network satisifying the given constraints.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-an-inverted-index&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;4&lt;/span&gt; Creating an inverted index&lt;/h1&gt;
&lt;p&gt;We have a collection of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; documents in a directory and we want to create
an &lt;strong&gt;inverted index&lt;/strong&gt;, one that associates each word
to the list of the files the word occurs in.
More precisely, for each word, the inverted index will
have a list of the names of the documents that contain the word.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-8&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.1  &lt;/strong&gt;&lt;/span&gt;
Propose a MapReduce implementation to create an inverted index over a
collection of documents.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>MongoDB</title>
      <link>/courses/databases/tutorials/mongodb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/databases/tutorials/mongodb/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;div id=&#34;setting-up-the-work-environment.&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Setting up the work environment.&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Start the &lt;strong&gt;MongoDB server&lt;/strong&gt;. Refer
to the &lt;a href=&#34;/courses/databases/overview/installation-mongodb&#34; target=&#34;_blank&#34;&gt;documentation&lt;/a&gt;
to find out how to start the server depending on your operating system.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Launch &lt;strong&gt;MongoDB compass&lt;/strong&gt;. You should have installed it
with the MongoDB server.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;From within MongoDB compass, connect to the local MongoDB server.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-the-database&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; Creating the database&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Download the data by &lt;a href=&#34;/courses/plp/tutorials/mongodb-data.zip&#34;&gt;clicking here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In MongoDB Compass, click on the button “Create database”.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Give the database a name (e.g., &lt;em&gt;cinema&lt;/em&gt;) and create a collection
named &lt;em&gt;movies&lt;/em&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Click on the button &lt;em&gt;Add data&lt;/em&gt; and select &lt;em&gt;Import file&lt;/em&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select JSON as a file format and select the file &lt;em&gt;movies.json&lt;/em&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Click on “Import”; 88 documents should be imported into the database.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;querying-the-data-with-find&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; Querying the data with &lt;em&gt;find&lt;/em&gt;&lt;/h1&gt;
&lt;p&gt;At the bottom of the MongoDB window, you should find a link
to open the MongoDB shell (MongoSH Beta).&lt;/p&gt;
&lt;p&gt;After opening the shell, write the following command to
switch to database &lt;em&gt;cinema&lt;/em&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;use cinema&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To verify that you’re actually connected to the database &lt;em&gt;cinema&lt;/em&gt;,
type the following query:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;db.movies.findOne()&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-1&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3.1  &lt;/strong&gt;&lt;/span&gt;
By using the MongoDB shell, execute the following queries.&lt;/p&gt;
&lt;p&gt;Q1. The release year of the movie “Le parrain III”.&lt;/p&gt;
&lt;p&gt;Q2. The title of the movies released between 1980 and 1990.&lt;/p&gt;
&lt;p&gt;Q3. Same query as b. with the titles must be sorted by alphabetical order.&lt;/p&gt;
&lt;p&gt;Q4. The titles of the french movies.&lt;/p&gt;
&lt;p&gt;Q5. The title of the “crime” or “drama” movies.&lt;/p&gt;
&lt;p&gt;Q6. The names and birth dates of the directors of french movies.&lt;/p&gt;
&lt;p&gt;Q7. The title of the movies in which Sofia Coppola played.&lt;/p&gt;
&lt;p&gt;Q8. The title and the genre of the movies of which Hitchcock is director.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;querying-the-data-with-the-aggregation-framework&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;4&lt;/span&gt; Querying the data with the aggregation framework&lt;/h1&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-2&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.1  &lt;/strong&gt;&lt;/span&gt;
By using the MongoDB shell, execute the following queries
by using &lt;strong&gt;aggregation pipelines&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Q1. The number of movies by country. Show by decresing number.&lt;/p&gt;
&lt;p&gt;Q2. The name of the actor in the role “Mary Corleone” in the movie “Le parrain III”.&lt;/p&gt;
&lt;p&gt;Q3. The number of actors by movie. Sort by decreasing number.&lt;/p&gt;
&lt;p&gt;Q4. The average number of actors in a film.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;join-in-mongodb&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;5&lt;/span&gt; Join in MongoDB&lt;/h1&gt;
&lt;p&gt;In the database &lt;em&gt;cinema&lt;/em&gt;, create a new collection called &lt;em&gt;movies_boffice&lt;/em&gt;.
Import the documents in file &lt;em&gt;moviesBoxOffice.json&lt;/em&gt; into this collection.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-3&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 5.1  &lt;/strong&gt;&lt;/span&gt;
By using the operator &lt;em&gt;$lookup&lt;/em&gt; on the collections
&lt;em&gt;movies&lt;/em&gt; and &lt;em&gt;movies_boffice&lt;/em&gt;, find the box office of the
movie “Le parrain III”.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Neo4j</title>
      <link>/courses/plp/tutorials/neo4j-tutorial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/plp/tutorials/neo4j-tutorial/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;div id=&#34;setting-up-the-work-environment.&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Setting up the work environment.&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Download &lt;a href=&#34;https://neo4j.com/download/&#34; target=&#34;_blank&#34;&gt;Neo4j Desktop&lt;/a&gt;
and install it on your computer.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create a new project by clicking on the button “New”
that you’ll find on the top left side of the window.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Click on “Add Database”, then “Create a Local Database”.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Give the database a name (e.g., &lt;em&gt;MovieLens&lt;/em&gt;) and set
a password that you can easily remember; then click on “Create”.
Choose version 4.1.1 for the database.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Click on “Start” and wait for the database to become active.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Click on the button “Open”. The &lt;em&gt;Neo4j Browser&lt;/em&gt; will pop up.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the next section, you’ll have to type a sequence of commands to
import the data.
You’ll write the commands in the text field on top of the
&lt;em&gt;Neo4j Browser&lt;/em&gt; (where you find the prompt &lt;em&gt;neo4j$&lt;/em&gt;).&lt;/p&gt;
&lt;div id=&#34;import-the-data.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.1&lt;/span&gt; Import the data.&lt;/h2&gt;
&lt;p&gt;The dataset consists of
data obtained from &lt;em&gt;MovieLens&lt;/em&gt;,
a recommender system
whose users give movies a rate
between 1 and 5,
based on whether they dislike or love them.
MovieLens uses the rates to recommend
movies that its users might like.
The dataset is modeled as a &lt;strong&gt;directed graph&lt;/strong&gt; and
consists of 100,004 rates on 9,125 movies
across 671 users between January 9th, 1995 and October 16, 2016.
The dataset also contains the names of
the directors and the actors of each movie.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Import the &lt;strong&gt;nodes&lt;/strong&gt; corresponding to the
&lt;strong&gt;movies&lt;/strong&gt; (label &lt;strong&gt;Movie&lt;/strong&gt;) by
using the following command (it took 31 seconds on my computer):&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;
:auto USING PERIODIC COMMIT 1000
LOAD CSV WITH HEADERS FROM &#39;https://gquercini.github.io/courses/plp/tutorials/neo4j/movies.csv&#39; as row
MERGE (m:Movie {movie_id: toInteger(row.movie_id), title_en:row.movie_title_en, title_fr:row.movie_title_fr, year: toInteger(row.movie_year)})
RETURN count(m)
&lt;/pre&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Create an &lt;strong&gt;index&lt;/strong&gt; on the property &lt;em&gt;movie_id&lt;/em&gt; of
the nodes with label &lt;strong&gt;Movie&lt;/strong&gt; with the following command:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;
create index movie_idx for (m:Movie) on (m.movie_id)
&lt;/pre&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Import the &lt;strong&gt;nodes&lt;/strong&gt; corresponding to the
&lt;strong&gt;actors&lt;/strong&gt; (label &lt;strong&gt;Actor&lt;/strong&gt;) by
using the following command (it took 62 seconds on my computer):&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;
:auto USING PERIODIC COMMIT 1000
LOAD CSV WITH HEADERS FROM &#39;https://gquercini.github.io/courses/plp/tutorials/neo4j/actors.csv&#39; as row
MERGE (a:Actor {actor_id: toInteger(row.actor_id), name:row.actor_name})
RETURN count(a)
&lt;/pre&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Create an &lt;strong&gt;index&lt;/strong&gt; on the property &lt;em&gt;actor_id&lt;/em&gt; of
the nodes with label &lt;strong&gt;Actor&lt;/strong&gt; with the following command:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;
create index actor_idx for (a:Actor) on (a.actor_id)
&lt;/pre&gt;
&lt;ol start=&#34;5&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Import the &lt;strong&gt;nodes&lt;/strong&gt; corresponding to the
&lt;strong&gt;directors&lt;/strong&gt; (label &lt;strong&gt;Director&lt;/strong&gt;) by
using the following command (it took 4 seconds on my computer):&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;
:auto USING PERIODIC COMMIT 1000
LOAD CSV WITH HEADERS FROM &#39;https://gquercini.github.io/courses/plp/tutorials/neo4j/directors.csv&#39; as row
MERGE (d:Director {director_id: toInteger(row.director_id), name:row.director_name})
RETURN count(d)
&lt;/pre&gt;
&lt;ol start=&#34;6&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Create an &lt;strong&gt;index&lt;/strong&gt; on the property &lt;em&gt;director_id&lt;/em&gt; of
the nodes with label &lt;strong&gt;Director&lt;/strong&gt; with the following command:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;
create index director_idx for (d:Director) on (d.director_id)
&lt;/pre&gt;
&lt;ol start=&#34;7&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Import the &lt;strong&gt;nodes&lt;/strong&gt; corresponding to the
&lt;strong&gt;genres&lt;/strong&gt; (label &lt;strong&gt;Genre&lt;/strong&gt;) by
using the following command (it took 197 ms on my computer):&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;
:auto USING PERIODIC COMMIT 1000
LOAD CSV WITH HEADERS FROM &#39;https://gquercini.github.io/courses/plp/tutorials/neo4j/genres.csv&#39; as row
MERGE (g:Genre {genre_id: toInteger(row.genre_id), name:row.genre_name})
RETURN count(g)
&lt;/pre&gt;
&lt;ol start=&#34;8&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Create an &lt;strong&gt;index&lt;/strong&gt; on the property &lt;em&gt;genre_id&lt;/em&gt; of
the nodes with label &lt;strong&gt;Genre&lt;/strong&gt; with the following command:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;
create index genre_idx for (g:Genre) on (g.genre_id)
&lt;/pre&gt;
&lt;ol start=&#34;9&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Import the &lt;strong&gt;nodes&lt;/strong&gt; corresponding to the
&lt;strong&gt;users&lt;/strong&gt; (label &lt;strong&gt;User&lt;/strong&gt;) by
using the following command (it took 347 seconds on my computer):&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;
:auto USING PERIODIC COMMIT 1000
LOAD CSV WITH HEADERS FROM &#39;https://gquercini.github.io/courses/plp/tutorials/neo4j/users.csv&#39; as row
MERGE (u:User {user_id: toInteger(row.user_id), name:row.user_nickname})
RETURN count(u)
&lt;/pre&gt;
&lt;ol start=&#34;10&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Create an &lt;strong&gt;index&lt;/strong&gt; on the property &lt;em&gt;user_id&lt;/em&gt; of
the nodes with label &lt;strong&gt;User&lt;/strong&gt; with the following command:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;
create index user_idx for (u:User) on (u.user_id)
&lt;/pre&gt;
&lt;ol start=&#34;11&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Import the links of type &lt;strong&gt;ACTED_IN&lt;/strong&gt;
between actors and movies with the following
command (it took 2.5 seconds on my computer):&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;
:auto USING PERIODIC COMMIT 1000
LOAD CSV WITH HEADERS FROM &#39;https://gquercini.github.io/courses/plp/tutorials/neo4j/movies_actors.csv&#39; as row
MATCH (m:Movie {movie_id: toInteger(row.movie_id)})
MATCH (a:Actor {actor_id: toInteger(row.actor_id)})
MERGE (a)-[r:ACTED_IN]-&gt;(m)
RETURN count(r)
&lt;/pre&gt;
&lt;ol start=&#34;12&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Import the links of type &lt;strong&gt;DIRECTED&lt;/strong&gt;
between directors and movies with the following
command (it took 688 ms on my computer):&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;
:auto USING PERIODIC COMMIT 1000
LOAD CSV WITH HEADERS FROM &#39;https://gquercini.github.io/courses/plp/tutorials/neo4j/movies_directors.csv&#39; as row
MATCH (m:Movie {movie_id: toInteger(row.movie_id)})
MATCH (d:Director {director_id: toInteger(row.director_id)})
MERGE (d)-[r:DIRECTED]-&gt;(m)
RETURN count(r)
&lt;/pre&gt;
&lt;ol start=&#34;13&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Import the links of type &lt;strong&gt;HAS_GENRE&lt;/strong&gt;
between movies and genres with the following
command (it took 1 second on my computer):&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;
:auto USING PERIODIC COMMIT 1000
LOAD CSV WITH HEADERS FROM &#39;https://gquercini.github.io/courses/plp/tutorials/neo4j/movies_genres.csv&#39; as row
MATCH (m:Movie {movie_id: toInteger(row.movie_id)})
MATCH (g:Genre {genre_id: toInteger(row.genre_id)})
MERGE (m)-[r:HAS_GENRE]-&gt;(g)
RETURN count(r)
&lt;/pre&gt;
&lt;ol start=&#34;14&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Import the links of type &lt;strong&gt;RATED&lt;/strong&gt;
between users and movies with the following
command (it took 5.9 seconds on my computer):&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;
:auto USING PERIODIC COMMIT 1000
LOAD CSV WITH HEADERS FROM &#39;https://gquercini.github.io/courses/plp/tutorials/neo4j/user_rates.csv&#39; as row
MATCH (m:Movie {movie_id: toInteger(row.movie_id)})
MATCH (u:User {user_id: toInteger(row.user_id)})
MERGE (u)-[r:RATED {rate:toFloat(row.rate)}]-&gt;(m)
RETURN count(r)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-queries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; Exploratory queries&lt;/h1&gt;
&lt;p&gt;If you looked at the commands used to import the data,
you might already have an idea as to the structure of
the graph.
You can get a glimpse on the node labels,
the relationship types and the property keys by clicking on the
button circled in the following figure:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/courses/plp/tutorials/neo4j/neo4j-db-button.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;strong&gt;Exercise&lt;/strong&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-1&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.1  &lt;/strong&gt;&lt;/span&gt;
Write and execute the following query:&lt;/p&gt;
&lt;pre&gt;
MATCH (m:Movie {title_en:&#34;Toy Story&#34;}) 
RETURN m;
&lt;/pre&gt;
&lt;p&gt;What do you obtain? What are the properties associated
to a node with label &lt;em&gt;Movie&lt;/em&gt;?
Click once on the node to display its properties.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;strong&gt;Exercise&lt;/strong&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-2&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.2  &lt;/strong&gt;&lt;/span&gt;
Double-click on the node displayed as the result of the previous query.
Analyze the neighbouring nodes (their labels and properties)
and the incident links (direction, type and properties).
You can move around the node by dragging it in the window.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;queries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; Queries&lt;/h1&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;strong&gt;Exercise&lt;/strong&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-3&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3.1  &lt;/strong&gt;&lt;/span&gt;
Write and execute the following queries:&lt;/p&gt;
&lt;p&gt;Q1. The genres of the movies in the database.&lt;/p&gt;
&lt;p&gt;Q2. The number of movies in the database.&lt;/p&gt;
&lt;p&gt;Q3. The title of the movies released in 2015.&lt;/p&gt;
&lt;p&gt;Q4. The number of directors by movie. Sort in decreasing order.&lt;/p&gt;
&lt;p&gt;Q5. The names of the directors and the title of the movies that they
directed and in which they also played.&lt;/p&gt;
&lt;p&gt;Q6. The genres of the movies in which Tom Hanks played.&lt;/p&gt;
Q7. The title and the rate of all the movies that
the user with identifier 3 rated.
Sort by rate in decreasing order.
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;query-chaining&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.1&lt;/span&gt; Query chaining&lt;/h2&gt;
&lt;p&gt;Cypher allows the specification of
complex queries composed of
several queries that are concatenated
with the clause &lt;strong&gt;WITH&lt;/strong&gt;.
We are now going to see an example to
obtain the titles of the movies
that have been rated by at least 100 users.&lt;/p&gt;
&lt;p&gt;At a first glance, the following query looks like a good solution:&lt;/p&gt;
&lt;pre&gt;
MATCH (n:Movie)&lt;-[:RATED]-(u:User) WHERE count(u) &gt;= 100
RETURN n.title_en
LIMIT 5;
&lt;/pre&gt;
&lt;p&gt;However, executing this query returns the following error:&lt;/p&gt;
&lt;pre&gt;
Invalid use of aggregating function count(...) in this context (line 1, column 42 (offset: 41))
&#34;MATCH (n:Movie)&lt;-[:RATED]-(u:User) WHERE count(u) &gt;= 100&#34;
&lt;/pre&gt;
&lt;p&gt;Similarly to SQL, we cannot use aggregating functions in the clause WHERE.&lt;/p&gt;
&lt;p&gt;A correct formulation of the query requires the use of the clause WITH
to concatenate two queries: the first will count the number of rates
for each movie:&lt;/p&gt;
&lt;pre&gt;
MATCH (n:Movie)&lt;-[:RATED]-(u:User) 
RETURN n, count(u) as nb_rates
&lt;/pre&gt;
&lt;p&gt;The second will take in the output of the first and will
filter all the movies where nb_rates &amp;lt; 100.
In order to chain the two queries, we’ll replace the
RETURN clause in the first query with a WITH clause, as follows:&lt;/p&gt;
&lt;pre&gt;
MATCH (n:Movie)&lt;-[:RATED]-(u:User) 
WITH n, count(u) as nb_rates
WHERE nb_rates &gt;= 100
RETURN n.title_en
&lt;/pre&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;strong&gt;Exercise&lt;/strong&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-4&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3.2  &lt;/strong&gt;&lt;/span&gt;
Write and execute a query to obtain the five movies
that obtained the best average rate among the movies
that have been rated by at least 100 users.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;movie-recommendation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;4&lt;/span&gt; Movie recommendation&lt;/h1&gt;
&lt;p&gt;We are now going to see how Neo4j
can be effectively used in a real application
by implementing queries that form the basis of a
simple &lt;strong&gt;movie recommendation system&lt;/strong&gt;.
This system is based on the notion of &lt;strong&gt;collaborative filtering&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;This consists in recommending a user &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt; some films
that s/he hasn’t rated yet and other
users with similar preferences have loved.
In our context, we say that a user loves
a movie if s/he rated the movie at least 3.&lt;/p&gt;
&lt;p&gt;This concept is explained in the following figure.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/courses/plp/tutorials/neo4j/collaborative-filtering.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The user &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt; loves 6 movies,
3 of which are also loved by the user &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt; (the black nodes);
it is reasonable to think that &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt;
may also love the two movies that &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt; loved and &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt; hasn’t rated yet.&lt;/p&gt;
&lt;p&gt;The principle of collaborative filtering is
based on the computation of a &lt;strong&gt;similarity score&lt;/strong&gt;
between two users.
Several similarity scores are possible in this context;
here, we are going to use the &lt;strong&gt;Jaccard coefficient&lt;/strong&gt;.
Let &lt;span class=&#34;math inline&#34;&gt;\(L(u)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(L(v)\)&lt;/span&gt; be the
sets of movies that &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt; love
respectively;
the similarity score &lt;span class=&#34;math inline&#34;&gt;\(J(u,v)\)&lt;/span&gt; between &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt; is given by:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
J(u, v) = \frac{|L(u) \cap L(v)|}{|L(u) \cup L(v)|}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In order to recommend movies to
a target user &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt;,
the recommender system computes the
similarity score between &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt; and all
the other users of the system and
proposes to &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt; the movies
that s/he hasn’t rated yet and that the &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; most similar users loved.&lt;/p&gt;
&lt;p&gt;We are now going to incrementally write a query to recommend some movies to the target user 3.
The first step consists in determining the value &lt;span class=&#34;math inline&#34;&gt;\(|L(v)|\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;strong&gt;Exercise&lt;/strong&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-5&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.1  &lt;/strong&gt;&lt;/span&gt;
Write and execute the query to obtain
the number of movies that the user 3 loved.
This query must return the target user
and the number of movies that s/he loves.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Next, we are going to determine the value &lt;span class=&#34;math inline&#34;&gt;\(|L(u)|\)&lt;/span&gt;,
for all users &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt; except &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;strong&gt;Exercise&lt;/strong&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-6&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.2  &lt;/strong&gt;&lt;/span&gt;
Write and execute the query
to obtain the number of movies that each user &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt; loves,
except the target user 3.
This query must return each user &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt; and the number
of movies that s/he loves.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We put the two queries together with the clause WITH.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;strong&gt;Exercise&lt;/strong&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-7&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.3  &lt;/strong&gt;&lt;/span&gt;
Compose the two previous queries with the clause WITH.
This query must return
the target user 3,
the number of movies that s/he loves,
the other users &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt; and the number of movies
that they love.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Now, we need to
determine the value &lt;span class=&#34;math inline&#34;&gt;\(L(u)\cup L(v)\)&lt;/span&gt;,
for each user &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt;, and compute the similarity score with the
Jaccard coefficient.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;strong&gt;Exercise&lt;/strong&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-8&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.4  &lt;/strong&gt;&lt;/span&gt;
Append (by using WITH)
to the query written in the previous exercise
a query that obtains
the number of movies
that any user &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt; loved
and that the target user 3 loved too,
and computes the similarity score
between the target user 3 and &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt;.
This query must return the five most similar
users to the target user and the similarity scores.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;Hint&lt;/summary&gt;
Multiply the numerator of the equation
by 1.0, otherwise Cypher will compute an integer division.
&lt;/details&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The last step consists in recommending some movies to the target user.
From the previous query,
take the identifier of the user &lt;span class=&#34;math inline&#34;&gt;\(w\)&lt;/span&gt; with
the highest similarity to the target user.
You are going to use this identifier directly in the new query.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;strong&gt;Exercise&lt;/strong&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-9&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.5  &lt;/strong&gt;&lt;/span&gt;
Write and execute
the query to obtain the list of
the movies that the user &lt;span class=&#34;math inline&#34;&gt;\(w\)&lt;/span&gt; loved
and that the target user hasn’t rated yet. Sort this list by decreasing rate.&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Hint&lt;/summary&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First, write a query
to obtain the list of the movies
that the target user rated.
In the MATCH clause,
use the variable &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; to indicate a movie that the target user rated.
Conclude the query with:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;
RETURN collect(m.title_en) AS movies
&lt;/pre&gt;
&lt;p&gt;The function &lt;em&gt;collect&lt;/em&gt; creates a list called &lt;em&gt;movies&lt;/em&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Replace RETURN with WITH in the previous query and add a
second query to select the titles of the movies
&lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; that the user &lt;span class=&#34;math inline&#34;&gt;\(w\)&lt;/span&gt; loved and the target user
did not rate.
In order to exclude the films that the target user
did not rate, use the following predicate:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;
none(x in movies where x=m.title_en)
&lt;/pre&gt;
&lt;p&gt;in the WHERE clause.&lt;/p&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Normalization</title>
      <link>/courses/databases/tutorials/normalization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/databases/tutorials/normalization/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;p&gt;In this tutorial you’ll learn:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How to obtain a &lt;strong&gt;non-redundant set of functional dependencies&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;How to determine the &lt;strong&gt;candidate keys&lt;/strong&gt; of a table given its functional dependencies.&lt;/li&gt;
&lt;li&gt;How to determine the &lt;strong&gt;normal form&lt;/strong&gt; of a table.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Having attended &lt;a href=&#34;/courses/cloud-computing/lectures/lectures&#34;&gt;Lecture 2&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;non-redundant-functional-dependencies&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Non-redundant functional dependencies&lt;/h1&gt;
&lt;p&gt;Consider the following set &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{F}\)&lt;/span&gt; of functional dependencies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(A, B \rightarrow C\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(D \rightarrow B, C\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(A \rightarrow B\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-1&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.1  &lt;/strong&gt;&lt;/span&gt;
Derive a minimal set &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{G}\)&lt;/span&gt; of functional dependencies that is equivalent to &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{F}\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;First, we rewrite the FDs such that each has a singleton right side.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(A, B \rightarrow C\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(D \rightarrow B\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(D \rightarrow C\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(A \rightarrow B\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The first has two attributes in the determinant, therefore we need to check whether we
can eliminate one of the two columns.&lt;/p&gt;
&lt;p&gt;We have &lt;span class=&#34;math inline&#34;&gt;\(A \rightarrow B\)&lt;/span&gt;. By &lt;strong&gt;augmentation&lt;/strong&gt; we obtain:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[A \rightarrow A, B\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We have &lt;span class=&#34;math inline&#34;&gt;\(A, B \rightarrow C\)&lt;/span&gt;. By &lt;strong&gt;transitivity&lt;/strong&gt; we obtain:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[A \rightarrow C\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Therefore, the column &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; is not useful and we can drop it.&lt;/p&gt;
&lt;p&gt;The set &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{G}\)&lt;/span&gt; consists of the following FDs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(A \rightarrow C\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(D \rightarrow B\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(D \rightarrow C\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(A \rightarrow B\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;candidate-keys-and-normal-forms-1&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; Candidate keys and normal forms (1)&lt;/h1&gt;
&lt;p&gt;We consider the following table:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Patient (ssn, first_name, last_name, phone_number, insurance_number, 
         insurance_expiration_date)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where the following set &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{F}\)&lt;/span&gt; of functional dependencies hold:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ 
\begin{align}
ssn \rightarrow first\_name, &amp;amp; last\_name, phone\_number, insurance\_number, \\
   &amp;amp; insurance\_expiration\_date 
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
insurance\_number \rightarrow insurance\_expiration\_date
\]&lt;/span&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-2&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.1  &lt;/strong&gt;&lt;/span&gt;Derive a minimal set &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{G}\)&lt;/span&gt; of functional dependencies that is equivalent to &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{F}\)&lt;/span&gt;.
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;First, we need to rewrite the FDs such that each has a singleton right side.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(ssn \rightarrow first\_name\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(ssn \rightarrow last\_name\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(ssn \rightarrow phone\_number\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(ssn \rightarrow insurance\_number\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(ssn \rightarrow insurance\_expiration\_date\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(insurance\_number \rightarrow insurance\_expiration\_date\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The determinant of each FD is composed of only one column, therefore
it is already irreducible.
It is easy to see that all FDs with &lt;TT&gt;ssn&lt;/TT&gt; as a determinant must be
kept (otherwise we lose some information).&lt;/p&gt;
&lt;p&gt;By transitivity from 4. and 6. we obtain:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ssn \rightarrow insurance\_expiration\_date\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Therefore, &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{G}\)&lt;/span&gt; is obtained from &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{F}\)&lt;/span&gt; by removing 5.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-3&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.2  &lt;/strong&gt;&lt;/span&gt;Given &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{G}\)&lt;/span&gt;, identify the candidate keys in the table &lt;TT&gt;Patient&lt;/TT&gt;.
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;From the functional dependencies in &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{F}\)&lt;/span&gt;, it’s easy to see that
that the only column that implies all the others
is &lt;TT&gt;ssn&lt;/TT&gt;. Therefore, {&lt;TT&gt;ssn&lt;/TT&gt;} is the only candidate key in
this table.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-4&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.3  &lt;/strong&gt;&lt;/span&gt;Specify the normal form of the table &lt;TT&gt;Patient&lt;/TT&gt;. Justify your answer.
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;It is immediate to verify that the table is 1NF.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The table is 2NF because there is only one candidate key, which is composed of
only one column.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The table is not in 3NF. Indeed, there is a functional dependency
between two non-prime columns &lt;span class=&#34;math inline&#34;&gt;\(insurance\_number \rightarrow insurance\_expiration\_date\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;span id=&#34;exr:unnamed-chunk-5&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.4  &lt;/strong&gt;&lt;/span&gt;How would you obtain two or more tables in BCNF from the
table &lt;TT&gt;Patient&lt;/TT&gt;?
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;We need to split the data relative to the patient from the
data relative to the insurance.
Therefore, we propose the following two tables:&lt;/p&gt;
&lt;pre&gt;
&lt;TT&gt;Patient&lt;/TT&gt; (&lt;u&gt;ssn&lt;/u&gt;, first_name, last_name, phone_number, insurance_number)
&lt;TT&gt;Insurance&lt;/TT&gt; (&lt;u&gt;insurance_number&lt;/u&gt;, insurance_expiration_date)
&lt;/pre&gt;
&lt;p&gt;Note that the column &lt;em&gt;insurance_number&lt;/em&gt; in table &lt;TT&gt;Patient&lt;/TT&gt; is foreign key to
the column &lt;em&gt;insurance_number&lt;/em&gt; in table &lt;TT&gt;Insurance&lt;/TT&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;candidate-keys-and-normal-forms-2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; Candidate keys and normal forms (2)&lt;/h1&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; be a relational table with five columns &lt;span class=&#34;math inline&#34;&gt;\((A, B, C, D, E)\)&lt;/span&gt;.
The following set &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{F}\)&lt;/span&gt; of functional dependencies hold:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(A, B \rightarrow C\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(C \rightarrow A\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(C \rightarrow B\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(C \rightarrow D\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(D \rightarrow E\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-6&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3.1  &lt;/strong&gt;&lt;/span&gt;
Specify the candidate keys of the table &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;First, let’s try sets composed of only one column: &lt;span class=&#34;math inline&#34;&gt;\(\{A\}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\{B\}\)&lt;/span&gt;,
&lt;span class=&#34;math inline&#34;&gt;\(\{C\}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\{D\}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\{E\}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We have the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\{A\}^+_{\mathcal{F}} = \{A\}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\{B\}^+_{\mathcal{F}} = \{B\}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\{C\}^+_{\mathcal{F}} = \{A, B, C, D, E\}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\{D\}^+_{\mathcal{F}} = \{D, E\}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\{E\}^+_{\mathcal{F}} = \{E\}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Therefore, &lt;span class=&#34;math inline&#34;&gt;\(\{C\}\)&lt;/span&gt; is a candidate key because it implies all the other columns.&lt;/p&gt;
&lt;p&gt;From the functional dependency 1., we obtain that &lt;span class=&#34;math inline&#34;&gt;\(\{A, B\}\)&lt;/span&gt; imply &lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt;; therefore,
by transitivity they imply all the other columns.&lt;/p&gt;
&lt;p&gt;In conclusion, we have two candidate keys: &lt;span class=&#34;math inline&#34;&gt;\(\{C\}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\{A, B\}\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-7&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3.2  &lt;/strong&gt;&lt;/span&gt;
We assume that &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; is in 1NF.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Is table &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; in 2NF? Justify your answer.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Is table &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; in 3NF? Justify your answer.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; is in 2NF. In fact, all non-prime columns depend
entirely on both candidate keys.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; is not in 3NF. In fact, the functional dependency &lt;span class=&#34;math inline&#34;&gt;\(D \rightarrow E\)&lt;/span&gt; is
between two non-prime columns.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;candidate-keys-and-normal-forms-3&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;4&lt;/span&gt; Candidate keys and normal forms (3)&lt;/h1&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; be the a relational table with five columns
&lt;span class=&#34;math inline&#34;&gt;\((A, B, C, D, E)\)&lt;/span&gt;.
The following set &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{F}\)&lt;/span&gt; of functional dependencies hold:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(A \rightarrow C\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(A, B \rightarrow D\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(A, B \rightarrow E\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-8&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.1  &lt;/strong&gt;&lt;/span&gt;
Specify the candidate keys of the table &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;The following hold:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\{A\}^+_{\mathcal{F}} = \{A, C\}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\{B\}^+_{\mathcal{F}} = \{B\}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\{C\}^+_{\mathcal{F}} = \{C\}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\{D\}^+_{\mathcal{F}} = \{D\}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\{E\}^+_{\mathcal{F}} = \{E\}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is clear that the only possible candidate key could be {A, B}; let’s verify it
by computing the closure of {A, B} under &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{F}\)&lt;/span&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\{A, B\}^+_{\mathcal{F}} = \{A, B, C, D, E\}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Indeed, {A, B} is the candidate key.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-9&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4.2  &lt;/strong&gt;&lt;/span&gt;
We assume that &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; is in 1NF.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Is table &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; in 2NF? Justify your answer.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Is table &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; in 3NF? Justify your answer.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; is not in 2NF. In fact, the non-prime column &lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt; is functionally dependent on
only one part of the candidate key.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; is not in 3NF, because it doesn’t fulfill the first condition, that is
being in 2NF.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;candidate-keys-and-normal-forms-4&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;5&lt;/span&gt; Candidate keys and normal forms (4)&lt;/h1&gt;
&lt;p&gt;Consider the following table &lt;TT&gt;Student&lt;/TT&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Student (stud_id, stud_ssn, course)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The following set &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{F}\)&lt;/span&gt; of functional dependencies hold:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(stud\_id \rightarrow stud\_ssn\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(stud\_ssn \rightarrow stud\_id\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-10&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 5.1  &lt;/strong&gt;&lt;/span&gt;
Specify the candidate keys of the table &lt;TT&gt;Student&lt;/TT&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;If we consider each column independently we have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\{stud\_id\}^+_{\mathcal{F}} = \{stud\_id, stud\_ssn\}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\{stud\_ssn\}^+_{\mathcal{F}} = \{stud\_id, stud\_ssn\}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;No single column implies all the other columns. Therefore,
the candidate key must be composed of at least 2 columns.&lt;/p&gt;
&lt;p&gt;It is also easy to verify that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\{stud\_id, stud\_ssn\}^+_{\mathcal{F}} = \{stud\_id, stud\_ssn\}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We are left with two possibilities:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\{stud\_id, course\}^+_{\mathcal{F}} = \{stud\_id, stud\_ssn, course\}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\{stud\_ssn, course\}^+_{\mathcal{F}} = \{stud\_id, stud\_ssn, course\}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In conclusion, there are two candidate keys: &lt;span class=&#34;math inline&#34;&gt;\(\{stud\_id, course\}\)&lt;/span&gt; and
&lt;span class=&#34;math inline&#34;&gt;\(\{stud\_ssn, course\}\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-11&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 5.2  &lt;/strong&gt;&lt;/span&gt;
We assume that &lt;TT&gt;Student&lt;/TT&gt; is in 1NF.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Is table &lt;TT&gt;Student&lt;/TT&gt; in 2NF? Justify your answer.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Is table &lt;TT&gt;Student&lt;/TT&gt; in 3NF? Justify your answer.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Is table &lt;TT&gt;Student&lt;/TT&gt; in BCNF? Justify your answer.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;TT&gt;Student&lt;/TT&gt; is in 2NF. There are no non-prime columns.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;TT&gt;Student&lt;/TT&gt; is in 3NF. There are no non-prime columns.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;TT&gt;Student&lt;/TT&gt; is not in BCNF. In both functional dependencies the determinant
is not a superkey.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to Spark programming</title>
      <link>/courses/plp/tutorials/spark-programming-dce/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/plp/tutorials/spark-programming-dce/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;/courses/plp/overview/cluster-connection&#34; target=&#34;_blank&#34;&gt;Refer to this documentation&lt;/a&gt; to learn how to connect and
interact with the cluster.&lt;/p&gt;
&lt;div id=&#34;computing-averages&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Computing averages&lt;/h1&gt;
&lt;p&gt;We consider a collection of CSV files containing temperature measurements in the following format:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;year,month,day,hours,minutes,seconds,temperature&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;you can find the files under the directory &lt;code&gt;hdfs://sar01:9000/data/temperatures/&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Here are the details for each file:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;File &lt;code&gt;temperatures_86400.csv&lt;/code&gt; contains one measurement per day in the years 1980 - 2018.&lt;/li&gt;
&lt;li&gt;File &lt;code&gt;temperatures_2880.csv&lt;/code&gt; contains one measurement every 2880 seconds in the years 1980 - 2018.&lt;/li&gt;
&lt;li&gt;File &lt;code&gt;temperatures_86.csv&lt;/code&gt; contains one measurement every 86 seconds for the year 1980 alone.&lt;/li&gt;
&lt;li&gt;File &lt;code&gt;temperatures_10.csv&lt;/code&gt; contains one measurement every 10 seconds for the years 1980 - 2018.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We intend to implement a Spark algorithm to generate pairs &lt;span class=&#34;math inline&#34;&gt;\((y, t_{avg})\)&lt;/span&gt;, where
&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; is the year and &lt;span class=&#34;math inline&#34;&gt;\(t_{avg}\)&lt;/span&gt; is the average temperature in the year.&lt;/p&gt;
&lt;div id=&#34;first-implementation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;First implementation&lt;/h2&gt;
&lt;p&gt;Copy the file &lt;code&gt;~vialle/DCE-Spark/template_temperatures.py&lt;/code&gt;
to your home directory by typing
the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;cp ~vialle/DCE-Spark/template_temperatures.py ./avg_temperatures_first.py&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Open the file &lt;code&gt;avg_temperatures_first.py&lt;/code&gt;
and write the following function:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def avg_temperature(theTextFile): 
    temperatures = theTextFile \ 
                        .map(lambda line: line.split(&amp;quot;,&amp;quot;)) \ 
                        .map(lambda term: (term[0],   [float(term[6])])) \ 
                        .reduceByKey(lambda x, y: x+y) \ 
                        .mapValues(lambda lv: sum(lv)/len(lv)) 
    return temperatures &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the same file, locate the two variables &lt;code&gt;input_path&lt;/code&gt; and &lt;code&gt;output-path&lt;/code&gt;.
and write the following code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;input_path = &amp;quot;hdfs://sar01:9000/data/temperatures/&amp;quot;
output_path = &amp;quot;hdfs://sar01:9000/cpupsmia1/your_username/&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Always remember to replace &lt;code&gt;your_username&lt;/code&gt; with your username!
&lt;strong&gt;Don’t forget the / at the end of the file paths!&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-1&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1  &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Run the script &lt;code&gt;avg_temperatures_first.py&lt;/code&gt; by using &lt;code&gt;temperatures_86400.csv&lt;/code&gt; as an input.
To this extent, use the following command:&lt;/p&gt;
&lt;div align=&#34;left&#34;&gt;
&lt;code&gt;spark-submit --master spark://sar01:7077 avg_temperatures_first.py temperatures_86400.csv&lt;/code&gt;
&lt;/div&gt;
&lt;p&gt;You should find the output of the program under the folder &lt;code&gt;hdfs://sar01:9000/cpupsmia1/your_username/temperatures_86400.out&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;What’s the execution time?
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;In the output of Spark on the command line you should see a line that mentions something along the following line:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;INFO DAGScheduler: Job 0 finished: runJob at SparkHadoopWriter.scala:78, took 3.478220 s&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Run the same script by using &lt;code&gt;temperatures_2880.csv&lt;/code&gt; as an input.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is the execution time? Does it seem reasonable compared with the execution time that you observed before?
Justify your answer.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Execute the same script by using &lt;code&gt;temperatures_86.csv&lt;/code&gt; as an input.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;What is the execution time? How would you justify it, knowing that
the files &lt;code&gt;temperatures_2880.csv&lt;/code&gt; and &lt;code&gt;temperatures_86.csv&lt;/code&gt; have a similar size (11 MB the former, 9 MB the latter)?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;second-implementation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Second implementation&lt;/h2&gt;
&lt;p&gt;Copy the file &lt;code&gt;~vialle/DCE-Spark/template_temperatures.py&lt;/code&gt; to your home directory by typing
the following command:&lt;/p&gt;
&lt;div align=&#34;left&#34;&gt;
&lt;p&gt;&lt;code&gt;cp ~vialle/DCE-Spark/template_temperatures.py ./avg_temperatures_second.py&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-2&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2  &lt;/strong&gt;&lt;/span&gt;
Based on the observations made in the
previous exercise, write an improved implementation of the
function &lt;code&gt;avg_temperature&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-3&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3  &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Run the script &lt;code&gt;avg_temperatures_second.py&lt;/code&gt; by using &lt;code&gt;temperatures_86.csv&lt;/code&gt; as an input.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What’s the execution time? Compare it with the execution time obtained in the previous exercise and
comment the difference.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Run the same script by using &lt;code&gt;temperatures_10.csv&lt;/code&gt; (3 GB!) as an input.
Do you think that the program takes too long? Why?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;average-and-standard-deviation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Average and standard deviation&lt;/h1&gt;
&lt;p&gt;We use the same files as in the first question.
Our objective is to write a Spark program that produces
triples &lt;span class=&#34;math inline&#34;&gt;\((y, t_{\mu}, t_{\sigma})\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(t_{\mu}\)&lt;/span&gt; and
&lt;span class=&#34;math inline&#34;&gt;\(t_{\sigma}\)&lt;/span&gt; are the year, the average temperature in the year and the
standard deviation respectively.&lt;/p&gt;
&lt;p&gt;We can express the standard deviation of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; values &lt;span class=&#34;math inline&#34;&gt;\(x_1 \ldots x_n\)&lt;/span&gt; with the following formula:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\sigma = \sqrt{\overline{x^2} - \overline{x}^2} = \sqrt{\frac{\sum_{i=1}^n (x_i)^2}{n} - \Bigg(\frac{\sum_{i=1}^n x_i}{n}\Bigg)^2} 
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Copy the file &lt;code&gt;~vialle/DCE-Spark/template_temperatures.py&lt;/code&gt; to your home directory by typing
the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;cp ~vialle/DCE-Spark/template_temperatures.py  ./avg_stddev_temp.py&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-4&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 4  &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Complete the definition of the function &lt;code&gt;avg_temperature&lt;/code&gt; in file &lt;code&gt;avg_stddev_temp.py&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Run the script by using &lt;code&gt;temperatures_86400.csv&lt;/code&gt; and &lt;code&gt;temperatures_2880.csv&lt;/code&gt;
as input files (small files).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Run the script by using &lt;code&gt;temperatures_86.csv&lt;/code&gt; and &lt;code&gt;temperatures_10.csv&lt;/code&gt; as input files (large files).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>SQL queries</title>
      <link>/courses/databases/tutorials/sql/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/databases/tutorials/sql/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;p&gt;In this tutorial you’ll learn:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How to write &lt;strong&gt;SQL queries&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Having attended &lt;a href=&#34;/courses/cloud-computing/lectures/lectures&#34;&gt;Lecture 3&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;database-of-a-social-network-platform&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Database of a social network platform&lt;/h1&gt;
&lt;p&gt;We consider the following collection of relational tables:&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;UserAccount&lt;/TT&gt; (&lt;u&gt;nickname&lt;/u&gt;, first_name, last_name, city, country)&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Post&lt;/TT&gt; (&lt;u&gt;post_id&lt;/u&gt;, content, date, time, lat, long, nickname)&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;EmailAddress&lt;/TT&gt; (&lt;u&gt;email_address&lt;/u&gt;, nickname)&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Relationship&lt;/TT&gt; (&lt;u&gt;nickname_src&lt;/u&gt;, &lt;u&gt;nickname_dst&lt;/u&gt;, type, date)&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Tag&lt;/TT&gt; (&lt;u&gt;post_id&lt;/u&gt;, &lt;u&gt;nickname&lt;/u&gt;)&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-1&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 1.1  &lt;/strong&gt;&lt;/span&gt;
Write the following queries in SQL:&lt;/p&gt;
&lt;p&gt;Q1. Count the number of posts by nickname. Sort by number of posts in descending order.&lt;/p&gt;
&lt;p&gt;Q2. Get the identifier and the content of all the posts of the user with nickname &lt;em&gt;nick_BLANCO&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Q3. Get the number of user accounts by country. Order by number of countries in descending order.&lt;/p&gt;
&lt;p&gt;Q4. Get the identifier of the posts where the user with nickname &lt;em&gt;nick_ANIS&lt;/em&gt; is tagged.&lt;/p&gt;
&lt;p&gt;Q5. Get the content of all the posts where the user with nickname &lt;em&gt;nick_ANIS&lt;/em&gt; is tagged.&lt;/p&gt;
&lt;p&gt;Q6. Get the email addresses of the user with nickname &lt;em&gt;nick_BLANCO&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Q7. Get the nicknames of the friends of the user with nickname &lt;em&gt;nick_BLANCO&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Q8. Get the the first and last names of the friends of the user with nickname &lt;em&gt;nick_BLANCO&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Q9. For each user, get the number of followers by country. Rank the countries by the number of followers in descending order.&lt;/p&gt;
&lt;p&gt;Q10. Get the first and family name of the users tagged by the user with nickname &lt;em&gt;nick_CAMERON&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Q11. Get the nickname, first and last name of the common friends of the users with nickname &lt;em&gt;nick_CAMERON&lt;/em&gt; and
&lt;em&gt;nick_ANIS&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Q12. Rank the users by the number of their followers.
The user with the most followers must appear at the top of the list.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
Q1.
&lt;pre&gt;
SELECT nickname, count(*) as nbPosts
FROM Post
GROUP BY nickname 
ORDER BY nbPosts DESC;
&lt;/pre&gt;
Q2.
&lt;pre&gt;
SELECT post_id,content
FROM Post 
WHERE nickname = &#39;nick_BLANCO&#39;;
&lt;/pre&gt;
Q3.
&lt;pre&gt;
SELECT country, COUNT(*) c
FROM UserAccount
GROUP BY country
ORDER BY c DESC;
&lt;/pre&gt;
Q4.
&lt;pre&gt;
SELECT post_id
FROM Tag t
WHERE t.nickname=&#39;nick_ANIS&#39;;
&lt;/pre&gt;
Q5.
&lt;pre&gt;
SELECT content
FROM Tag t JOIN Post p ON t.post_id=p.post_id 
WHERE t.nickname=&#39;nick_ANIS&#39;;
&lt;/pre&gt;
Q6.
&lt;pre&gt;
SELECT email_address
FROM EmailAddress
WHERE u.nickname = &#39;nick_BLANCO&#39;;
&lt;/pre&gt;
Q7.
&lt;pre&gt;
SELECT nickname_dst  
FROM Relationship
WHERE nickname_src = &#39;nick_BLANCO&#39; and type = &#39;friendship&#39;;
&lt;/pre&gt;
Q8.
&lt;pre&gt;
SELECT u1.first_name, u1.last_name  
FROM Relationship r JOIN UserAccount u ON u.nickname = r.nickname_dst
WHERE r.nickname_src = &#39;nick_BLANCO&#39; and t.type = &#39;friendship&#39;;
&lt;/pre&gt;
Q9.
&lt;pre&gt;
SELECT nickname_dst, country, count(*) as nbFollowers
FROM UserAccount u JOIN Relationship r ON u.nickname = r.nickname_src
WHERE type=&#39;follower&#39;
GROUP BY nickname_dst, country
ORDER BY nickname_dst, country, nbFollowers DESC
&lt;/pre&gt;
Q10.
&lt;pre&gt;
SELECT first_name, last_name
FROM UserAccount
WHERE nickname in
  (
    SELECT distinct u.nickname
    FROM Post p JOIN Tag t ON p.post_id=t.post_id 
        JOIN UserAccount u ON u.nickname=t.nickname
    WHERE p.nickname=&#39;nick_CAMERON&#39;
  )
&lt;/pre&gt;
Q11.
&lt;pre&gt;
SELECT nickname, first_name, last_name
FROM UserAccount
WHERE nickname IN
  ( SELECT nickname_dst as nickname
    FROM Relationship
    WHERE nickname_src=&#39;nick_CAMERON&#39; AND type=&#39;friendship&#39;
          AND nickname_dst IN
            ( SELECT nickname_dst as nickname
              FROM Relationship
              WHERE nickname_src=&#39;nick_ANIS&#39;
                    AND type=&#39;friendship&#39;)
  )
&lt;/pre&gt;
Q12.
&lt;pre&gt;
SELECT u.nickname, u.first_name, u.last_name, nbFollowers
FROM UserAccount u JOIN
      (SELECT nickname_dst as nickname, count(*) as nbFollowers
      FROM Relationship r
      WHERE r.type=&#39;follower&#39;
      GROUP BY r.nickname_dst) temp ON u.nickname = temp.nickname
ORDER BY nbFollowers DESC
&lt;/pre&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;database-of-a-banking-system&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; Database of a banking system&lt;/h1&gt;
&lt;p&gt;We consider the following collection of relational tables:&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Bank&lt;/TT&gt; (&lt;u&gt;code_bank&lt;/u&gt;, name, street_number, street_name, postal_code)&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Branch&lt;/TT&gt; (&lt;u&gt;branch_id&lt;/u&gt;, street_number, street_name, postal_code, code_bank)&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Account&lt;/TT&gt; (&lt;u&gt;acct_nbr&lt;/u&gt;, acct_type, balance, branch_id, ssn)&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Loan&lt;/TT&gt; (&lt;u&gt;loan_nbr&lt;/u&gt;, loan_type, amount, branch_id, ssn)&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Customer&lt;/TT&gt; (&lt;u&gt;ssn&lt;/u&gt;, first_name, last_name, telephone, street_number,
street_name, postal_code)&lt;/p&gt;
&lt;p&gt;&lt;TT&gt;Address&lt;/TT&gt; (&lt;u&gt;postal_code&lt;/u&gt;, city, country)&lt;/p&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-2&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.1  &lt;/strong&gt;&lt;/span&gt;
Write the following queries in SQL:&lt;/p&gt;
&lt;p&gt;Q1. Get the name, street name, street number and postal code of all the banks in the database.&lt;/p&gt;
&lt;p&gt;Q2. Get the city and country of all banks in the database.&lt;/p&gt;
&lt;p&gt;Q3. Count the number of accounts by customer.&lt;/p&gt;
&lt;p&gt;Q4. Get the amount of money owned by the customer.&lt;/p&gt;
&lt;p&gt;Q5. Return the average amount of money loaned by any bank for a mortgage.&lt;/p&gt;
&lt;p&gt;Q6. Get the amount of money loaned by each bank.&lt;/p&gt;
&lt;p&gt;Q7. Get the social security number, the first and last name of all customers of the bank with name “Bank of America”.&lt;/p&gt;
&lt;p&gt;Q8. Get all the data (including the full address) on the customers that have a checking account with a negative balance.&lt;/p&gt;
&lt;p&gt;Q9. Get the SSN of all customers that have no loan at the “Bank of America”.&lt;/p&gt;
&lt;p&gt;Q10. Get the name of the bank that has the most branches.&lt;/p&gt;
&lt;p&gt;Q11. Get the SSN of all customers having an account in more than one bank.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
Q1.
&lt;pre&gt;
SELECT name_bank, street_number, street_name, postal_code
FROM Bank
&lt;/pre&gt;
Q2.
&lt;pre&gt;
SELECT name_bank, city, country
FROM Bank ba JOIN Address a ON ba.postal_code = a.postal_code
&lt;/pre&gt;
Q3.
&lt;pre&gt;
SELECT ssn, count(*)
FROM Account
GROUP BY ssn
&lt;/pre&gt;
Q4.
&lt;pre&gt;
SELECT SUM(balance)
FROM Account a JOIN Customer c ON a.ssn = c.ssn
WHERE c.first_name = &#34;John&#34; AND c.last_name = &#34;Smith&#34;
&lt;/pre&gt;
Q5.
&lt;pre&gt;
SELECT AVG(amount)
FROM Loan
WHERE loan_type = &#34;mortgage&#34;
&lt;/pre&gt;
Q6.
&lt;pre&gt;
SELECT ba.name_bank, sum(amount)
FROM Loan l JOIN Branch br ON l.branch_id = br.branch_id
    JOIN Bank ba  ON br.code_bank = ba.code_bank
GROUP BY ba.code_bank
&lt;/pre&gt;
Q7.
&lt;pre&gt;
SELECT distinct c.ssn, c.first_name, c.last_name
FROM Account a JOIN Customer c ON a.ssn =  c.ssn
      JOIN Branch br ON a.branch_id = br.branch_id
      JOIN Bank ba ON ba.code_bank = br.code_bank
WHERE ba.name_bank = &#34;Bank of America&#34;
&lt;/pre&gt;
Q8.
&lt;pre&gt;
SELECT c.*, addr.city, addr.country
FROM Customer c JOIN Account acc ON c.ssn = acc.ssn
    JOIN Address addr ON c.postal_code = addr.postal_code
WHERE  acc.balance &lt; 0 and acc.acct_type=&#39;checking&#39;
&lt;/pre&gt;
Q9.
&lt;pre&gt;
SELECT ssn
FROM Customer
WHERE ssn NOT IN (
    SELECT c.ssn
    FROM Customer c JOIN Loan l ON c.ssn = l.ssn
            JOIN Branch br ON l.branch_id=br.branch_id
            JOIN Bank ba ON br.code_bank=ba.code_bank 
    WHERE ba.name_bank=&#39;Bank of America&#39;
  )
&lt;/pre&gt;
Q10.
&lt;pre&gt;
SELECT name_bank
FROM Bank
WHERE code_bank IN 
(
  SELECT code_bank
  FROM Branch
  GROUP BY code_bank
  HAVING COUNT(*) =
        (SELECT MAX(nb_Branches)
         FROM 
              (SELECT count(*) as nb_Branches
                FROM Branch
                GROUP BY code_bank)
        )
)
&lt;/pre&gt;
Q11.
&lt;pre&gt;
SELECT ssn
  FROM
      (SELECT  distinct a.ssn as ssn, br.code_bank as code_bank
       FROM Account a JOIN Branch br ON a.branch_id = br.branch_id)
  GROUP BY ssn
  HAVING COUNT(*) &gt; 1
&lt;/pre&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>SQLite in action</title>
      <link>/courses/databases/tutorials/sqlite/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/courses/databases/tutorials/sqlite/</guid>
      <description>


&lt;p&gt;&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/course.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;/styles/cloud-computing.css&#34;&gt;&lt;/p&gt;
&lt;div id=&#34;obtain-the-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Obtain the data&lt;/h1&gt;
&lt;p&gt;We consider the database of DVD rental store containing data on films, actors,
customers and the transactions of the store.&lt;/p&gt;
&lt;p&gt;You can obtain the data &lt;a href=&#34;/courses/databases/tutorial-4/sakila_new.db&#34;&gt;at this link&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The following figure shows the &lt;strong&gt;physical schema&lt;/strong&gt; of the database.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:cnm&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/courses/databases/tutorial-4/sakila_new.png&#34; alt=&#34;The physical schema of the database&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1.1: The physical schema of the database
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;You should now open the database with &lt;strong&gt;DB Browser for SQLite&lt;/strong&gt;.
To this extent, open &lt;strong&gt;DB Browser for SQLite&lt;/strong&gt;, click on &lt;em&gt;Open database&lt;/em&gt;
and select the downloaded file.&lt;/p&gt;
&lt;div class=&#34;infobox warning&#34;&gt;
&lt;p&gt;&lt;strong&gt;Foreign key alert&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;By default, SQLite doesn’t check foreign key constraints.
Open the preferences of DB Browser for SQLite and make sure
the checkbox &lt;em&gt;Foreign keys&lt;/em&gt; in the tab &lt;em&gt;Database&lt;/em&gt; is checked.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;foreign-key-constraints&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; Foreign key constraints&lt;/h1&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-1&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.1  &lt;/strong&gt;&lt;/span&gt;
Try to delete the film with &lt;em&gt;film_id&lt;/em&gt;=1 from
the table &lt;TT&gt;Film&lt;/TT&gt;.
What happens?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;The query is not allowed, because there
are rows in other tables that reference that movie.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-2&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.2  &lt;/strong&gt;&lt;/span&gt;
Write a query to get &lt;em&gt;film_id&lt;/em&gt;,
&lt;em&gt;actor_id&lt;/em&gt; and &lt;em&gt;title&lt;/em&gt; from
the table &lt;TT&gt;film&lt;/TT&gt;
joined with &lt;TT&gt;film_actor&lt;/TT&gt;
for the film “ACE GOLDFINGER”.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;pre&gt;
SELECT f.film_id, fa.film_id, fa.actor_id, f.title
FROM film f JOIN film_actor fa ON f.film_id = fa.film_id
WHERE  f.title=&#34;ACE GOLDFINGER&#34;
&lt;/pre&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-3&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 2.3  &lt;/strong&gt;&lt;/span&gt;
Modify the identifier of the film ACE GOLDFINGER
in table &lt;TT&gt;Film&lt;/TT&gt;.
Write the query of the previous exercise.
What happens?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
&lt;p&gt;The identifier of the film is changed in all referencing tables.
This is because the foreign key constraint is defined
ON UPDATE CASCADE.&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;queries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; Queries&lt;/h1&gt;
&lt;div class=&#34;infobox exercisebox&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&#34;exercise&#34;&gt;
&lt;p&gt;&lt;span id=&#34;exr:unnamed-chunk-4&#34; class=&#34;exercise&#34;&gt;&lt;strong&gt;Exercise 3.1  &lt;/strong&gt;&lt;/span&gt;
Write the following queries in SQL:&lt;/p&gt;
&lt;p&gt;Q1. Return the first and last names of all the actors.&lt;/p&gt;
&lt;p&gt;Q2. Return the title and the language of each film.&lt;/p&gt;
&lt;p&gt;Q3. Return the first and the last name of the manager of the store with code 2.&lt;/p&gt;
&lt;p&gt;Q4. Return the first and last names of all the actors who performed in the movie ‘ANGELS LIFE’.&lt;/p&gt;
&lt;p&gt;Q5. Return the number of films where each actor performed. Sort the results in descending order.&lt;/p&gt;
&lt;p&gt;Q6. Return the film categories that contain between 25 and 55 films.&lt;/p&gt;
&lt;p&gt;Q7. Return the first and family name of the customers who have rented more than five family movies.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Solution&lt;/summary&gt;&lt;/p&gt;
&lt;div class=&#34;infobox exosolution&#34;&gt;
Q1.
&lt;pre&gt;
SELECT first_name,last_name 
FROM actor
&lt;/pre&gt;
Q2.
&lt;pre&gt;
SELECT f.title, l.name 
FROM film AS f JOIN language AS l 
    ON f.language_id = l.language_id;
&lt;/pre&gt;
Q3.
&lt;pre&gt;
SELECT first_name, last_name
FROM store JOIN staff ON manager_staff_id = staff_id
WHERE store.store_id=2;
&lt;/pre&gt;
Q4.
&lt;pre&gt;
SELECT first_name,last_name
FROM actor a  JOIN film_actor fa 
        ON a.actor_id=fa.actor_id
        JOIN film f ON fa.Film_ID=f.Film_ID
WHERE f.title=&#34;ANGELS LIFE&#34;
&lt;/pre&gt;
Q5.
&lt;pre&gt;
SELECT first_name, last_name, count(*) as nbFilms
FROM actor a JOIN film_actor fa on a.actor_id=fa.actor_id
GROUP BY a.actor_id, a.first_name, a.last_name
ORDER BY nbFilms DESC
&lt;/pre&gt;
Alternative solution:
&lt;pre&gt;
SELECT t.actor_id, t.nb_films
FROM    
(SELECT actor_id, count(*) as nb_films
FROM film_actor
GROUP BY actor_id
ORDER BY nb_films DESC) t
&lt;/pre&gt;
Q6.
&lt;pre&gt;
SELECT c.name 
FROM category c JOIN film_category fc ON c.category_id = fc.category_id 
GROUP BY c.category_id 
HAVING count(*) BETWEEN 25 AND 55 
&lt;/pre&gt;
Alternative solution:
&lt;pre&gt;
SELECT name 
FROM category
WHERE category_id IN
(SELECT category_id
FROM film_category fc 
GROUP BY category_id 
HAVING COUNT(*) BETWEEN 25 AND 55)
&lt;/pre&gt;
Q7.
&lt;pre&gt;
SELECT c.customer_id, c.first_name, c.last_name,  COUNT(*) AS nbFilms 
FROM customer c JOIN rental r ON c.customer_id=r.customer_id  
    JOIN inventory i ON r.inventory_id = i.inventory_id 
    JOIN film f ON i.Film_ID = f.Film_ID 
    JOIN film_category fc on f.Film_ID = fc.Film_ID 
    JOIN category c ON fc.category_id = c.category_id 
WHERE c.name = &#34;Family&#34; 
GROUP BY r.customer_id 
HAVING nbFilms &gt; 5;
&lt;/pre&gt;
Alternative solution:
&lt;pre&gt;
SELECT first_name, last_name
FROM customer
WHERE customer_id IN (
SELECT r.customer_id 
FROM rental r JOIN inventory i ON r.inventory_id = i.inventory_id 
    JOIN film f ON i.Film_ID = f.Film_ID 
    JOIN film_category fc on f.Film_ID = fc.Film_ID 
    JOIN category c ON fc.category_id = c.category_id 
WHERE c.name = &#34;Family&#34; 
GROUP BY r.customer_id 
HAVING count(*) &gt; 5)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
