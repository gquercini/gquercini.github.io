<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <title>Map Reduce Exercises</title>
    <link rel="stylesheet" type="text/css" href="./styles/exercises.css">

    <link rel="stylesheet" href="./styles-hjs/default.css">
    <script src="./scripts/highlight.pack.js"></script>

    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

    <script>hljs.initHighlightingOnLoad();</script>
    <script>
      function showHideSolution(elem, elemLink) {
        state = document.getElementById(elem).style.display;
        if (state == "none") {
        	document.getElementById(elem).style.display='block';
          document.getElementById(elemLink).innerHTML='Hide solution'
        }
        else {
          document.getElementById(elem).style.display='none';
          document.getElementById(elemLink).innerHTML='See solution'
        }

      }
    </script>
  </head>
  <body>

    <img src="./figs/cs-logo.png" alt="cs-logo" class="logo">

    <h1>Exercises on MapReduce</h1>

    <h2>Average Monthly Temperature of the Year</h2>

    We are given a dataset that contains the average monthly temperature measurements over
    the course of some years.
    More precisely, the dataset is stored in a CSV file, where each row corresponds to
    a monthly measurement and the columns
    contain the following values: year, month, average temperature.
    <pre>
    <code>
    1980,11,11.0
    1980,12,4.0
    1981,1,1.0
    ....
    </code>
    </pre>
We intend to write an algorithm that returns the average monthly temperature of each year;
    the output of the algorithm is a set of key-value pairs (e.g., (1980, 20.0), (1981, 15.0), (1982, 17.0) ...),
    where the key is a year and the value is the average monthly temperature in that year.
    <pre>
    <code>
    1980,20.0
    1981,15.0
    1982,17.0
    ....
    </code>
    </pre>

    <h3>Questions</h3>

    <ol type="a">
      <li> Describe a MapReduce algorithm to compute the average monthly temperature of each year
        [<a href="#" onclick="showHideSolution('temperature-mr-solution', 'temperature-mr-solution-link');return false;"><span id="temperature-mr-solution-link">See solution</span></a>].
        <div id="temperature-mr-solution"  style="display:none;" class="reltables">
        <b>Informal description of the solution.</b><br><br>
        \(map(year, month, temp) : (year, temp)\)<br>
        \(reduce(year, temps) : (year, avg(temps))\)<br>
        \(temps\) is a list with all the temperatures in a given year. \(avg(year)\) returns the average of the values in the list \(temps\).
        <br><br>
        <b>Python code</b>
        <pre>
        <code>
def mapper(self, _, line):
    (year, month, temp) = line.split(",")
    yield(int(year), float(temp))

def reducer(self, year, temps):
    temperatures = list(temps)
    yield(year, sum(temperatures)/len(temperatures))

        </code>
        </pre>
        </div>
      <li> Describe an algorithm in Spark to compute the average monthly temperature of each year
        [<a href="#" onclick="showHideSolution('temperature-spark-solution', 'temperature-spark-solution-link');return false;"><span id="temperature-spark-solution-link">See solution</span></a>].
        <div id="temperature-spark-solution"  style="display:none;" class="reltables">
          <b>Informal description of the solution.</b><br>

          <ul>
            <li> The input is a RDD \(temps\), where each element is a line \(year,month,temp\) of the input file.
            <li> Transform \(temps\) into a RDD where each element is a list \([year,month, temp]\).
            <li> Transform \(temps\) into a RDD where each element is a key-value pair \((year, (temp, 1))\).
            <li> Transform \(temps\) into a RDD where each element is a tuple \((year, (sum(temperatures), len(temperatures)))\), 
              where \(sum(temperatures)\) is the sum of temperatures in the given \(year\) and 
              \(len(temperatures)\) is the number of temperatures registered in the year.
            <li> Transform \(temps\) into a RDD where each element is a tuple \((year, sum(temperatures)/len(temperatures))\).
          </ul>
          <br>
          <b>Python code</b>
          <pre>
          <code>
def avg_temperature(filename):
  temps = sc.textFile(filename)\
    .map(lambda line: line.split(","))\
    .map(lambda triple: (triple[0],(float(triple[2]),1)))\
    .reduceByKey(lambda x, y:((x[0]+x[1]),(y[0]+y[1])))\
    .mapValues(lambda t:t[0]/t[1])
  return temps
          </pre>
        </code>
        </div>
    </ol>

    <h2>Common Friends</h2>
    A social network platform stores in a huge CSV file the relationships among the individuals.
    Each line of the file contains the nickname of the individual,
    followed by the list of the nicknames of his/her friends.
    In the following excerpt of the file:
    <pre>
    <code>
A,B,C,D
B,A,D
C,A,D
D,A,B,C,E,F
E,D,F
F,D,E
    </code>
    </pre>
    the first line indicates that the individual A is friend with B, C, D; the second line indicates that B is friend with A and D; ...
    We want to implement an algorithm to find the common friends between any two individuals.
    The output of the algorithm is a set of key-value pairs (e.g., ((A, B), [D]), ((A, D), [B,C]), ...),
    where the key is a pair of individuals and the value is the list of the common friends
    of the two individuals.

    <h3>Questions</h3>

    <ol type="a">
      <li> Describe a MapReduce algorithm
        [<a href="#" onclick="showHideSolution('commonfriends-mr-solution', 'commonfriends-mr-solution-link');return false;"><span id="commonfriends-mr-solution-link">See solution</span></a>].
        <div id="commonfriends-mr-solution"  style="display:none;" class="reltables">
          <b>Informal description of the solution.</b><br><br>
          \(map(x, F) : ((u, v), x) \forall (u, v) \in F, u< v \)<br>
          <ul>
            <li> \((x, F)\) refers to an individual \(x\) and the list \(F\) of the friends of \(x\).
            <li> In the output, \(u, v\) are lexicographically sorted, to avoid repetitions.
          </ul>
          \(reduce((u, v), L) : ((u, v), L)\)<br>
          \(L\) is the list of individuals that are friends with \(u\) and \(v\). reduce is the identity function.
          <br><br>
          <b>Python code</b>
          <pre>
          <code>
def mapper(self, _, line):
      (x, F) = line.split(",")[0], line.split(",")[1:]
      for u in F:
          for v in F:
              if u < v:
                  yield((u, v),  x)

  def reducer(self, pair, L):
      yield(pair, list(L))
          </code>
          </pre>
        </div>
      <li> Describe an algorithm in Spark
        [<a href="#" onclick="showHideSolution('commonfriends-spark-solution', 'commonfriends-spark-solution-link');return false;"><span id="commonfriends-spark-solution-link">See solution</span></a>].
        <div id="commonfriends-spark-solution"  style="display:none;" class="reltables">
          <b>Informal description of the solution.</b><br>

          <ul>
            <li> The input is a RDD \(cf\), where each element is a line \(A, B, C, D...\) of the input file.
            <li> Transform \(cf\) into a RDD where each element is a list \([x, F]\), where \(x\) is an individual and \(F\) is the list of the friends of \(x\).
            <li> Transform \(cf\) into a RDD where each element is a tuple \(((u, v), x)\ \forall u, v \in F\ u< v\).
            <li> Group \(cf\) by key.
          </ul>
          <br>
          <b>Python code</b>
          <pre>
          <code>
def common_friends(filename):
    cf = sc.textFile(filename)\
            .map(lambda line: line.split(","))\
            .flatMap(lambda t: [((u, v), t[0]) for u in t[1:] for v in t[1:] if u < v])\
            .groupByKey()\
            .mapValues(lambda x: list(x))
    return cf
          </pre>
        </code>
        After the transformation groupByKey, each element of the RDD \(cf\) is a pair \((x, L)\), where \(L\) is an interable.
        The last transformation is used to transform the iterable into a list, for each key.
        </div>
    </ol>

    <h2>User similarity</h2>

    Consider a dataset that contains the rates that the MovieLens users assign to movies.
    The dataset is contained in one file, as follows:
    <pre>
    <code>
    23,"Toy Story",4
    12,"Armageddon",2
    123,"Gone with the Wind",4.5
    ....
    </code>
    </pre>
    where each row contains the identifier of a user, the title of a movie and the rate (a value between 1 and 5)
    that the user gives to the movie.
    For simplicity, we assume that there aren't any two movies with the same title.
    We want to develop an algorithm that computes the similarity between the users based on the movies that they rated.
    The output of the algorithm is a set of key-value pairs, such as \(((u_1, u_2), sim_{u_1, u_2})\), where
    the key is a pair \((u_1, u_2)\) of users and the value is the similarity between \(u_1\) and \(u_2\).

    <p>
    The similarity \(S(u_1, u_2)\) of two users \(u_1\) and \(u_2\) is given by the following
    Jaccard score:
    $$
    S(u_1, u_2) = \frac{|L(u_1) \cap L(u_2)|}{|L(u_1) \cup L(u_2)|}
    $$
    </p>
    where \(L(u_1)\) and \(L(u_2)\) are the set of movies liked by the user \(u_1\)
    and \(u_2\) respectively.
    We consider that a user "likes" a movie when the user gives the movie a rate \(\geq 3\).

    <h3>Questions</h3>

    <ol type="a">
      <li> Describe a MapReduce algorithm to compute the similarity between pairs of users in MovieLens
        [<a href="#" onclick="showHideSolution('usersim-mr-solution', 'usersim-mr-solution-link');return false;"><span id="usersim-mr-solution-link">See solution</span></a>].
        <div id="usersim-mr-solution"  style="display:none;" class="reltables">
          <b>Informal description of the solution.</b><br><br>
          We have three iterations of MapReduce.
          <ol>
            <li> First iteration.<br>
                \(map(user, movie, rate) : (user, movie)\) if \(rate \geq 3\)<br>
                \(reduce(user, L_u): (f, (user, len(L_u))), \forall f \in L_u\). \(L_u\) is the list of movies liked by \(user\).
            <li> Second iteration.<br>
                 \(map(f, (user, l)): (f, (user, l)) \) identity function, \(l\) is the number of movies liked by \(user\). <br>
                 \(reduce(f, users): ((u_1, l_1, u_2, l_2), f)\ \forall (u_1, l_1), (u_2, l_2) \in users\ u_1 < u_2 \).
            <li> Third iteration. <br>
                \(map((u_1, l_1, u_2, l_2), f): ((u_1, l_1, u_2, l_2), f) \) identity function <br>
                \(reduce((u_1, l_1, u_2, l_2), I): ((u_1, u_2), len(I) / (l_1 + l_2 - len(I)))\). \(I\) is the list of movies liked by both \(u_1\) and \(u_2\).
          </ol>
          <br>
          <b>Python code</b>
          <pre>
          <code>
def first_mapper(self, _, line):
        (user, movie, rate) = line.split(",")
        if float(rate) >= 3:
            yield(user, movie)

def first_reducer(self, user, L_u):
    L_u_list = list(L_u)
    for f in L_u_list:
        yield(f, (user, len(L_u_list)))


def second_reducer(self, f, users):
    users_list = list(users)
    for u1 in users_list:
        for u2 in users_list:
            if u1 < u2:
                yield((u1, u2), f)

def third_reducer(self, pair_users, intersection):
    intersection_size = sum(1 for i in intersection)
    union_size = pair_users[0][1] + pair_users[1][1] - intersection_size
    yield((pair_users[0][0], pair_users[1][0]), intersection_size / union_size)
          </code>
          </pre>
        </div>

      <li> Describe an algorithm in Spark to compute the similarity between pairs of users in MovieLens
        [<a href="#" onclick="showHideSolution('usersim-spark-solution', 'usersim-spark-solution-link');return false;"><span id="usersim-spark-solution-link">See solution</span></a>].
        <div id="usersim-spark-solution"  style="display:none;" class="reltables">
          <b>Informal description of the solution.</b><br>

          <ul>
            <li> The input is a RDD \(user\_sim\), where each element is a line \(user, movie, rate\) of the input file.
            <li> Transform \(user\_sim\) into a RDD where each element is a tuple \((user, movie, rate)\).
            <li> Filter \(user\_sim\) to only keep the tuples \((user, movie, rate)\), where \(rate \geq 3\).
            <li> Transform \(user\_sim\) into a RDD where each element is a tuple \((user, L)\), where \(L\) is the list of movies liked by \(user\).
            <li> Transform \(user\_sim\) into a RDD where each element is a tuple \((movie, [(user, len(L))])\), \(\forall movie \in L\).
            <li> Transform \(user\_sim\) into a RDD where each element is a tuple \((movie, K)\), where \(K\) is the list of users that liked the \(movie\), and
              each element of \(K\) is a tuple \((u, l)\), where \(u\) is a user and \(l\) is the number of movies liked by \(u\).
            <li> Transform \(user\_sim\) into a RDD where each element is a tuple \(((u_1, l_1, u_2, l_2), [movie])\), \(\forall (u_1, l_1), (u_2, l_2) \in K, u_1< u_2\).
            <li> Transform \(user\_sim\) into a RDD where each element is a tuple \(((u_1, l_1, u_2, l_2), I)\), where \(I\) is the list of movies liked by both \(u_1\)
              and \(u_2\).
           <li> Transform \(user\_sim\) into a RDD where each element is a tuple \(((u_1, u_2), len(I)/(l_1 + l_2 - len(I)))\), where \(I\) is the list of movies liked by both \(u_1\)
             and \(u_2\).
          </ul>
          <br>
          <b>Python code</b>
          <pre>
          <code>
def similarity(filename):
  user_sim = sc.textFile(filename)\
    .map(lambda line: line.split(","))\
    .filter(lambda t: float(t[2]) >= 3)\
    .map(lambda t: (t[0], [t[1]]))\
    .reduceByKey(lambda x, y : x + y)\
    .flatMap(lambda t: [(f, [(t[0], len(t[1]))]) for f in t[1]])\
    .reduceByKey(lambda x, y:x+y)\
    .flatMap(lambda t: [((u1, u2), [t[0]]) for u1 in t[1] for u2 in t[1] if u1< u2])\
    .reduceByKey(lambda x, y:x+y)\
    .map(lambda t: ((t[0][0][0], t[0][1][0]), len(t[1])/(t[0][0][1] + t[0][1][1] - len(t[1]))))
  return user_sim
          </pre>
        </code>
        </div>
    </ol>

    <h2>k-means</h2>

    <p>Let \(P\) be a set of \(n\) points \((x_0, x_1, ..., x_{n-1})\) in a d-dimensional space.
    We want to partition the points into \(k \leq n\) groups, called <i>clusters</i>,
    \(C=\{C_0, C_1, ..., C_{k-1}\}\)
    so as to minimize the within-cluster sum of squares \(S\) given by the following formula:
    $$
    S = \sum_{j=0}^{k-1} \sum_{x \in C_j}  \left\lVert x - \mu_j \right\rVert^2
    $$
    where \(\mu_j\) is the mean (a.k.a, <i>centroid</i>) of the points in cluster \(C_j\). </p>

    K-means is a popular clustering algorithm that goes through the following steps:
    <ol>
      <li> <b>Initialization.</b> Choose randomly \(k\) centroids \(\mu_0^{(1)}, ..., \mu_{k-1}^{(1)}\) for the
        clusters \(C_0, ..., C_{k-1}\).
      <li> For \(t \geq 2\), execute the following steps:
        <ul>
          <li> <b>Assignment.</b> Assign each point to the cluster whose centroid is the nearest.
            In other words, the cluster \(C_j^{(t)}\) at iteration \(t\) is defined as follows:
            $$
            C_j^{(t)} = \left \{x_p : \left\lVert x_p - \mu_j^{(t-1)} \right\rVert^2\ \leq \left\lVert x_p - \mu_z^{(t-1)} \right\rVert^2, \forall z \ne j, 0 \leq z \leq k-1 \right \}
            $$
          <li> <b>Update.</b> Compute the new centroids of the clusters \(\mu_0^{(t)}, ..., \mu_{k-1}^{(t)} \), as follows:
            $$
            \mu_j^{(t)} = \frac{1}{|C_j^{(t)}|} \sum_{x \in C_j^{(t)}} x
            $$
          <li> <b>Stopping critirion.</b> If \(\mu_j^{(t-1)} = \mu_j^{(t)}, \forall\ 0 \leq j \leq k-1 \), stop, otherwise execute from 2.
        </ul>
    </ol>
    The input points \((x_0, x_1, ..., x_{n-1})\)
    are stored in a text file, where each line contains the coordinates of a point.
    In the following example, \(x_0 = (56.18,41.09)\), \(x_1 = (41.56,51.57)\),
    \(x_2 = (38.96,80.92)\)...
    <pre>
    <code>
0,56.18,41.09
1,41.56,51.57
2,38.96,80.92
3,51.68,53.45
4,63.88,18.06
5,85.34,54.72
6,68.72,24.04
7,15.2,15.93
....
  </code>
  </pre>
In the output, we want the key value pairs \((j, \mu_j)\ \forall\ 0 \leq j \leq k-1\), such as:
<pre>
<code>
(0,[39.28,20.04])
(1, [27.33, 71.08])
(2, [79.95, 54.63])
....
  </code>
</pre>

    <h3> Questions </h3>

    <ol type="a">
      <li> Describe a MapReduce implementation of k-means
        [<a href="#" onclick="showHideSolution('kmeans-mr-solution', 'kmeans-mr-solution-link');return false;"><span id="kmeans-mr-solution-link">See solution</span></a>].
        <div id="kmeans-mr-solution"  style="display:none;" class="reltables">
          <b>Informal description of the solution.</b><br><br>
          \(map(i, x_i) : (j, x_i)\ s.t.\ j = arg\,min_j(dist(\mu_j, x_i)) \).<br>
          \(reduce(j, L) : (j, compute\_centroid(L))\)<br>
          \(L\) is the list of points that are closest to the j-th centroid. \(compute\_centroid\) is a function that computes the centroid of a given list of points.
          <br>
          <br>
          The two Map-Reduce functions are iterated until convergence.
          A script is used to generate the initial centroids, broadcast them to the mappers, launch the iterations  and check the convergence
          at the end of each.<br><br>
          <b>Python code</b>
          <pre>
          <code>
def mapper(self, _, line):
        centroids = self.read_centroids()
        values = line.split(",")
        point = (int(values[0]), [float(v) for v in values[1:]])
        mindist = float("inf")
        minclust = -1
        for c in centroids:
            dist = self.distance(point[1], c[1])
            if dist < mindist:
                mindist = dist
                minclust = c[0]
        yield(minclust, point[1])

def reducer(self, cluster_id, points):
        new_centroid = self.compute_centroid(list(points))
        yield(cluster_id, new_centroid)
          </code>
          </pre>
        </div>
      <li> Describe an implementation in Spark of k-means
        [<a href="#" onclick="showHideSolution('kmeans-spark-solution', 'kmeans-spark-solution-link');return false;"><span id="kmeans-spark-solution-link">See solution</span></a>].
        <div id="kmeans-spark-solution"  style="display:none;" class="reltables">
          <b>Informal description of the solution.</b><br>

          <ul>
            <li> Afer reading from file and splitting each line into its constituent parts, the input is a RDD \(points\), where each element is a tuple \((i, x_i)\).
            <li> Transform \(points\) into a RDD \(new\_centroids\), where each element is a tuple \((j, (i, x_i))\), \(j\) is the identifier of a cluster.
              In practice, for each input point \((i, x_i)\), the new RDD contains the tuples \((j, (i, x_i)))\ \forall\ 0\leq j \leq k-1\).
            <li> Let \(centroids\) be a RDD, where each element is \((j, \mu_j)\), where \(\mu_j\) is the coordinates of the j-th centroid.
            <li> Join the RDD \(new\_centroids\) with the RDD \(centroids\). Now, each element of the new RDD is \((j, ((i, x_i), \mu_j))\).
            <li> Transform the new RDD into one where each element is \((i, (j, x_i, distance(x_i, \mu_j)))\).
            <li> Group by key the elements of the new RDD. Now each element is \((i, L)\), where \(L=[(j, x_i, distance(x_i, \mu_j)) \forall\ 0\leq j \leq k-1 ]\).
            <li> Let \((j, x_{min}, distance(x_{min}, \mu_j) \in L\) be the item in \(L\) such that \(distance(x_{min}, \mu_j) \leq distance(x_{min}, \mu_z)\), for all centroids \(\mu_z\).
            <li> Transform the RDD into one where each element is \((j, x_{min})\).
            <li> Group by key. Now each element of the RDD is \((j, P)\), where \(P\) is the list of points closest to the j-th centroid.
            <li> Transform the RDD into one where each element is \((j, compute\_centroid(P))\).
          </ul>
          The steps above are repeated until convergence.
          <br><br>
          <b>Python code</b>
          <pre>
          <code>
def step_kmeans(k, d, points, centroids):
    print(centroids.collect())
    new_centroids = points.flatMap(lambda x: [(i, (x[0], x[1])) for i in range(k)])\
                        .join(centroids)\
                        .map(lambda x: (x[1][0][0], (x[0], x[1][0][1], distance(x[1][0][1], x[1][1], d))))\
                        .groupByKey()\
                        .mapValues(lambda x: sorted(list(x), key=lambda t:t[2]))\
                        .map(lambda x: (x[1][0][0], x[1][0][1]))\
                        .groupByKey()\
                        .mapValues(lambda x: compute_centroid(list(x), d))
    stop = centroids.union(new_centroids)\
                        .reduceByKey(lambda x, y: distance(x, y, d))\
                        .filter(lambda x: x[1] >= threshold).count() == 0
    if stop:
        return new_centroids
    else:
        return step_kmeans(k, d, points, new_centroids)

def kmeans(filename, k, d):
    centroids = sc.parallelize([(i, [round(random.uniform(0, 100), 2) for j in range(d)]) for i in range(k)])
    points = sc.textFile(filename)\
                .map(lambda line:line.split(","))\
                .map(lambda x: (int(x[0]), [float(v) for v in x[1:]]))
    return step_kmeans(k, d, points, centroids)
          </pre>
        </code>
        </div>
    </ol>



  </body>
  </html>
